
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName journalpublishing.dtd?><?SourceDTD.Version 2.3?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 2?><front><journal-meta><journal-id journal-id-type="nlm-ta">Syst Biol</journal-id><journal-id journal-id-type="iso-abbrev">Syst. Biol</journal-id><journal-id journal-id-type="publisher-id">sysbio</journal-id><journal-id journal-id-type="hwp">sysbio</journal-id><journal-title-group><journal-title>Systematic Biology</journal-title></journal-title-group><issn pub-type="ppub">1063-5157</issn><issn pub-type="epub">1076-836X</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">4141202</article-id><article-id pub-id-type="pmid">24789072</article-id><article-id pub-id-type="doi">10.1093/sysbio/syu031</article-id><article-id pub-id-type="publisher-id">syu031</article-id><article-categories><subj-group subj-group-type="heading"><subject>Software for Systematics and Evolution</subject></subj-group></article-categories><title-group><article-title><SecTag type="TITLE"><text><SENT sid="0" pm="."><plain>A Gateway for Phylogenetic Analysis Powered by Grid Computing Featuring GARLI 2.0 </plain></SENT>
</text></SecTag></article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bazinet</surname><given-names>Adam L.</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref><xref ref-type="corresp" rid="COR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Zwickl</surname><given-names>Derrick J.</given-names></name><xref ref-type="aff" rid="AFF1"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Cummings</surname><given-names>Michael P.</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref></contrib><aff id="AFF1"><sup>1</sup>Center for Bioinformatics and Computational Biology, University of Maryland, College Park, MD, 20742-3360, USA, and <sup>2</sup>Department of Ecology and Evolutionary Biology, University of Arizona, Tucson, AZ, 85721-0088, USA</aff></contrib-group><author-notes><corresp id="COR1">*Correspondence to be sent to: Center for Bioinformatics and Computational Biology, University of Maryland, Biomolecular Sciences Building, College Park, MD, 20742-3360, USA; E-mail: <email>adam.bazinet@umiacs.umd.edu</email>.</corresp><fn id="FN100"><p><text><SENT sid="1" pm="."><plain>Associate Editor: David Posada </plain></SENT>
</text></p></fn></author-notes><pub-date pub-type="ppub"><month>9</month><year>2014</year></pub-date><pub-date pub-type="epub"><day>30</day><month>4</month><year>2014</year></pub-date><pub-date pub-type="pmc-release"><day>30</day><month>4</month><year>2014</year></pub-date><volume>63</volume><issue>5</issue><fpage>812</fpage><lpage>818</lpage><history><date date-type="received"><day>2</day><month>2</month><year>2014</year></date><date date-type="rev-request"><day>21</day><month>3</month><year>2014</year></date><date date-type="accepted"><day>22</day><month>4</month><year>2014</year></date></history><permissions><copyright-statement>© The Author(s) 2014. Published by Oxford University Press, on behalf of the Society of Systematic Biologists.</copyright-statement><copyright-year>2014</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/3.0/"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<uri xlink:type="simple" xlink:href="http://creativecommons.org/licenses/by-nc/3.0/">http://creativecommons.org/licenses/by-nc/3.0/</uri>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com.</license-p></license></permissions><abstract><p><SecTag type="ABS"><text><SENT sid="2" pm="."><plain>We introduce molecularevolution.org, a publicly available gateway for high-throughput, maximum-likelihood phylogenetic analysis powered by grid computing. </plain></SENT>
<SENT sid="3" pm="."><plain>The gateway features a garli 2.0 web service that enables a user to quickly and easily submit thousands of maximum likelihood tree searches or bootstrap searches that are executed in parallel on distributed computing resources. </plain></SENT>
<SENT sid="4" pm="."><plain>The garli web service allows one to easily specify partitioned substitution models using a graphical interface, and it performs sophisticated post-processing of phylogenetic results. </plain></SENT>
<SENT sid="5" pm="."><plain>Although the garli web service has been used by the research community for over three years, here we formally announce the availability of the service, describe its capabilities, highlight new features and recent improvements, and provide details about how the grid system efficiently delivers high-quality phylogenetic results. </plain></SENT>
<SENT sid="6" pm="."><plain>[garli, gateway, grid computing, maximum likelihood, molecular evolution portal, phylogenetics, web service.] </plain></SENT>
</text></SecTag></p></abstract><counts><page-count count="7"/></counts></article-meta></front><body><p><text><SENT sid="7" pm="."><plain>The most widely used modern statistical methods of phylogenetic inference fall into two broad classes: maximum likelihood methods and Bayesian inference methods. </plain></SENT>
<SENT sid="8" pm="."><plain>Depending on the number of sequences, the number of characters, and the chosen evolutionary model, both maximum likelihood and Bayesian tree inference methods can be computationally intensive, thus creating the need for strategies that speed up computation and decrease time to results. </plain></SENT>
<SENT sid="9" pm="."><plain>One such strategy is parallelization, which distributes a logical unit of computation over multiple processors. </plain></SENT>
<SENT sid="10" pm="."><plain>Maximum likelihood methods are generally more amenable to parallelization than Bayesian inference methods, since the hundreds or thousands of searches for the maximum likelihood tree and bootstrap trees that are required for a typical phylogenetic analysis may be run independently of one another. </plain></SENT>
<SENT sid="11" pm="."><plain>We have developed a grid computing system that features the maximum likelihood-based program garli (Genetic Algorithm for Rapid Likelihood Inference; Zwickl 2006) for high-throughput phylogenetic analysis. </plain></SENT>
<SENT sid="12" pm="."><plain>Here we describe this publicly available system, in particular focusing on the user-friendly garli web interface available at molecularevolution.org. </plain></SENT>
</text></p><p><text><SENT sid="13" pm="."><plain>garli is an open-source phylogenetic inference program that uses the maximum likelihood criterion and a stochastic evolutionary algorithm to search for optimal solutions within the joint space of tree topologies, branch length parameter values, and model parameter values. garli was developed with the goal of increasing both the speed of maximum likelihood tree inference and the size of data sets that can be reasonably analyzed. garli 2.0 implements models for the analysis of biological sequence data (at the level of nucleotides, amino acids, or codons), as well as morphology and (not officially released) insertion–deletion characters. </plain></SENT>
<SENT sid="14" pm="."><plain>Version 2.0 introduced support for partitioned models, allowing simultaneous use of different data types or assignment of differing model parameters and rates to individual loci or codon positions. </plain></SENT>
<SENT sid="15" pm="."><plain>The program design focuses on flexibility of model choice and rigor in parameter estimation. </plain></SENT>
</text></p><p><text><SENT sid="16" pm="."><plain>Searches through phylogenetic tree space may become entrapped in local optima, and therefore it is necessary to perform multiple garli searches for the tree with the highest likelihood, which we simply call the best tree. </plain></SENT>
<SENT sid="17" pm="."><plain>This could entail hundreds of searches depending on the difficulty of the problem. </plain></SENT>
<SENT sid="18" pm="."><plain>Furthermore, one typically conducts hundreds or thousands of bootstrap replicate searches to assess confidence in the bipartitions found in the best tree. </plain></SENT>
<SENT sid="19" pm="."><plain>Depending on the number of sequences, the number of unique alignment columns, the evolutionary models employed, various garli configuration settings, and the capability of the designated computational resource, it can take hours or even days to complete a single garli search replicate. </plain></SENT>
<SENT sid="20" pm="."><plain>Thus, running many search replicates in parallel on a grid computing system greatly reduces the amount of time required to complete a set of analyses. </plain></SENT>
</text></p><p><text><SENT sid="21" pm="."><plain>Grid computing is a model of distributed computing that seamlessly links geographically and administratively disparate computational resources, allowing users to access them without having to consider location, operating system, or account administration (Cummings and Huskamp 2005). </plain></SENT>
<SENT sid="22" pm="."><plain>The Lattice Project, our grid computing system based on Globus software (Foster and Kesselman 1999), incorporates volunteer computers running boinc (Anderson 2004) as well as traditional grid computing resources such as Condor pools (Litzkow et al. </plain></SENT>
<SENT sid="23" pm="."><plain>1988) and compute clusters. </plain></SENT>
<SENT sid="24" pm="."><plain>The architecture and functionality of the grid system is described extensively elsewhere (Bazinet 2009); fundamentally, however, The Lattice Project provides access to scientific applications (which we term grid services), as well as the means to distribute the computation required by these services over thousands of processors. </plain></SENT>
<SENT sid="25" pm="."><plain>In recent years, the system has been enhanced by the development of a web interface to the garli grid service (Bazinet and Cummings 2011, currently available at molecularevolution.org). </plain></SENT>
<SENT sid="26" pm="."><plain>The garli grid service has been used in at least 50 published phylogenetic studies, with usage having increased dramatically since the release of the garli web interface (e.g., Myers and Cummings 2003; Regier et al. </plain></SENT>
<SENT sid="27" pm="."><plain>2009; Kawahara et al. </plain></SENT>
<SENT sid="28" pm="."><plain>2011; Bazinet et al. </plain></SENT>
<SENT sid="29" pm="."><plain>2013; Regier et al. </plain></SENT>
<SENT sid="30" pm="."><plain>2013; Sohn et al. </plain></SENT>
<SENT sid="31" pm="."><plain>2013, see Supplemental Material for the full list, available on Dryad <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.d7639">http://dx.doi.org/10.5061/dryad.d7639</ext-link>). </plain></SENT>
<SENT sid="32" pm="."><plain>As of April 2, 2014, 843 distinct web service users have completed 4835 analyses comprising 2,306,159 individual garli search replicates. </plain></SENT>
</text></p><p><text><SENT sid="33" pm="."><plain>In this article, we compare The Lattice Project to other scientific gateways and describe the features of the garli web service. </plain></SENT>
<SENT sid="34" pm="."><plain>In addition, we provide details about how the grid system efficiently processes computationally intensive phylogenetic analyses. </plain></SENT>
</text></p><sec><title><text><SENT sid="35" pm="."><plain>Features </plain></SENT>
</text></title><sec><title><text><SENT sid="36" pm="."><plain>The Lattice Project Compared to other Scientific Gateways </plain></SENT>
</text></title><p><text><SENT sid="37" pm="."><plain>There are a number of other scientific gateways that provide bioinformatics tools and services, including those for phylogenetic analysis. </plain></SENT>
<SENT sid="38" pm="."><plain>These include the Cyberinfrastructure for Phylogenetic Research (cipres) Gateway (Miller et al. </plain></SENT>
<SENT sid="39" pm="."><plain>2010), the University of Oslo Bioportal (Kumar et al. </plain></SENT>
<SENT sid="40" pm="."><plain>2009, which has recently closed), the Cornell Computational Biology Service Unit (cbsuapps.tc.cornell.edu), Phylemon (Sánchez et al. </plain></SENT>
<SENT sid="41" pm="."><plain>2011), and Mobyle (Néron et al. </plain></SENT>
<SENT sid="42" pm="."><plain>2009). </plain></SENT>
<SENT sid="43" pm="."><plain>Although each of these other systems has proved to be of use in phylogenetic research, our grid system has some distinguishing characteristics. GARLI version 2.0—Of the gateways supporting phylogenetic analysis, only The Lattice Project and the cipres gateways offer a garli 2.0 (Zwickl 2011) service.Unlimited computation—The garli service on molecularevolution.org currently allows an unlimited number of submissions, up to 100 best tree or 2000 bootstrap search replicates per submission, and no resource or runtime limitations. </plain></SENT>
<SENT sid="44" pm="."><plain>We are able to offer this level of service due to our implementation of stringent error checking, advanced scheduling mechanisms, and inclusion of novel resources such as our public computing pool of boinc clients.Facile user interface and resource abstraction—Fully embracing the grid computing model, the computing resources backing the garli service are abstracted from the user, facilitated by an elegant user interface. </plain></SENT>
<SENT sid="45" pm="."><plain>In contrast, the cipres gateway requires the user to become familiar with their computing resources and to specify their analysis in such a way that it will complete on the allocated resource (usually only a small number of processors) within an allotted period of time.Sophisticated and relevant post-processing—The use of stochastic algorithms, multiple search replicates, and bootstrap analyses generates a large number of individual results that must be compiled and processed for evaluation and subsequent use. </plain></SENT>
<SENT sid="46" pm="."><plain>We perform much of this post-processing automatically, including computation of the best tree found or bootstrap majority rule consensus tree, and the calculation of various summary statistics and graphical representations (see Post-processing routines).Large-scale public participation—The Lattice Project is the only phylogenetic analysis system that provides an easy and meaningful opportunity for public participation in research, which is achieved by using our boinc project (boinc.umiacs.umd.edu). </plain></SENT>
<SENT sid="47" pm="."><plain>Volunteers simply download a lightweight client to their personal computer, thus enabling it to process garli workunits for The Lattice Project. </plain></SENT>
<SENT sid="48" pm="."><plain>As of April 2, 2014, more than 16,956 people from 146 countries have participated.Minimal energy usage—Emergy, the energy embodied in computing components (which includes manufacture and transportation), accounts for the majority of power consumed in computing (Raghavan and Ma 2011). </plain></SENT>
<SENT sid="49" pm="."><plain>Put another way, the “greenest” computer is one that is never built. </plain></SENT>
<SENT sid="50" pm="."><plain>Apart from a few servers for web, database, and middleware services, no hardware is purchased specifically for our grid system. </plain></SENT>
<SENT sid="51" pm="."><plain>The institutional resources we use are comprised largely of desktop systems and clusters purchased for other purposes (e.g., teaching labs and research, respectively), and we use these resources only when they are not being used for their primary purpose. </plain></SENT>
<SENT sid="52" pm="."><plain>In addition, more than 38,481 computers from the general public have been volunteered at various stages of the project. </plain></SENT>
<SENT sid="53" pm="."><plain>For all of these resources, the emergy investment has already been made, and our use of these resources amortizes this investment over a greater usage basis. </plain></SENT>
<SENT sid="54" pm="."><plain>In contrast, phylogenetic analyses through other gateways compete for limited resources on high-capacity clusters, where the jobs often do not take advantage of the high-bandwidth, low-latency interconnects and other special hardware features offered. </plain></SENT>
<SENT sid="55" pm="."><plain>Furthermore, the widely distributed, low-density computing model of our grid system results in almost no additional energy use for cooling compared with the substantial energy costs of cooling computer data centers. No other openly accessible phylogenetic computing system collectively shares these attributes. </plain></SENT>
<SENT sid="56" pm="."><plain>Although dedicated high-performance computing resources have their place in scientific research, a substantial share of phylogenetic analyses can be performed very effectively, and more energy efficiently, by means of grid and public computing. </plain></SENT>
</text></p></sec><sec><title><text><SENT sid="57" pm="."><plain>GARLI Web Service: User Interface and Functionality </plain></SENT>
</text></title><p><text><SENT sid="58" pm="."><plain>We have recently upgraded the user interface to our grid system from a Unix command-line interface to a web-based one. </plain></SENT>
<SENT sid="59" pm="."><plain>This greatly reduces the entry barrier for potential non-technical users. </plain></SENT>
<SENT sid="60" pm="."><plain>Researchers were previously required to use command-line tools to upload data, submit analyses to a particular grid service (e.g., garli), and download subsequent results. </plain></SENT>
<SENT sid="61" pm="."><plain>Basic utilities were also available to query the status of jobs or cancel them. </plain></SENT>
</text></p><p><text><SENT sid="62" pm="."><plain>Although the command-line interface is still available, we anticipate that the web-based interfaces to our services will generate considerably more interest; the garli web service is the first of these to be developed. </plain></SENT>
<SENT sid="63" pm="."><plain>The following sections describe the modes of use and the basic functionality of the garli web service on molecularevolution.org. </plain></SENT>
</text></p><sec><title><text><SENT sid="64" pm="."><plain>Modes of use </plain></SENT>
</text></title><p><text><SENT sid="65" pm="."><plain>A garli web service user may register an account or choose to remain anonymous. </plain></SENT>
<SENT sid="66" pm="."><plain>Anonymous users are only required to provide an email address (used to notify them of job status updates) and to fill out a captcha (Completely Automated Public Turing test to tell Computers and Humans Apart) for each job submission to prevent spam. </plain></SENT>
<SENT sid="67" pm="."><plain>Anonymous use of the web service is a convenient way to try out the service with minimal effort. </plain></SENT>
<SENT sid="68" pm="."><plain>However, registration on molecularevolution.org confers several advantages: (1) one does not have to fill out a captcha for each job submission; (2) one gains access to a file repository that can be used to store and reuse input files (Supplementary Fig. 1, available at <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.d7639">http://dx.doi.org/10.5061/dryad.d7639</ext-link>; and (3) one gains the ability to view a list of their jobs and manage them. </plain></SENT>
</text></p></sec><sec><title><text><SENT sid="69" pm="."><plain>Create job page </plain></SENT>
</text></title><p><text><SENT sid="70" pm="."><plain>Submitting a garli analysis via the create job page (Supplementary Fig. 2, available at <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.d7639">http://dx.doi.org/10.5061/dryad.d7639</ext-link>) consists of the following general steps: (1) specification of a job name, analysis type (best tree or bootstrap search), and number of replicates (up to 2000); (2) upload or specification of necessary input files (sequence data, starting tree, and/or constraint file); and (3) specification of model parameters and other program settings. </plain></SENT>
<SENT sid="71" pm="."><plain>Upon job submission, the system uses a special validation mode of the garli program to ensure that there are no problems with the user-supplied data file and the parameters specified; for example, very large data sets may require more ram than the system currently allows (i.e., 24,000 mb). garli search replicates are then scheduled to run in parallel on one or more grid system resources that meet the job requirements (e.g., that have enough ram). </plain></SENT>
<SENT sid="72" pm="."><plain>The user is notified by email if their job was submitted successfully or if it failed for some reason. </plain></SENT>
</text></p></sec><sec><title><text><SENT sid="73" pm="."><plain>Job status page </plain></SENT>
</text></title><p><text><SENT sid="74" pm="."><plain>The job status page (Supplementary Fig. 3, available at <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.d7639">http://dx.doi.org/10.5061/dryad.d7639</ext-link>) allows a registered user to view and manage a list of their jobs. </plain></SENT>
<SENT sid="75" pm="."><plain>For each job listed, the following attributes are displayed: job id, job name, number of replicates complete, job status, and time the job was created. </plain></SENT>
<SENT sid="76" pm="."><plain>The dropdown at the top of the page allows one to filter jobs by a particular job status (“idle”, “running”, “retrieved”, “failed”, or “removed”). </plain></SENT>
<SENT sid="77" pm="."><plain>Finally, using the button at the bottom of the page, one may remove jobs that are no longer of interest. </plain></SENT>
<SENT sid="78" pm="."><plain>If the jobs to be removed are in the process of running, they will be canceled. </plain></SENT>
</text></p></sec><sec><title><text><SENT sid="79" pm="."><plain>Job details page </plain></SENT>
</text></title><p><text><SENT sid="80" pm="."><plain>When a registered user selects a particular job from the job status page, or an anonymous user enters a valid e-mail address/job id combination on the same page, the job details page is shown (Supplementary Fig. 4, available at <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.d7639">http://dx.doi.org/10.5061/dryad.d7639</ext-link>). </plain></SENT>
<SENT sid="81" pm="."><plain>This page contains a section for job input files (both user-provided and system-generated) and a section for job output files. </plain></SENT>
<SENT sid="82" pm="."><plain>The job output files section always includes a zip file that contains all of the currently available output associated with the analysis. </plain></SENT>
<SENT sid="83" pm="."><plain>If all of the replicates for a particular analysis are complete, then the job output files section will also include the results of post-processing (see Post-processing routines). </plain></SENT>
</text></p></sec></sec><sec><title><text><SENT sid="84" pm="."><plain>Partitioned Analysis Specification </plain></SENT>
</text></title><p><text><SENT sid="85" pm="."><plain>Support for partitioned substitution models is the most significant new feature of garli 2.0. </plain></SENT>
<SENT sid="86" pm="."><plain>However, partitioned analysis specification can be a relatively complicated and error-prone process. </plain></SENT>
<SENT sid="87" pm="."><plain>We have made the specification of modestly-sized partitioned analyses easier by introducing a guided mode that allows the user to specify the details of the partitioned analysis with graphical form elements (Supplementary Fig. 5, available at <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.d7639">http://dx.doi.org/10.5061/dryad.d7639</ext-link>), rather than by manually composing a nexus sets block and garli model blocks. </plain></SENT>
<SENT sid="88" pm="."><plain>Guided mode is enabled once the user has selected a valid nexus data file, which the system processes with the Nexus Class Library (Lewis 2003). </plain></SENT>
<SENT sid="89" pm="."><plain>The user then creates one or more character sets (charsets), each consisting of a name, a start position, and an end position; charsets may also be specified by codon position using a checkbox. </plain></SENT>
<SENT sid="90" pm="."><plain>Once the user specifies one or more valid charsets they will be made available to be added to data subsets. </plain></SENT>
<SENT sid="91" pm="."><plain>Each data subset must contain at least one charset, but may contain more than one. </plain></SENT>
<SENT sid="92" pm="."><plain>The service currently allows the definition of up to ten data subsets in guided mode. </plain></SENT>
<SENT sid="93" pm="."><plain>For each data subset, a particular substitution model (or particular model parameters) may be specified. </plain></SENT>
<SENT sid="94" pm="."><plain>When the partitioned analysis is submitted, the service will automatically transform the charset and subset data into a nexus sets block and include it in the data file, and will likewise produce the appropriate model blocks and add them to the garli configuration file. </plain></SENT>
<SENT sid="95" pm="."><plain>For users who prefer to provide their own nexus sets block and garli model blocks, we provide an expert mode that allows the user to input them directly. </plain></SENT>
</text></p></sec><sec><title><text><SENT sid="96" pm="."><plain>Post-processing Routines </plain></SENT>
</text></title><p><text><SENT sid="97" pm="."><plain>Due to the difficulty of inferring large phylogenetic trees, multiple searches for the best tree are typically performed with garli. </plain></SENT>
<SENT sid="98" pm="."><plain>This increases the thoroughness of the search for the best tree, but the resulting large number of files and analysis results can be overwhelming. </plain></SENT>
<SENT sid="99" pm="."><plain>To ease the burden on the end user, our web-based system performs some post-processing routines, which include graphical and quantitative characterizations of the set of trees inferred from multiple search replicates. </plain></SENT>
</text></p><p><text><SENT sid="100" pm="."><plain>Post-processing generates a textual summary for all analyses (Supplementary Fig. 6, available at <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.d7639">http://dx.doi.org/10.5061/dryad.d7639</ext-link>). </plain></SENT>
<SENT sid="101" pm="."><plain>This file contains the following general information: (1) the data file used; (2) the number of replicates performed; (3) the cumulative garli runtime; and (4) suggestions for citing the garli web service (omitted from Supplementary Fig. 6, available at <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.d7639">http://dx.doi.org/10.5061/dryad.d7639</ext-link>). </plain></SENT>
<SENT sid="102" pm="."><plain>The analysis summary for a best tree search also contains summary statistics that characterize the distribution of log-likelihood scores and symmetric tree distances (Robinson and Foulds 1981, absolute and normalized), as well as estimates of the number of search replicates required to recover the best tree topology at three probability levels (see Calculating the required number of GARLI search replicates). </plain></SENT>
</text></p><p><text><SENT sid="103" pm="."><plain>In the case of a best tree search, post-processing generates the following files in addition to the analysis summary: (1) a nexus file containing the single tree with the highest likelihood score; (2) a file containing all of the trees found across search replicates, as well as a file containing only the unique trees found (both files in nexus format); (3) a file containing a sorted list of the likelihood scores of the trees found by the analysis and a file containing a sorted list of the likelihood scores of the unique trees found; (3) a pdf file showing the distribution of likelihood scores among trees (Fig. 1a); and (4) a pdf file showing the distribution of symmetric tree distances (Fig. 1b). </plain></SENT>
</text></p><SecTag type="FIG"><fig id="F1" position="float"><label>F<sc>igure</sc> 1.</label><caption><p><text><SENT sid="104" pm="."><plain>Properties of trees from multiple search replicates for a representative analysis using garli. </plain></SENT>
<SENT sid="105" pm="."><plain>a) The distribution of likelihood scores. </plain></SENT>
<SENT sid="106" pm="."><plain>b) The distribution of symmetric tree distances (as a fraction of the maximum possible value for the data set). </plain></SENT>
<SENT sid="107" pm="."><plain>Both measures are given as frequency and proportion. </plain></SENT>
</text></p></caption><graphic xlink:href="syu031f1"/></fig></SecTag><p><text><SENT sid="108" pm="."><plain>In the case of a bootstrap analysis, post-processing uses DendroPy (Sukumaran and Holder 2010) to generate the following files in addition to the analysis summary: (1) a nexus file containing all of the bootstrap trees from the analysis; (2) a nexus file containing the majority rule bootstrap consensus tree with bootstrap probability values embedded; (3) a pdf file showing the 0.90, 0.95, and 0.99 confidence intervals for the bootstrap probabilities observed in the majority rule bootstrap consensus tree, calculated using the formulas given in Hedges (1992) (Fig. 2); and (4) a table giving the 0.90, 0.95, and 0.99 confidence intervals for the bootstrap probabilities observed in the majority rule bootstrap consensus tree. </plain></SENT>
</text></p><SecTag type="FIG"><fig id="F2" position="float"><label>F<sc>igure</sc> 2.</label><caption><p><text><SENT sid="109" pm="."><plain>Confidence intervals associated with the bootstrap probabilities observed in the majority rule consensus tree computed from 500 garli bootstrap replicates. </plain></SENT>
<SENT sid="110" pm="."><plain>Confidence intervals are given for three probabilities (0.90, 0.95, and 0.99). </plain></SENT>
</text></p></caption><graphic xlink:href="syu031f2"/></fig></SecTag><sec><title><text><SENT sid="111" pm="."><plain>Calculating the required number of GARLI search replicates </plain></SENT>
</text></title><p><text><SENT sid="112" pm="."><plain>Our post-processing routines for a best tree search include the calculation of the number of search replicates necessary to guarantee a particular probability (e.g., 0.95) of recovering the tree topology with the highest observed likelihood score (Regier et al. </plain></SENT>
<SENT sid="113" pm="."><plain>2009). </plain></SENT>
<SENT sid="114" pm="."><plain>This statistic, based on properties of the binomial distribution, is calculated using the number of replicates that find the same best topology (x), where “same topology” is defined as having symmetric distance from the best topology equal to zero. </plain></SENT>
</text></p><p><text><SENT sid="115" pm="."><plain>For example, if the topology of the best tree out of 100 is unique among all topologies found (x = 1), then 298 replicates are required in order to recover the best topology with a probability of at least 0.95 (Fig. 3). </plain></SENT>
<SENT sid="116" pm="."><plain>Of course, it is entirely possible that upon running 298 replicates, the statistical estimate would be revised upwards; e.g., if the topology of the best tree were still unique among the set of topologies, then yet more replicates would be required. </plain></SENT>
</text></p><SecTag type="FIG"><fig id="F3" position="float"><label>F<sc>igure</sc> 3.</label><caption><p><text><SENT sid="117" pm="."><plain>Relationship between the number of search replicates (out of 100) returning the same topology as that of the best tree found and the estimated number of search replicates necessary to guarantee a particular probability of recovering that topology. </plain></SENT>
<SENT sid="118" pm="."><plain>Estimates are given at three probabilities (0.90, 0.95, 0.99). </plain></SENT>
</text></p></caption><graphic xlink:href="syu031f3"/></fig></SecTag><p><text><SENT sid="119" pm="."><plain>This statistical estimate of the number of search replicates required to guarantee a particular probability of obtaining the best tree found is intended to inform users about the joint behavior of their data and the garli search algorithm, and consequently how many search replicates they should perform. </plain></SENT>
<SENT sid="120" pm="."><plain>This introduces an objective decision process into the analysis design that eliminates guesswork and the need to evaluate intermediate output, thus saving investigator time and improving analytical results. </plain></SENT>
<SENT sid="121" pm="."><plain>It also reduces waste of grid resources and energy by suggesting that the user run only the number of replicates needed. </plain></SENT>
</text></p><p><text><SENT sid="122" pm="."><plain>Eventually, we intend to have the system automatically and adaptively run the appropriate number of search replicates on behalf of the user. </plain></SENT>
<SENT sid="123" pm="."><plain>It may also be possible to do something similar for bootstrap replicates, perhaps based on a desired level of precision (Fig. 2) or other criteria (Pattengale et al. </plain></SENT>
<SENT sid="124" pm="."><plain>2010). </plain></SENT>
</text></p></sec></sec></sec><sec><title><text><SENT sid="125" pm="."><plain>System Performance </plain></SENT>
</text></title><p><text><SENT sid="126" pm="."><plain>The performance of any distributed computing system depends on how efficiently its resources are utilized. </plain></SENT>
<SENT sid="127" pm="."><plain>We have implemented a number of scheduling optimizations that enable efficient use of our grid computing resources (Bazinet 2009). </plain></SENT>
<SENT sid="128" pm="."><plain>These include a round-robin scheduling algorithm to distribute load evenly among resources; a scheme for benchmarking resources and prioritizing job assignments so that faster resources receive jobs before slower resources; use of predicted job runtime to ensure that long-running jobs are placed on resources where they are unlikely to be interrupted; and a mechanism for combining many short-running jobs into a single job with an “optimal” aggregate runtime to maximize system throughput. </plain></SENT>
<SENT sid="129" pm="."><plain>These last two features depend on a framework we developed for garli runtime prediction using random forests (Bazinet and Cummings 2011), a machine learning method. </plain></SENT>
<SENT sid="130" pm="."><plain>We have improved this framework so that the runtime prediction model is continuously updated as new jobs are run. </plain></SENT>
<SENT sid="131" pm="."><plain>In supplemental material (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.d7639">http://dx.doi.org/10.5061/dryad.d7639</ext-link>) we describe two system performance improvements in some detail: use of optimal-length jobs for grid computing, and automatic measurement of resource throughput. </plain></SENT>
</text></p><p><text><SENT sid="132" pm="."><plain>It is important to keep in mind that our grid system is designed for high-throughput computing rather than high-performance computing. </plain></SENT>
<SENT sid="133" pm="."><plain>As a result, while any one analysis might run more quickly on a dedicated high-performance platform, the system described here allows many such analyses to run concurrently and still complete in a relatively modest amount of time (Fig. 4). </plain></SENT>
<SENT sid="134" pm="."><plain>In addition, use of a high-performance system may not necessarily yield decreased time to results once allocation processes, system availability, queue waiting times, scheduling policies, and other considerations commonly associated with the use of high-performance resources are factored in. </plain></SENT>
<SENT sid="135" pm="."><plain>The high-throughput computing gateway at molecularevolution.org is well matched to the requirements of many typical phylogenetic analyses, and it has already proven useful to many researchers conducting maximum likelihood phylogenetic analyses using garli 2.0. </plain></SENT>
</text></p><SecTag type="FIG"><fig id="F4" position="float"><label>F<sc>igure</sc> 4.</label><caption><p><text><SENT sid="136" pm="."><plain>Completion times of 719 analyses submitted to the garli web service for a recent six month period (2013-07-23 to 2014-01-23). </plain></SENT>
<SENT sid="137" pm="."><plain>Despite great variation in analysis parameters (e.g., data matrix size, substitution model used, number of replicates requested), ≈97% of analyses were completed in less than 24 hours. </plain></SENT>
</text></p></caption><graphic xlink:href="syu031f4"/></fig></SecTag></sec><SecTag type="SUPPL"><sec><title><text><SENT sid="138" pm="."><plain>Supplementary material </plain></SENT>
</text></title><p><text><SENT sid="139" pm="."><plain>Data available from the Dryad Digital Repository: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.d7639">http://dx.doi.org/10.5061/dryad.d7639</ext-link>. </plain></SENT>
</text></p></sec></SecTag><SecTag type="ACK_FUND"><sec><title><text><SENT sid="140" pm="."><plain>Funding </plain></SENT>
</text></title><p><text4fund><text><SENT sid="141" pm="."><plain>This work was supported by the National Science Foundation (DBI-0755048). </plain></SENT>
</text></text4fund></p></sec></SecTag></body><back><SecTag type="ACK_FUND"><ack><title>A<sc>cknowledgments</sc></title><p><text4fund><text><SENT sid="142" pm="."><plain>We thank Barry Dutton, Yevgeny Deviatov, and Derrick Hinkle for their efforts developing various aspects of the grid system and the garli web service; Charles Mitter for developing the statistical determination of the number of required garli search replicates; and Mike Landavere, Christopher Camacho, Ahmed El-Haggan, Wasay Taha Mohammed Abdul, Patrick Beach, Matthew Kweskin, Kevin Hildebrand, and Fritz McCall for connecting and administering grid system resources. </plain></SENT>
<SENT sid="143" pm="."><plain>We also thank the associate editor and one anonymous reviewer for their helpful suggestions. </plain></SENT>
</text></text4fund></p></ack></SecTag><SecTag type="REF"><ref-list><title>R<sc>eferences</sc></title><ref id="B1"><text><SENT sid="144" pm="."><plain>AndersonD.P.BOINC: A system for public-resource computing and storageProceedings of the 5th IEEE/ACM International Workshop on Grid Computing GRID '04 IEEE Computer Society2004Washington, DC, USA410 </plain></SENT>
</text></ref><ref id="B2"><text><SENT sid="145" pm="."><plain>BazinetA.L.The Lattice Project: A Multi-model Grid Computing System2009College ParkUniversity of MarylandMaster's thesis </plain></SENT>
</text></ref><ref id="B3"><text><SENT sid="146" pm="."><plain>BazinetA.L.CummingsM P.Computing the tree of life: Leveraging the power of desktop and service grids2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and PhD Forum201118961902 </plain></SENT>
</text></ref><ref id="B4"><text><SENT sid="147" pm="?"><plain>BazinetA.L.CummingsM.P.MitterK.T.MitterC.W.Can RNA-Seq resolve the rapid radiation of advanced moths and butterflies (Hexapoda: Lepidoptera: Apoditrysia)? </plain></SENT>
<SENT sid="148" pm="."><plain>An exploratory studyPLoS ONE20138e8261524324810 </plain></SENT>
</text></ref><ref id="B5"><text><SENT sid="149" pm="."><plain>CummingsM.HuskampJ.Grid computingEDUCAUSE Review200540116117 </plain></SENT>
</text></ref><ref id="B6"><text><SENT sid="150" pm="."><plain>FosterI.KesselmanC.FosterI.KesselmanC.Globus: a toolkit-based grid architectureThe grid: blueprint for a new computing infrastructure Morgan-Kaufmann1999259278 </plain></SENT>
</text></ref><ref id="B7"><text><SENT sid="151" pm="."><plain>HedgesS.B.The number of replications needed for accurate estimation of the bootstrap P value in phylogenetic studiesMol. </plain></SENT>
<SENT sid="152" pm="."><plain>Biol. </plain></SENT>
<SENT sid="153" pm="."><plain>Evol.1992936691560769 </plain></SENT>
</text></ref><ref id="B8"><text><SENT sid="154" pm="."><plain>KawaharaA.OhshimaI.KawakitaA.RegierJ.MitterC.CummingsM.DavisD.WagnerD.De PrinisJ.Lopez-VaamondeC.Increased gene sampling provides stronger support for higher-level groups within gracillariid leaf mining moths and relatives (Lepidoptera: Gracillariidae)BMC Evol. </plain></SENT>
<SENT sid="155" pm="."><plain>Biol.20111118221702958 </plain></SENT>
</text></ref><ref id="B9"><text><SENT sid="156" pm="."><plain>KumarS.SkjaevelandA.OrrR.J.S.EngerP.RudenT.MevikB.-H.BurkiF.BotnenA.Shalchian-TabriziK.AIR: a batch-oriented web program package for construction of supermatrices ready for phylogenomic analysesBMC Bioinformatics20091035719863793 </plain></SENT>
</text></ref><ref id="B10"><text><SENT sid="157" pm="."><plain>LewisP.O.NCL: a C +  +  class library for interpreting data files in NEXUS formatBioinformatics2003192330233114630669 </plain></SENT>
</text></ref><ref id="B11"><text><SENT sid="158" pm="."><plain>LitzkowM.LivnyM.MutkaM.Condor–a hunter of idle workstationsDistributed Computing Systems, 1988., 8th International Conference on1988104111 </plain></SENT>
</text></ref><ref id="B12"><text><SENT sid="159" pm="."><plain>MillerM.PfeifferW.SchwartzT.Creating the CIPRES science gateway for inference of large phylogenetic treesGateway Computing Environments Workshop (GCE), 2010201018 </plain></SENT>
</text></ref><ref id="B13"><text><SENT sid="160" pm="."><plain>MyersD.CummingsM.Necessity is the mother of invention: a simple grid computing system using commodity toolsJ. </plain></SENT>
<SENT sid="161" pm="."><plain>Parallel Distr. </plain></SENT>
<SENT sid="162" pm="."><plain>Com.200363578589 </plain></SENT>
</text></ref><ref id="B14"><text><SENT sid="163" pm="."><plain>NéronB.MénagerH.MaufraisC.JolyN.MaupetitJ.LetortS.CarrereS.TufferyP.LetondalC.Mobyle: a new full web bioinformatics frameworkBioinformatics20092530051119689959 </plain></SENT>
</text></ref><ref id="B15"><text><SENT sid="164" pm="."><plain>PattengaleN.D.AlipourM.Bininda-EmondsO.R.P.MoretB.M.E.StamatakisA.How many bootstrap replicates are necessary?J. </plain></SENT>
<SENT sid="165" pm="."><plain>Comput. </plain></SENT>
<SENT sid="166" pm="."><plain>Biol.2010173375420377449 </plain></SENT>
</text></ref><ref id="B16"><text><SENT sid="167" pm="."><plain>RaghavanB.MaJ.The energy and emergy of the InternetHotNets20119 </plain></SENT>
</text></ref><ref id="B17"><text><SENT sid="168" pm="."><plain>RegierJ.C.MitterC.ZwickA.BazinetA.L.CummingsM.P.KawaharaA.Y.SohnJ.-C.ZwicklD.J.ChoS.DavisD.R.BaixerasJ.BrownJ.ParrC.WellerS.LeesD.C.MitterK.T.A large-scale, higher-level, molecular phylogenetic study of the insect order Lepidoptera (moths and butterflies)PLoS ONE20138e5856823554903 </plain></SENT>
</text></ref><ref id="B18"><text><SENT sid="169" pm="."><plain>RegierJ.C.ZwickA.CummingsM.P.KawaharaA.Y.ChoS.WellerS.RoeA.BaixerasJ.BrownJ.W.ParrC.DavisD.R.EpsteinM.HallwachsW.HausmannA.JanzenD.H.KitchingI.J.SolisM.A.YenS.-H.BazinetA.L.MitterC.Toward reconstructing the evolution of advanced moths and butterflies (Lepidoptera: Ditrysia): an initial molecular studyBMC Evol. </plain></SENT>
<SENT sid="170" pm="."><plain>Biol.2009928019954545 </plain></SENT>
</text></ref><ref id="B19"><text><SENT sid="171" pm="."><plain>RobinsonD.R.FouldsL.R.Comparison of phylogenetic treesMath. </plain></SENT>
<SENT sid="172" pm="."><plain>Biosci.198153131147 </plain></SENT>
</text></ref><ref id="B20"><text><SENT sid="173" pm="."><plain>SánchezR.SerraF.TárragaJ.MedinaI.CarbonellJ.PulidoL.de MaríaA.Capella-GutíerrezS.Huerta-CepasJ.GabaldónT.DopazoJ.DopazoH.Phylemon 2.0: a suite of web-tools for molecular evolution, phylogenetics, phylogenomics and hypotheses testingNucleic Acids Res201139W470W47421646336 </plain></SENT>
</text></ref><ref id="B21"><text><SENT sid="174" pm="."><plain>SohnJ.-C.RegierJ.C.MitterC.DavisD.LandryJ.-F.ZwickA.CummingsM.P.A molecular phylogeny for Yponomeutoidea (Insecta, Lepidoptera, Ditrysia) and its implications for classification, biogeography and the evolution of host plant usePLoS ONE20138e5506623383061 </plain></SENT>
</text></ref><ref id="B22"><text><SENT sid="175" pm="."><plain>SukumaranJ.HolderM.T.DendroPy: a Python library for phylogenetic computingBioinformatics2010261569157120421198 </plain></SENT>
</text></ref><ref id="B23"><text><SENT sid="176" pm="."><plain>ZwicklD.J.Genetic algorithm approaches for the phylogenetic analysis of large biological sequence datasets under the maximum likelihood criterion2006The University of Texas at AustinPh.D. thesis </plain></SENT>
</text></ref><ref id="B24"><text><SENT sid="177" pm="."><plain>Zwickl D.J. </plain></SENT>
<SENT sid="178" pm="."><plain>2011. </plain></SENT>
<SENT sid="179" pm="."><plain>GARLI 2.0 <ext-link ext-link-type="uri" xlink:href="https://www.nescent.org/wg_garli/main_page">https://www.nescent.org/wg_garli/main_page</ext-link>. </plain></SENT>
</text></ref></ref-list></SecTag></back></article>
