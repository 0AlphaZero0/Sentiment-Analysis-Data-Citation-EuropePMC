<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id><journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id><journal-title-group><journal-title>BMC Bioinformatics</journal-title></journal-title-group><issn pub-type="epub">1471-2105</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">5249011</article-id><article-id pub-id-type="publisher-id">1308</article-id><article-id pub-id-type="doi">10.1186/s12859-016-1308-y</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Spectral consensus strategy for accurate reconstruction of large biological networks</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Affeldt</surname><given-names>S&#233;verine</given-names></name><address><email>s.affeldt@ican-institute.org</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Sokolovska</surname><given-names>Nataliya</given-names></name><address><email>nataliya.sokolovska@upmc.fr</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Prifti</surname><given-names>Edi</given-names></name><address><email>e.prifti@ican-institute.org</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Zucker</surname><given-names>Jean-Daniel</given-names></name><address><email>jean-daniel.zucker@ird.fr</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2150 9058</institution-id><institution-id institution-id-type="GRID">grid.411439.a</institution-id><institution>Integromics, Institute of Cardiometabolism and Nutrition, ICAN, Assistance Publique H&#244;pitaux de Paris, </institution><institution>Piti&#233;-Salp&#234;tri&#232;re Hospital, </institution></institution-wrap>Paris, 75013 France </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 1955 3500</institution-id><institution-id institution-id-type="GRID">grid.5805.8</institution-id><institution>Sorbonne Universit&#233;s, </institution><institution>UPMC University Paris 6, UMR S U1166 NutriOmics Team, </institution></institution-wrap>Paris, 75013 France </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000000121866389</institution-id><institution-id institution-id-type="GRID">grid.7429.8</institution-id><institution>UMR S U1166 Nutriomics Team, </institution><institution>INSERM, </institution></institution-wrap>Paris, 75013 France </aff><aff id="Aff4"><label>4</label>IRD, UMI 209, UMMISCO, IRD France Nord, Bondy, F-93143 France </aff></contrib-group><pub-date pub-type="epub"><day>13</day><month>12</month><year>2016</year></pub-date><pub-date pub-type="pmc-release"><day>13</day><month>12</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>17</volume><issue>Suppl 16</issue><issue-sponsor>Publication of this supplement has not been supported by sponsorship. Information about the source of funding for publication charges can be found in the individual articles. The articles have undergone the journal's standard peer review process for supplements. The Supplement Editors declare that they have no competing interests.</issue-sponsor><elocation-id>493</elocation-id><permissions><copyright-statement>&#169; The Author(s) 2016</copyright-statement><license license-type="OpenAccess"><license-p>
<bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p>The last decades witnessed an explosion of large-scale biological datasets whose analyses require the continuous development of innovative algorithms. Many of these high-dimensional datasets are related to large biological networks with few or no experimentally proven interactions. A striking example lies in the recent gut bacterial studies that provided researchers with a plethora of information sources. Despite a deeper knowledge of microbiome composition, inferring bacterial interactions remains a critical step that encounters significant issues, due in particular to high-dimensional settings, unknown gut bacterial taxa and unavoidable noise in sparse datasets. Such data type make any a priori choice of a learning method particularly difficult and urge the need for the development of new scalable approaches.</p></sec><sec><title>Results</title><p>We propose a consensus method based on spectral decomposition, named <italic>Spectral Consensus Strategy</italic>, to reconstruct large networks from high-dimensional datasets. This novel unsupervised approach can be applied to a broad range of biological networks and the associated spectral framework provides scalability to diverse reconstruction methods. The results obtained on benchmark datasets demonstrate the interest of our approach for high-dimensional cases. As a suitable example, we considered the human gut microbiome co-presence network. For this application, our method successfully retrieves biologically relevant relationships and gives new insights into the topology of this complex ecosystem.</p></sec><sec><title>Conclusions</title><p>The <italic>Spectral Consensus Strategy</italic> improves prediction precision and allows scalability of various reconstruction methods to large networks. The integration of multiple reconstruction algorithms turns our approach into a robust learning method. All together, this strategy increases the confidence of predicted interactions from high-dimensional datasets without demanding computations.</p></sec><sec><title>Electronic supplementary material</title><p>The online version of this article (doi:10.1186/s12859-016-1308-y) contains supplementary material, which is available to authorized users.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Network reconstruction</kwd><kwd>Community-based method</kwd><kwd>Spectral theory</kwd><kwd>High-dimensional data</kwd><kwd>Microbiota</kwd></kwd-group><conference><conf-name>The 10th International Workshop on Machine Learing in Systems Biology (MLSB)</conf-name><conf-loc>Den Haag, The Netherlands</conf-loc><conf-date>3-4 September 2016</conf-date></conference><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#169; The Author(s) 2016</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p>Discovering complex interactions is a long-standing problem which led over the past years to the development of many network reconstruction methods that exhibit competitive results on various types of data. As successfully demonstrated, networks are invaluable tools to comprehensively relate biological variables [<xref ref-type="bibr" rid="CR1">1</xref>&#8211;<xref ref-type="bibr" rid="CR3">3</xref>] and possibly gain insights into their direct causal relationships [<xref ref-type="bibr" rid="CR4">4</xref>]. Interestingly, recent studies have shown that the available approaches would not generally perform optimally across all dataset types and the integration of diverse inference methods can provide an improved robust performance [<xref ref-type="bibr" rid="CR5">5</xref>&#8211;<xref ref-type="bibr" rid="CR8">8</xref>]. However, several well-known and widely used algorithms cannot directly process high-dimensional data or actually perform better on small networks. Bringing these methods within a lower dimensional space would enable researchers to fully benefit from their strengths under high-dimensional settings, and more interestingly, to integrate their outcome in community-based predictions.</p><p>We propose a <italic>consensus</italic> approach, named <italic>Spectral Consensus Strategy</italic> (SCS), to reconstruct complex biological networks from high-dimensional datasets. This method provides scalability to various reconstruction methods and can be applied to a broad range of complex biological networks. Our approach unfolds in three parts. First, it relies on a spectral framework to identify sets of significantly related variables. Specifically, the subset selection uses the magnitude of the normalized Laplacian eigenvector elements. These subsets are then considered in a second phase for multiple parallel <italic>local</italic> reconstructions from which global effects are inferred. By enabling each reconstruction method to locally <italic>avoid</italic> high-dimensional settings, this second phase improves individual prediction accuracy and scalability. In the last phase, the individual reconstructions that benefited from the spectral embedding are integrated in a consensus network.</p><p>All together, this strategy provides robust and accurate reconstructions from high-dimensional observational data for which no suitable learning approach is known beforehand, as for instance frequently encountered in metagenomics. To our knowledge, our contribution is the first attempt to introduce a consensus network reconstruction approach based on a spectral framework.</p><sec id="Sec2"><title>Network reconstruction background</title><p>Generally speaking, network learning algorithms can be divided into two categories: <italic>constraint-based</italic> and <italic>score-based</italic> approaches. The constraint-based methods ascertain (conditional) independence relationships from statistical tests [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>] to learn structural constraints in causal graphs. These approaches are highly efficient on sparse networks and are guaranteed to learn the Markov equivalent class of the underlying graphical model if the <italic>exact</italic> list of conditional independence relationships is given. However, constraint-based methods have also proved to be very sensitive to sampling noise from finite datasets. Alternatively, score-based methods identify the model that best fits the data through the maximization of a score function over the space of (ideally all) possible Bayesian networks [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR12">12</xref>]. To learn the networks in reasonable time, the search procedure usually follows a heuristic algorithm that identifies a local optimum. More recently, several <italic>mutual information-based</italic> approaches have been proposed to infer direct relationships from noisy observational datasets containing few samples [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Nevertheless, as demonstrated by the growing number of <italic>hybrid</italic> approaches [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR13">13</xref>&#8211;<xref ref-type="bibr" rid="CR15">15</xref>], the wide range of high-dimensional data is still challenging state-of-the-art methods, both in terms of accuracy, or time and memory consumption.</p></sec><sec id="Sec3"><title>Spectral methods background</title><p>Spectral theory has provided a number of approaches to uncover dataset structure. A well-known result is the ability to optimally bi-partition a graph based on the second eigenvector of the normalized Laplacian matrix, also known as <italic>algebraic connectivity</italic> or <italic>Fiedler vector</italic> [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. Following this idea, recursive <italic>two-way</italic> cut methods [<xref ref-type="bibr" rid="CR18">18</xref>&#8211;<xref ref-type="bibr" rid="CR20">20</xref>] that rely solely on the second eigenvector, and <italic>k-way</italic> cut approaches [<xref ref-type="bibr" rid="CR21">21</xref>&#8211;<xref ref-type="bibr" rid="CR26">26</xref>] that are based on truncated eigenvector basis, have been successfully applied to dimensionality reduction or clustering problems. Specifically, the truncated eigenvector basis provides a new representation that amplifies the similarity between closely related variables while reducing the affinity of unrelated variables [<xref ref-type="bibr" rid="CR26">26</xref>&#8211;<xref ref-type="bibr" rid="CR29">29</xref>]. Many biological systems are usually composed of overlapping sub-units that involve functionally related features, such as found in metabolic or gene regulatory networks. Hence, learning large biological networks from multiple local reconstructions appears to be a reasonable procedure as much as it follows the natural dataset structure. Spectral methods hold great potential for guiding learning algorithms that perform better on small graphs towards improving inference of large networks.</p></sec><sec id="Sec4"><title>Consensus reconstruction approaches</title><p>The idea of consensus or <italic>ensemble</italic> learning is recently gaining interest in the field. An example is given in [<xref ref-type="bibr" rid="CR30">30</xref>] where the yeast metabolic network was reconstructed based on a complex consensus procedure that involved a number of statistical methods and an important amount of prior knowledge. As previously demonstrated [<xref ref-type="bibr" rid="CR31">31</xref>], consensus approaches can be efficiently exploited to reconstruct Bayesian networks and provide robust models from biological data. A consensus method that mainly rely on significance tests is proposed in [<xref ref-type="bibr" rid="CR32">32</xref>] to learn dependencies between gene regulatory factors in the human frontal lobe, resulting in a high-confidence model. The community structure in complex networks can also be revealed by consensus clustering as reported in [<xref ref-type="bibr" rid="CR33">33</xref>], where a stable partitioning approach based on several stochastic method results is proposed. Marbach et al. [<xref ref-type="bibr" rid="CR5">5</xref>] motivates the development of consensus methods by demonstrating the benefits of combining complementary inference approaches. Specifically, they have evaluated the performance of diverse learning algorithms and shown that their combination performs robustly across various datasets while providing as good or better results than individual methods.</p></sec><sec id="Sec5"><title>The complex gut microbiome system</title><p>The human gut hosts a high density of commensal bacteria whose collective genome, also known as <italic>metagenome</italic>, exceeds more than a hundred times the size of the human genome [<xref ref-type="bibr" rid="CR34">34</xref>]. This rich ecosystem provides the host with vital functions that affect nutritional efficiency and overall health [<xref ref-type="bibr" rid="CR35">35</xref>, <xref ref-type="bibr" rid="CR36">36</xref>]. Over the past few years, the role of gut microbiota in human health has received unprecedented attention [<xref ref-type="bibr" rid="CR37">37</xref>]. In particular, several chronic diseases such as obesity [<xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>], inflammatory bowel disease [<xref ref-type="bibr" rid="CR40">40</xref>, <xref ref-type="bibr" rid="CR41">41</xref>], liver cirrhosis [<xref ref-type="bibr" rid="CR42">42</xref>, <xref ref-type="bibr" rid="CR43">43</xref>], type-I [<xref ref-type="bibr" rid="CR44">44</xref>], and type-II diabetes [<xref ref-type="bibr" rid="CR45">45</xref>, <xref ref-type="bibr" rid="CR46">46</xref>] have been associated with gut microbiota. For a long time, the composition of human gut microbial ecosystem was unknown, especially due to the large number of non-cultivable species. The recent availability of metagenomic data along with different binning techniques allows now to obtain a better picture of the taxonomical groups that inhabit the gut microbiome [<xref ref-type="bibr" rid="CR47">47</xref>]. These species are organized in complex ecological networks and can be involved in different types of interactions such as competition or mutualism [<xref ref-type="bibr" rid="CR48">48</xref>]. Yet, mapping these relationships with high confidence remains a complicated task for multiple reasons. First of all, as many species are usually absent from one sample to another, metagenomic datasets are very sparse. This sparsity adds on technical artifacts inherent to the obligate multi-step data processing. Hence, metagenomic data are challenging available reconstruction methods, which may individually yield different topologies for the same set of observations.</p></sec></sec><sec id="Sec6"><title>Methods</title><p>We propose a simple yet highly efficient method called <italic>Spectral Consensus Strategy</italic> (SCS) that simultaneously embeds multiple discovery algorithms within a spectral framework for the reconstruction of large graphical model. The strength of the SCS method hinges on two key points that are (i) the accuracy improvement of each individual learning algorithm and (ii) the combination of predictions from complementary reconstruction methods. Specifically, sets of <italic>path-related</italic> variables are first identified based on the magnitude of the graph Laplacian eigenvector elements (Fig. <xref rid="Fig1" ref-type="fig">1</xref>,<xref rid="Fig1" ref-type="fig">a</xref>), then multiple parallel local reconstructions are performed using different learning methods (Fig. <xref rid="Fig1" ref-type="fig">1</xref>,<xref rid="Fig1" ref-type="fig">b</xref>) and lastly a consensus network is built on the previous multiple outcomes (Fig. <xref rid="Fig1" ref-type="fig">1</xref>,<xref rid="Fig1" ref-type="fig">c</xref>).
<fig id="Fig1"><label>Fig. 1</label><caption><p>Overview of the Spectral Consensus Strategy (SCS). The SCS method unfolds in three parts. <bold>a</bold> The SCS-<italic>spectral</italic> phase identifies sets of <italic>path-related</italic> variables based on the magnitude of the graph Laplacian eigenvector elements. <bold>b</bold> The SCS-<italic>learn</italic> phase performs multiple parallel <italic>local</italic> reconstructions using different learning methods. <bold>c</bold> The SCS-<italic>consensus</italic> phase provides a consensus network built on the individual outcomes from the SCS-<italic>learn</italic> step</p></caption><graphic xlink:href="12859_2016_1308_Fig1_HTML" id="MO1"/></fig>
</p><p>In the following, we provide theoretical support to the uncovering of connected variable subsets from the first phase of the SCS approach (SCS-<italic>spectral</italic> step, Fig. <xref rid="Fig1" ref-type="fig">1</xref>,<xref rid="Fig1" ref-type="fig">a</xref>). In particular, we demonstrate that subsets of <italic>path-related vertices</italic> can be directly retrieved from the magnitude and sign of individual eigenvector elements. These subsets, which correspond to possibly overlapping dense subgraphs, are given as input to the second phase of the SCS approach (SCS-<italic>learn</italic> step, Fig. <xref rid="Fig1" ref-type="fig">1</xref>,<xref rid="Fig1" ref-type="fig">b</xref>). We finally detail the whole <italic>Spectral Consensus Strategy</italic>.</p><sec id="Sec7"><title>Normalized Laplacian eigenvectors</title><p>We consider the <italic>random-walk</italic> normalized Laplacian matrix <italic>L</italic>
<sub><italic>rw</italic></sub> as it entails the random walk dynamics from one vertex to another in the corresponding graph <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}$\end{document}</tex-math><mml:math id="M2"><mml:mi mathvariant="script">G</mml:mi></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq1.gif"/></alternatives></inline-formula>. This matrix is defined as <italic>L</italic>
<sub><italic>rw</italic></sub>=<italic>I</italic>&#8722;<italic>D</italic>
<sup>&#8722;1</sup>
<italic>W</italic>, where <italic>I</italic> is the identity matrix, <italic>W</italic>=(<italic>w</italic>
<sub><italic>ij</italic></sub>) is a weight matrix over all pairs of variables and <italic>D</italic> the diagonal degree matrix with <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$d_{ii}=\sum _{j}w_{ij}$\end{document}</tex-math><mml:math id="M4"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ii</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq2.gif"/></alternatives></inline-formula>.</p><sec id="Sec8"><title>Community membership indicators</title><p>As already established [<xref ref-type="bibr" rid="CR49">49</xref>], the null eigenvalues of the graph Laplacian matrices are associated with the number of <italic>connected components</italic>. A subset of vertices <italic>A</italic>
<sub><italic>k</italic></sub>&#8834;<italic>V</italic> is a connected component if (i) all intermediate points that lie on a path between two vertices of <italic>A</italic>
<sub><italic>k</italic></sub> also belong to <italic>A</italic>
<sub><italic>k</italic></sub> and (ii) there is no connection between the vertices of <italic>A</italic>
<sub><italic>k</italic></sub> and its complementary subset <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\overline {A_{k}}$\end{document}</tex-math><mml:math id="M6"><mml:mover accent="false"><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">&#175;</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq3.gif"/></alternatives></inline-formula> (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Proposition 1). Interestingly, for the case of finding <italic>k</italic>&gt;2 clusters, the first <italic>k</italic> eigenvectors of the normalized Laplacian matrix <italic>L</italic>
<sub><italic>rw</italic></sub> minimize the <italic>normalized cut</italic> (<italic>N</italic>
<italic>C</italic>
<italic>u</italic>
<italic>t</italic>) criterion of the relaxed problem [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR50">50</xref>], 
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \mathit{Ncut}(A_{1},\ldots,A_{k})=\frac{1}{2} \sum_{i=1}^{k} \frac{W(A_{i},\overline{A_{i}})}{vol(A_{i})}  $$ \end{document}</tex-math><mml:math id="M8"><mml:mi mathvariant="italic">Ncut</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mi>W</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mover accent="false"><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">&#175;</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">vol</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="12859_2016_1308_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>
</p><p>where <inline-formula id="IEq4"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$W(A,B)=\sum _{\substack {i \in A \\ j \in B}} \omega _{ij}$\end{document}</tex-math><mml:math id="M10"><mml:mi>W</mml:mi><mml:mo>(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mtable rowspacing="0"><mml:mtr><mml:mtd><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:mi>A</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>&#8712;</mml:mo><mml:mi>B</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>&#969;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq4.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq5"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$vol(A_{i})=\sum _{j \in A_{i}} d_{j}$\end{document}</tex-math><mml:math id="M12"><mml:mtext mathvariant="italic">vol</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq5.gif"/></alternatives></inline-formula>.</p><p>In a nutshell, the solution of the relaxed <italic>N</italic>
<italic>c</italic>
<italic>u</italic>
<italic>t</italic> minimization problem consists of the orthonormal matrix <inline-formula id="IEq6"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$H \in \mathbb {R}^{p \times k}$\end{document}</tex-math><mml:math id="M14"><mml:mi>H</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq6.gif"/></alternatives></inline-formula> whose columns are the first <italic>k</italic> eigenvectors of the normalized Laplacian eigenvector matrix <italic>U</italic>, associated with the first <italic>k</italic> smallest eigenvalues.</p><p>When the between-cluster similarity is exactly 0, these eigenvectors are the indicator vectors {<italic>h</italic>
<sub><italic>j</italic></sub>}<sub><italic>j</italic>&#8712;[1,<italic>k</italic>]</sub> (<inline-formula id="IEq7"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$h_{j} \in \mathbb {R}^{p}$\end{document}</tex-math><mml:math id="M16"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#8712;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq7.gif"/></alternatives></inline-formula> and <inline-formula id="IEq8"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}${h_{j}^{i}}=1$\end{document}</tex-math><mml:math id="M18"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq8.gif"/></alternatives></inline-formula> if <italic>x</italic>
<sub><italic>i</italic></sub>&#8712;<italic>A</italic>
<sub><italic>j</italic></sub>, otherwise 0) of the <italic>k</italic> connected components [<xref ref-type="bibr" rid="CR50">50</xref>]. In practice, the distribution of the data points in distinct clusters is hardly encountered, and one should expect the between-cluster similarity to be greater than 0. Yet, under <italic>nearly ideal</italic> conditions the eigenvectors are still close to the indicator vectors, and the elements magnitude and sign of each eigenvector contain information on vertices membership <italic>strength</italic> [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR50">50</xref>, <xref ref-type="bibr" rid="CR51">51</xref>].</p></sec><sec id="Sec9"><title>Path-related vertices subsets</title><p>Beyond the membership indication, the Laplacian matrix eigenvector elements also convey path-relationship information. In the following we assume that <italic>v</italic>
<sub><italic>k</italic></sub> is the <italic>k</italic>-th eigenvector of the normalized Laplacian matrix associated with the connected component <italic>A</italic>
<sub><italic>k</italic></sub>. Under ideal conditions, <italic>x</italic>
<sub><italic>i</italic></sub>&#8712;<italic>A</italic>
<sub><italic>k</italic></sub>&#8658;<italic>v</italic>
<sub><italic>k</italic></sub>(<italic>i</italic>)=1, otherwise <italic>v</italic>
<sub><italic>k</italic></sub>(<italic>i</italic>)=0 [<xref ref-type="bibr" rid="CR50">50</xref>]. In addition, we demonstrate that similar elements of a given eigenvector (|<italic>v</italic>
<sub><italic>k</italic></sub>(<italic>i</italic>)&#8722;<italic>v</italic>
<sub><italic>k</italic></sub>(<italic>j</italic>)|=0) indicate path-related variables (<italic>x</italic>
<sub><italic>j</italic></sub> is path connected with <italic>x</italic>
<sub><italic>i</italic></sub>) based on the Rayleigh quotient [<xref ref-type="bibr" rid="CR52">52</xref>] (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Proposition 2).</p><p>For the case of a <italic>connected</italic> graph <inline-formula id="IEq9"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}$\end{document}</tex-math><mml:math id="M20"><mml:mi mathvariant="script">G</mml:mi></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq9.gif"/></alternatives></inline-formula> (i.e. there is a path between any pair of variables in <inline-formula id="IEq10"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}$\end{document}</tex-math><mml:math id="M22"><mml:mi mathvariant="script">G</mml:mi></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq10.gif"/></alternatives></inline-formula>) Fiedler&#8217;s Nodal Domain theorem (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Theorem 1) indicates that while <italic>x</italic>
<sub><italic>i</italic></sub> and <italic>x</italic>
<sub><italic>j</italic></sub> belong to different clusters <italic>A</italic> and <italic>B</italic>, |<italic>v</italic>
<sub><italic>k</italic></sub>(<italic>i</italic>)&#8722;<italic>v</italic>
<sub><italic>k</italic></sub>(<italic>j</italic>)|&lt;<italic>&#949;</italic> can be found. However, if there exists a subset of vertices <italic>S</italic> at a distance less than a <italic>step</italic>
<italic>&#961;</italic>&#8805;2 from <italic>A</italic> that separates <italic>A</italic> and <italic>B</italic>, then <italic>v</italic>
<sub><italic>k</italic></sub> is such that [<xref ref-type="bibr" rid="CR53">53</xref>] 
<disp-formula id="Equ2"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \left\{\begin{array}{ll} &amp; \text{if}~i \in A, \, \text{then}~v_{k}(i) = 1,\\ &amp; \text{if}~i \in B, \, \text{then}~v_{k}(i) = -1,\\ &amp; \text{if}~i \in S, \, \text{then}~-1 + 2/\rho \leq v_{k}(i) \leq 1 - 2/\rho, \\ &amp; \text{if}~i,j \text{ are adjacent then}~|v_{k}(i)-v_{k}(j)| \leq 2/\rho. \end{array}\right.  $$ \end{document}</tex-math><mml:math id="M24"><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mtext>then</mml:mtext><mml:mspace width="1em"/><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mtext>then</mml:mtext><mml:mspace width="1em"/><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mtext>then</mml:mtext><mml:mspace width="1em"/><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mi>&#961;</mml:mi><mml:mo>&#8804;</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo><mml:mo>&#8804;</mml:mo><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mi>&#961;</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mtext>are adjacent then</mml:mtext><mml:mspace width="1em"/><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo><mml:mo>|</mml:mo><mml:mo>&#8804;</mml:mo><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mi>&#961;.</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2016_1308_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>
</p><p>Taking <italic>&#961;</italic>=2 we obtain the case which is commonly used for separators. Hence, |<italic>v</italic>
<sub><italic>k</italic></sub>(<italic>i</italic>)&#8722;<italic>v</italic>
<sub><italic>k</italic></sub>(<italic>j</italic>)| is a measure of the distance between the vertices <italic>i</italic> and <italic>j</italic> reflecting the <italic>cluster assumption</italic> which stipulates that close data points are expected to lie within the same cluster (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Proposition 3).</p><p>In summary, under ideal conditions, the first <italic>k</italic> eigenvectors of the normalized Laplacian matrix provide indicator vectors of the <italic>k</italic> connected components. In practice, the magnitude and sign of the eigenvector elements contain information on vertex membership <italic>strength</italic> to the corresponding component (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Proposition 1). Furthermore, <italic>path-connected</italic> variables have similar eigenvector elements (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Proposition 2), that are distinct from the element of vertices belonging to a different component (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Proposition 3). Thus, subsets of nodes that correspond to large positive or negative eigenvector elements (retrieved in the SCS-<italic>spectral</italic> step) correspond to dense subgraphs (to be reconstructed in the SCS-<italic>learn</italic> step). These subgraphs associated to large eigenvector elements can be redundantly found in the first eigenvectors [<xref ref-type="bibr" rid="CR54">54</xref>]. However, higher eigenvectors can also be used to identify different subsets of connected nodes, as observed in the context of anomalous graph detection [<xref ref-type="bibr" rid="CR55">55</xref>].</p></sec></sec><sec id="Sec10"><title>The spectral consensus strategy</title><p>This section details the three steps of the SCS approach and provides the algorithms associated with each phase (Fig. <xref rid="Fig1" ref-type="fig">1</xref>).</p><sec id="Sec11"><title>(a) SCS-spectral, identifying graph sub-paths</title><p>The first phase of the SCS approach, called SCS-<italic>spectral</italic>, identifies subsets of vertices that are at a small <italic>walk</italic> distance from each other within the graph <inline-formula id="IEq11"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}$\end{document}</tex-math><mml:math id="M26"><mml:mi mathvariant="script">G</mml:mi></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq11.gif"/></alternatives></inline-formula> (Fig. <xref rid="Fig1" ref-type="fig">1</xref>,<xref rid="Fig1" ref-type="fig">a</xref>). This information is conveyed by the magnitude of the Laplacian eigenvector elements [<xref ref-type="bibr" rid="CR51">51</xref>].</p><p>In the following, the input data matrix is <inline-formula id="IEq12"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbb {R}^{n \times p}$\end{document}</tex-math><mml:math id="M28"><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq12.gif"/></alternatives></inline-formula> with <italic>n</italic> the number of observations and <italic>p</italic> the number of variables. In Algorithm 1, the eigenvectors of the normalized Laplacian matrix <italic>L</italic>
<sub><italic>rw</italic></sub> are computed to identify vertices that lie on common sub-paths (Algorithm 1, lines 4&#8722;5).</p><p>
<graphic xlink:href="12859_2016_1308_Figa_HTML.gif" id="MO2"/>
</p><p>In our consensus approach, we choose the mutual information to model vertex similarity as it provides a general measure of relationship between variables [<xref ref-type="bibr" rid="CR56">56</xref>, <xref ref-type="bibr" rid="CR57">57</xref>]. Moreover, previous studies have shown that information theoretic measures are well suited to study high-dimensional biological data [<xref ref-type="bibr" rid="CR58">58</xref>&#8211;<xref ref-type="bibr" rid="CR60">60</xref>], which was one of our objectives when designing the SCS approach.</p></sec><sec id="Sec12"><title>(b) SCS-learn, high-dimensional spectral embedding</title><p>The second phase of our approach, called SCS-<italic>learn</italic>, relies on the sign and magnitude of the first <italic>k</italic> eigenvector elements to reconstruct possibly overlapping sub-graphs that involve path connected vertices (Fig. <xref rid="Fig1" ref-type="fig">1</xref>,<xref rid="Fig1" ref-type="fig">b</xref>). Specifically, each eigenvector <italic>v</italic>
<sub><italic>k</italic></sub> is associated with two sub-graphs, <inline-formula id="IEq13"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}_{v_{k}}^{m,-}$\end{document}</tex-math><mml:math id="M30"><mml:msubsup><mml:mrow><mml:mi mathvariant="script">G</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mo>&#8722;</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq13.gif"/></alternatives></inline-formula> and <inline-formula id="IEq14"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}_{v_{k}}^{m,+}$\end{document}</tex-math><mml:math id="M32"><mml:msubsup><mml:mrow><mml:mi mathvariant="script">G</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq14.gif"/></alternatives></inline-formula>, that relate the <italic>m</italic> data points corresponding to either the most <italic>negative</italic> or the most <italic>positive</italic> eigenvector elements (Algorithm 2, line 7).</p><p>
<graphic xlink:href="12859_2016_1308_Figb_HTML.gif" id="MO3"/>
</p><p>For clustering purposes, the subspace spanned by the first <italic>k</italic> eigenvectors would normally be preferred to their individual interpretation [<xref ref-type="bibr" rid="CR28">28</xref>]. However the SCS-<italic>learn</italic> step does not aim at partitioning the variables, but rather to learn the whole underlying network based on overlapping sub-graphs. In particular, the non high-dimensional settings (<italic>m</italic>&#8810;<italic>n</italic>) obtained for each local reconstruction <inline-formula id="IEq15"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}_{v_{k}}^{m,\scriptscriptstyle {+/-}}$\end{document}</tex-math><mml:math id="M34"><mml:msubsup><mml:mrow><mml:mi mathvariant="script">G</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mo>+</mml:mo><mml:mo>/</mml:mo><mml:mo>&#8722;</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq15.gif"/></alternatives></inline-formula> restrict the number of <italic>false positive</italic> edges. Alternatively, the overlaps between selected subsets of <italic>m</italic> variables limit the number of <italic>false negative</italic> interactions. At the end of this phase, the edges eventually retained in each individual network <inline-formula id="IEq16"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}_{l}$\end{document}</tex-math><mml:math id="M36"><mml:msub><mml:mrow><mml:mi mathvariant="script">G</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq16.gif"/></alternatives></inline-formula> are those that were learned every time a sub-graph <inline-formula id="IEq17"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}_{v_{k}}^{m,\scriptscriptstyle {+/-}}$\end{document}</tex-math><mml:math id="M38"><mml:msubsup><mml:mrow><mml:mi mathvariant="script">G</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mo>+</mml:mo><mml:mo>/</mml:mo><mml:mo>&#8722;</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq17.gif"/></alternatives></inline-formula> involved the corresponding pair of vertices (Algorithm 2, lines 17&#8722;18). Lastly, whenever the input reconstruction method <inline-formula id="IEq18"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {R}_{l}$\end{document}</tex-math><mml:math id="M40"><mml:msub><mml:mrow><mml:mi mathvariant="script">R</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq18.gif"/></alternatives></inline-formula> provides orientations, a <italic>majority rule</italic> is applied to set the final orientation or resolve possible conflicts over all the inferred orientations for two adjacent vertices (Algorithm 2, line 19). If no majority can be achieved, the edge is set undirected.</p></sec><sec id="Sec13"><title>(c) SCS-consensus, final network</title><p>
<graphic xlink:href="12859_2016_1308_Figc_HTML.gif" id="MO4"/>
</p><p>In this last phase, called SCS-<italic>consensus</italic>, networks inferred by individually embedded reconstruction methods are combined (Fig. <xref rid="Fig1" ref-type="fig">1</xref>,<xref rid="Fig1" ref-type="fig">c</xref>). Specifically, for each learning approach <inline-formula id="IEq19"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {R}_{l}$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mrow><mml:mi mathvariant="script">R</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq19.gif"/></alternatives></inline-formula>, we rank the predicted edges by decreasing strength or confidence (Algorithm 3, lines 4&#8722;6). Then, following the integration procedure proposed in [<xref ref-type="bibr" rid="CR5">5</xref>], an average is computed to provide a consensus rank for the (<italic>x</italic>
<sub><italic>i</italic></sub>,<italic>x</italic>
<sub><italic>j</italic></sub>) edge in the final graph <inline-formula id="IEq20"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}$\end{document}</tex-math><mml:math id="M44"><mml:mi mathvariant="script">G</mml:mi></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq20.gif"/></alternatives></inline-formula> (Algorithm 3, line 8). If an individual reconstruction method gives no edge between (<italic>x</italic>
<sub><italic>i</italic></sub>,<italic>x</italic>
<sub><italic>j</italic></sub>), the pair receives the worst possible rank for this method, i.e. <inline-formula id="IEq21"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$rank^{x_{i}x_{j}}_{\mathcal {G}_{l}}=1$\end{document}</tex-math><mml:math id="M46"><mml:mtext mathvariant="italic">ran</mml:mtext><mml:msubsup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">G</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq21.gif"/></alternatives></inline-formula>. A weighted average over the (sub)set <inline-formula id="IEq22"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\{\mathcal {R}\}_{L'}$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq22.gif"/></alternatives></inline-formula> of learning approaches that predicted orientations is also computed, giving greater weight to upper rank edge orientations (Algorithm 3, lines 9&#8722;12). Lastly, only the <italic>e</italic>
<sub><italic>m</italic><italic>a</italic><italic>x</italic></sub> most significant edges are retained in the consensus network (Algorithm 3, line 15).</p></sec></sec></sec><sec id="Sec14" sec-type="results"><title>Results</title><p>The SCS approach embeds multiple reconstruction methods in a spectral framework to learn possibly oriented interactions from high-dimensional data by (i) combining the edges discovered from overlapping sub-graphs (Fig. <xref rid="Fig1" ref-type="fig">1</xref>, SCS-<italic>learn</italic>, (b)) and (ii) computing a consensus network (Fig. <xref rid="Fig1" ref-type="fig">1</xref>, SCS-<italic>consensus</italic>, (c)). In the following, the reconstructed networks are evaluated for an increasing proportion of eigenvectors (Fig. <xref rid="Fig2" ref-type="fig">2</xref>, horizontal axis). Results are discussed in terms of <italic>Precision</italic> (<italic>T</italic>
<italic>P</italic>/(<italic>F</italic>
<italic>P</italic>+<italic>T</italic>
<italic>P</italic>)), <italic>Recall</italic> (<italic>T</italic>
<italic>P</italic>/(<italic>T</italic>
<italic>P</italic>+<italic>F</italic>
<italic>N</italic>)) and <italic>F-score</italic> (2&#215;<italic>P</italic>
<italic>r</italic>
<italic>e</italic>
<italic>c</italic>&#215;<italic>R</italic>
<italic>e</italic>
<italic>c</italic>/(<italic>P</italic>
<italic>r</italic>
<italic>e</italic>
<italic>c</italic>+<italic>R</italic>
<italic>e</italic>
<italic>c</italic>)) (<italic>F</italic>
<italic>N</italic>,<italic>T</italic>
<italic>P</italic>,<italic>F</italic>
<italic>P</italic>; <italic>false negative</italic>, <italic>true positive</italic> and <italic>false positive</italic> edges resp.). In particular, falsely oriented <italic>T</italic>
<italic>P</italic> edges are considered as <italic>F</italic>
<italic>P</italic>. For these evaluations, a benchmark network of 223 nodes and 338 edges has been considered (ANDES benchmark [<xref ref-type="bibr" rid="CR61">61</xref>, <xref ref-type="bibr" rid="CR62">62</xref>]). This choice was in particular motivated by the fact that each variable of the ANDES benchmark network has exactly two categories, as encountered for metagenomics co-presence or presence-absence data. Besides, the 223 variables of this network enable us to reproduce high-dimensional conditions while evaluating the SCS results against reconstruction performed by each learning approach without the SCS embedding. We also considered a larger benchmark network composed of 1, 041 nodes and 1, 397 edges, MUNIN [<xref ref-type="bibr" rid="CR63">63</xref>], and provide the corresponding results in (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figures S3 and S9). We randomly sampled 5 datasets of sizes 150 and 200 to perform the experiments under high-dimensional conditions for ANDES, and 5 datasets of size 935 for MUNIN. The embedded reconstruction methods are ARACNE [<xref ref-type="bibr" rid="CR1">1</xref>], a mutual information-based approach, 3off2 [<xref ref-type="bibr" rid="CR4">4</xref>], a hybrid method that combines constraint-based and scoring approaches based on multivariate information measures, and a hill-climbing algorithm using the Bayesian Dirichlet equivalent score. We also considered a random classifier in our SCS-<italic>spectral</italic> and SCS-<italic>learn</italic> step evaluations (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figures S4).
<fig id="Fig2"><label>Fig. 2</label><caption><p>SCS-learn and SCS-consensus evaluations for ANDES benchmark network [223 nodes, 338 edges, &#9001;<italic>k</italic>&#9002;=3.03]. <italic>Precision</italic>, <italic>Recall</italic> and <italic>F-score</italic> results for an increasing proportion of eigenvectors (up to 40 <italic>%</italic>), subgraphs of 12 nodes (5 <italic>%</italic> variables) and 150 samples. Scores take misorientations into account. Each point is an average over 5 datasets (results for different subgraph and dataset sizes follow a similar trend, see Additional file <xref rid="MOESM1" ref-type="media">1</xref>). (SCS-learn, top three rows) Three learning algorithms are embedded to reconstruct a network from subgraphs whose vertices are selected from the magnitude of eigenvector elements (SCS-<italic>learn</italic>, red solid line), spectral fuzzy C-means partitioning (<italic>light blue</italic> solid line), spectral K-means clustering (<italic>dark blue</italic> solid line), random subsets (<italic>green</italic> solid line) and recursive bi-partitioning (salmon solid line). Results are compared to scores obtained without spectral or partitioning embedding (<italic>red</italic> dashed line). (SCS-consensus, bottom row) The SCS-<italic>learn</italic> reconstructions are combined in a consensus network (<italic>red</italic> solid line) and compared with individual SCS-<italic>learn</italic> outcomes (<italic>gray</italic> dashed lines). Scores are computed from the top 338 consensus edges (results for different number of consensus edges follow a similar trend, see Additional file <xref rid="MOESM1" ref-type="media">1</xref>)</p></caption><graphic xlink:href="12859_2016_1308_Fig2_HTML" id="MO5"/></fig>
</p><sec id="Sec15"><title>SCS-learn network evaluations</title><p>As previously established [<xref ref-type="bibr" rid="CR5">5</xref>], adding high quality reconstruction methods to a consensus approach significantly improves consensus predictions. We have thus evaluated the accuracy improvement achieved in the SCS-<italic>learn</italic> phase that relies on the SCS-<italic>spectral</italic> step. Specifically, we have compared reconstructions obtained from variable subsets selected with the element magnitude of the first <italic>k</italic> eigenvectors to networks learnt based on variable subsets derived from different partitioning or clustering methods. Alternative subset selections are provided by spectral fuzzy C-means partitioning, spectral K-means clustering and recursive bi-partitioning. Random subset selection is also considered as a mere comparison.</p><p>Evaluations of embedded network reconstructions from subgraphs of <italic>m</italic>=12 nodes using <italic>n</italic>=150 samples (results for different subgraph and dataset sizes follow a similar trend, see Additional file <xref rid="MOESM1" ref-type="media">1</xref>) for the ANDES benchmark are given in Fig. <xref rid="Fig2" ref-type="fig">2</xref> (top three rows). Reconstructions obtained from randomly sampled subsets exhibit a poor <italic>Precision</italic> (green solid line). This highlights that guided local reconstructions improve prediction accuracy. Networks reconstructed from subgraphs that rely on spectral K-means (darkblue solid line) or spectral fuzzy C-means (lightblue solid line) subsets do not provide better <italic>Precision</italic> than the SCS-<italic>learn</italic> method (red solid line) up to 30 eigenvectors (14 <italic>%</italic> of the total number). Although bipartition of the variables (salmon solid line) allows for better <italic>Precision</italic> than the random or spectral clustering, it is still largely outperformed by the SCS-<italic>learn</italic> phase.</p><p>This high <italic>Precision</italic> is at the slight expense of the <italic>Recall</italic> (Fig. <xref rid="Fig2" ref-type="fig">2</xref>, middle column), although it still outperforms the bi-partitioning approach and performs almost as better as clustering-based reconstructions. It is worth noting that reconstructions obtained with the SCS-<italic>learn</italic> step are consistent with Proposition 2 and 3. In particular, Fig. <xref rid="Fig2" ref-type="fig">2</xref> shows an increase of the <italic>Recall</italic> as the number of eigenvectors grows (middle column, red solid line) as well as a higher <italic>Precision</italic> with the first eigenvectors (left column, red solid line). This is in line with a progressive discovery of the true underlying network and further show that non principal eigenvectors, although less informative than the first eigenvectors, carry relevant information on connected vertices. This can also be observed, to a lesser extent, when a random classifier is embedded in the SCS-<italic>learn</italic> step (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S4). Interestingly, the <italic>Recall</italic> of networks based on spectral clustering partitions decreases when too many eigenvectors are considered (Fig. <xref rid="Fig2" ref-type="fig">2</xref>, middle column, lightblue and darkblue solid lines). As already established [<xref ref-type="bibr" rid="CR26">26</xref>&#8211;<xref ref-type="bibr" rid="CR29">29</xref>], truncated eigenvector basis are expected to emphasize variable similarities and thus, should indicate relevant variable subsets. Yet, due to the approximation error from the real valued solution, non principal eigenvectors are unreliable and worsen variable partitioning. Consequently, connected vertices may be assigned to distinct clusters as the number of eigenvector grows, leading to local reconstructions with a low <italic>Recall</italic>.</p><p>All together, the association of the SCS-<italic>spectral</italic> and SCS-<italic>learn</italic> steps leads to higher <italic>F-score</italic> results (Fig. <xref rid="Fig2" ref-type="fig">2</xref>, right column; Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S3, left column) as compared to reconstructions obtained with various partitioning approaches. This improvement is achieved from a relatively small number of eigenvectors (5 <italic>%</italic> of the total number), thus enabling a good trade-off between reconstruction quality and the number of required subgraphs. Lastly, the ANDES benchmark network was considered as its size allows for a direct reconstruction by each learning method. Results provided in Fig. <xref rid="Fig2" ref-type="fig">2</xref> (dashed red line) show that SCS-<italic>learn</italic> performs better than, or as well as, reconstruction methods alone.</p></sec><sec id="Sec16"><title>SCS-consensus network evaluations</title><p>Evaluations of consensus networks reconstructed from embedded learning approaches based on subgraphs of <italic>m</italic>=12 nodes and using <italic>n</italic>=150 samples are given in Fig. <xref rid="Fig2" ref-type="fig">2</xref> (bottom row). The ANDES benchmark network having 338 edges, scores for the consensus outcome are given based on the 338 first ranked edges (results for different number of edges follow a similar trend, see Additional file <xref rid="MOESM1" ref-type="media">1</xref>). The consensus <italic>Precision</italic> scores (Fig. <xref rid="Fig2" ref-type="fig">2</xref>, bottom left, red solid line) clearly outperform the individually embedded learning approaches (gray dashed lines) as the proportion of eigenvector grows. Similar results are observed for the MUNIN benchmark network (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S9).</p><p>Interestingly, these results emphasize the complementarity of the different reconstruction methods, as already demonstrated [<xref ref-type="bibr" rid="CR5">5</xref>]. In particular, it has been shown that ARACNE and other mutual information reconstruction methods detect more easily feedfoward loop (<italic>A</italic>&#8594;<italic>B</italic>&#8594;<italic>C</italic> and <italic>A</italic>&#8594;<italic>C</italic>) and fan-in (<italic>A</italic>&#8594;<italic>C</italic> and <italic>B</italic>&#8594;<italic>C</italic>) patterns. Conversely, cascade (<italic>A</italic>&#8594;<italic>B</italic>&#8594;<italic>C</italic> and (<italic>A</italic>,<italic>B</italic>) not adjacent) and fan-out (<italic>A</italic>&#8594;<italic>C</italic> and <italic>A</italic>&#8594;<italic>B</italic>) patterns are more easily inferred by Bayesian learning approaches [<xref ref-type="bibr" rid="CR5">5</xref>].</p><p>All together, the SCS-<italic>consensus</italic> phase provides high <italic>F-score</italic> network reconstructions (Fig. <xref rid="Fig2" ref-type="fig">2</xref>, bottom right, red solid line) for a reasonable number of eigenvectors (proportion &#8805;11.5 <italic>%</italic>). The SCS-<italic>consensus</italic> predictions also exhibit high <italic>F-scores</italic> when considering variable subsets of larger sizes in the SCS-<italic>learn</italic> phase (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figures S7&#8211;S9).</p></sec><sec id="Sec17"><title>Reconstruction of microbial ecosystems</title><p>We applied the SCS method to a complex biological dataset generated by high-throughput sequencing of gut microbiome samples from 663 patients recruited in the MetaHIT project (Metagenomics of the Human Intestinal Tract). The nearly 4 million genes whose abundance was measured using quantitative metagenomics were binned to generate representative variables based on their mean co-abundance as introduced by Nielsen et al. [<xref ref-type="bibr" rid="CR47">47</xref>]. These co-abundance groups (CAG) can be either classified as <italic>genomic units</italic> (GU) for small groups (between 3 and 700 genes) or <italic>metagenomic species</italic> (MGS) for larger groups (more than 700 genes). The authors produced a first reconstruction of the gut microbial ecosystem based on Fisher&#8217;s exact test between pairs of CAGs.</p><p>In our study we used this extensively annotated dataset where information on phylogenetic classification and gene assembly is also available. Here we focused on <italic>p</italic>=2, 101 CAGs with more than 50 genes as already proposed in [<xref ref-type="bibr" rid="CR64">64</xref>]. Figure <xref rid="Fig3" ref-type="fig">3</xref>
<xref rid="Fig3" ref-type="fig">a</xref> represents 307 co-presence relationships (edges) between these 2, 101 CAGs (vertices) with at least one connection (leading to a subset of 445) as already provided by Nielsen et al. [<xref ref-type="bibr" rid="CR47">47</xref>]. The number of genes composing a CAG is proportional to the vertex size. CAGs from the same phylum have similar color hues that are specified at the family level of their phylogenetic classification (e.g. <italic>Firmicutes</italic> are given in a range of blue and <italic>Bacteroides</italic> in a range of pink).
<fig id="Fig3"><label>Fig. 3</label><caption><p>Microbial co-presence ecosystem. Microbial ecosystem reconstructed with the pairwise Fisher&#8217;s exact test [<xref ref-type="bibr" rid="CR47">47</xref>] (<bold>a</bold>) and the SCS approach (<bold>b,c</bold>). Data for 2, 101 co-abundant groups (CAGs) and <italic>n</italic>=663 patients recruited in the MetaHIT project were used. Edges depict co-presence (<italic>gray edges</italic>) or absence-presence (<italic>red edges</italic>) relationships. <bold>a</bold> Gut microbial ecosystem based on Fisher&#8217;s exact test between pairs of CAGs [<xref ref-type="bibr" rid="CR47">47</xref>] (307 edges between 445 CAGs of at least 50 genes). <bold>b</bold> The same number of top-ranked edges (307) obtained with the SCS approach which involve 443 CAGs of at least 50 genes. <bold>c</bold> The 15 <italic>%</italic> most significant edges obtained with the SCS approach (654 nodes and 639 edges)</p></caption><graphic xlink:href="12859_2016_1308_Fig3_HTML" id="MO6"/></fig>
</p><p>The SCS approach which embeds three reconstruction methods (ARACNE, 3off2, hill-climbing) inferred a consensus network of 6, 389 edges from the above-mentioned dataset. To compare our results with the pairwise network reconstructed by Nielsen et al. [<xref ref-type="bibr" rid="CR47">47</xref>], we selected the same number (307) of top-ranked SCS edges which represent approximately 5 <italic>%</italic> of the consensus interactions. This network composed of 443 nodes yields more complex sub-structural patterns as illustrated in Fig. <xref rid="Fig3" ref-type="fig">3</xref>
<xref rid="Fig3" ref-type="fig">b</xref>. When comparing networks (A) and (B), only 111 out of the 307 edges (36 <italic>%</italic>) inferred by Fisher&#8217;s exact test are also predicted by the SCS method. Interestingly, 105 of these common edges (95 <italic>%</italic>) have genetic elements that share same assembly contigs, bringing strong biological evidence for these predicted relationships. Conversely, out of the remaining 196 edges solely inferred by Fisher&#8217;s exact test, a significantly smaller number (121, 62 <italic>%</italic>) have genetic elements that share same assembly contigs (<italic>p</italic>&lt;8&#215;10<sup>&#8722;10</sup>, <italic>&#967;</italic>
<sup>2</sup>). Complementary evaluations for different number of common edges (from 55 to 146 edges) follow the same trend (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4 and Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S9). We hypothesize that a non negligible number of edges inferred by pairwise reconstruction techniques may correspond to indirect relationships.</p><p>We explored the topology of the SCS consensus gut microbial ecosystem at different most significant edges threshold (<italic>e</italic>
<sub><italic>m</italic><italic>a</italic><italic>x</italic></sub>) and illustrate the network at 15 <italic>%</italic> in Fig. <xref rid="Fig3" ref-type="fig">3</xref>
<xref rid="Fig3" ref-type="fig">c</xref> (654 vertices and 639 edges). The modular structure of this network is highlighted by tightly related vertices sharing similar colors. This indicates that species of the same family or phylum are mostly co-present as previously discussed [<xref ref-type="bibr" rid="CR43">43</xref>]. This can be explained by the fact that closely related species have similar genetic background adapted for the same environmental niche. Of interest is also the fact that small CAGs (GU) are strongly linked with large CAGs (MGS) having the same phylogenetic annotations as depicted in Fig. <xref rid="Fig3" ref-type="fig">3</xref>(<xref rid="Fig3" ref-type="fig">a</xref> &amp; <xref rid="Fig3" ref-type="fig">b</xref>) and previously described [<xref ref-type="bibr" rid="CR47">47</xref>]. The SCS microbial network also includes consensus directed edges computed from the orientations of the embedded 3off2 and hill-climbing algorithms. Gray oriented edges (<italic>A</italic>&#8594;<italic>B</italic>) indicate <italic>ordered</italic> co-presence relationships (i.e. the presence of <italic>A</italic> species is expected whenever <italic>B</italic> is found). Conversely, red oriented edges provide presence-absence information.</p><p>We further analysed the SCS microbial network by considering the edge rank correlations between individual reconstructions and the consensus result (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). The 3off2 and the ARACNE algorithms have a strong correlation (Fig. <xref rid="Fig4" ref-type="fig">4</xref>, <italic>&#961;</italic>=0.77), as it could be expected for approaches that rely on similar metrics. Conversely, the edge ranks between 3off2 or ARACNE and hill-climbing heuristic exhibit weak correlation coefficients (Fig. <xref rid="Fig4" ref-type="fig">4</xref>, <italic>&#961;</italic>=0.31 and <italic>&#961;</italic>=0.22 resp.). The slightly higher correlation between 3off2 and hill-climbing approaches may be related to the fact that 3off2 is a hybrid approach that is also score-based. All together, these results demonstrate the complementarity of the individual approaches from which the human gut microbial consensus predictions can benefit.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Edge rank correlations between SCS-learn and SCS-consensus outcomes for human gut microbial ecosystem. 6, 389 edges were predicted from a dataset of 663 observations and 2, 101 CAGs (MetaHIT project [<xref ref-type="bibr" rid="CR47">47</xref>]). Rank of edges predicted by only one embedded learning method are given in blue (ARACNE, 159 edges), red (3off2, 498 edges) and yellow (hill-climbing, 2, 889 edges). Rank of edges predicted by two individual learning methods are given in green (ARACNE &amp; hill-climbing, 31), orange (3off2 &amp; hill-climbing, 573 edges) and purple (3off2 &amp; ARACNE, 720 edges). Rank of edges predicted by all individual methods are given in black (1, 519 edges)</p></caption><graphic xlink:href="12859_2016_1308_Fig4_HTML" id="MO7"/></fig>
</p></sec></sec><sec id="Sec18" sec-type="discussion"><title>Discussion</title><p>In this paper, we propose a consensus network learning approach called <italic>Spectral Consensus Strategy</italic> which is based on spectral decomposition. Our method proceeds in three steps, namely SCS-<italic>spectral</italic>, SCS-<italic>learn</italic> and SCS-<italic>consensus</italic>. The first and second phases enable any reconstruction method to learn a possibly oriented network under high-dimensional settings. In addition to accuracy improvement of each reconstruction method, the spectral framework on which the SCS approach relies, also supports fast processing of high-dimensional datasets. The last phase combines the outcome of each reconstruction method to provide consensus predictions.</p><p>This strategy, as well as being accurate, scales up extremely well. Specifically, as the SCS-<italic>learn</italic> step processes in parallel local reconstructions related to the first <italic>k</italic> eigenvectors (Algorithm 2, lines 5&#8722;15), it is the time complexity of the reconstruction methods that mainly impedes the whole running time. The SCS framework itself does not add any demanding computations. In particular, the running time for each individual reconstruction method embedded in the SCS-<italic>learn</italic> phase grows with the number of variables <italic>p</italic> as <inline-formula id="IEq23"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {O}(p\log {p})$\end{document}</tex-math><mml:math id="M50"><mml:mi mathvariant="script">O</mml:mi><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>log</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq23.gif"/></alternatives></inline-formula> (Algorithm ??, line 6). Furthermore, all reconstruction methods can simultaneously learn the network within the second phase. As an example, gut microbiota consensus reconstruction (2, 101 variables, 663 samples, Fig. <xref rid="Fig3" ref-type="fig">3</xref>
<xref rid="Fig3" ref-type="fig">c</xref>) required 43 seconds to reconstruct all subgraphs (<italic>m</italic>=40 vertices, 63 eigenvectors) needed for the <inline-formula id="IEq24"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}_{l}$\end{document}</tex-math><mml:math id="M52"><mml:msub><mml:mrow><mml:mi mathvariant="script">G</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq24.gif"/></alternatives></inline-formula> individual networks, and 52 seconds to build the consensus outcome <inline-formula id="IEq25"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}$\end{document}</tex-math><mml:math id="M54"><mml:mi mathvariant="script">G</mml:mi></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq25.gif"/></alternatives></inline-formula> using 40 CPUs. Besides, the early step of the SCS-<italic>spectral</italic> phase which involves the computation of the mutual information matrix (Algorithm ??, line 3) and the last step of the SCS-<italic>learn</italic> phase which is dedicated to the assembling of local reconstructions (Algorithm ??, lines 17&#8722;19), can be efficiently optimised and implemented [<xref ref-type="bibr" rid="CR65">65</xref>, <xref ref-type="bibr" rid="CR66">66</xref>]. All together, the SCS approach could efficiently reconstruct the microbiome ecosystem, while the hill-climbing algorithm alone did not converge in 48 hours (see Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Section 4, for detailed evaluations). These results highlight the ability of our method to improve the scalability of the embedded learning approaches.</p><p>The subgraph size <italic>m</italic> for the SCS-<italic>learn</italic> phase influences the quality of individual reconstructions (<inline-formula id="IEq26"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}_{l}$\end{document}</tex-math><mml:math id="M56"><mml:msub><mml:mrow><mml:mi mathvariant="script">G</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq26.gif"/></alternatives></inline-formula> graphs). Specifically, too small subgraphs lead to low <italic>Recall</italic> and very high <italic>Precision</italic>, while conversely too large subgraphs (even still under non high-dimensional conditions) increase the <italic>Recall</italic> at the expense of the <italic>Precision</italic>, both cases impeding the <italic>F-score</italic> results (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figures S1&#8211;S3). Yet, predictions output by the SCS-<italic>learn</italic> step remain better than predictions derived from classical clustering and partitioning approaches for various sizes <italic>m</italic>. Interestingly, although the parameter <italic>m</italic> significantly impacts individual reconstructions, it only slightly impedes the consensus <italic>F-score</italic>. In particular, larger subgraphs still provide a consensus network of good quality from high-dimensional dataset (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figures S7&#8211;S9). Similarly, the eigenvector proportion influences individual reconstructions <inline-formula id="IEq27"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {G}_{l}$\end{document}</tex-math><mml:math id="M58"><mml:msub><mml:mrow><mml:mi mathvariant="script">G</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2016_1308_Article_IEq27.gif"/></alternatives></inline-formula> as too many eigenvectors lead to lower <italic>Precision</italic> and higher <italic>Recall</italic>. Yet, the consensus network based on the first <italic>e</italic>
<sub><italic>m</italic><italic>a</italic><italic>x</italic></sub> most significant edges achieves good and stable quality as the number of eigenvectors grows (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figures S7&#8211;S9).</p><p>To define the minimal number of eigenvectors that would bring sufficient amount of information for a good consensus reconstruction, we designed a heuristic approach based on the decreasing interval between successive eigenvalues. For classical clustering approaches, the <italic>eigengap</italic> heuristic has been proposed to define the most suitable cluster number. This eigengap heuristic method is related to the fact that under ideal conditions, <italic>k</italic> distinct connected components are associated to the first <italic>k</italic> null eigenvalues and thus, a gap can be found between <italic>&#955;</italic>
<sub><italic>i</italic>&#8804;<italic>k</italic></sub>=0 and <italic>&#955;</italic>
<sub><italic>k</italic>+1</sub>&gt;0. In practice, the eigengap heuristic sets the number <italic>k</italic> such that <italic>&#955;</italic>
<sub><italic>i</italic>&#8804;<italic>k</italic></sub> are small but <italic>&#955;</italic>
<sub><italic>k</italic>+1</sub> is relatively large. The SCS approach objective is not to partition variables but rather to reconstruct a consensus network from overlapping subgraphs, using as much as possible of the information conveyed by each eigenvector. As shown from the counts and cumulative counts of <italic>true positive</italic> interactions for the ANDES benchmark network (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S5), although most of the <italic>true positive</italic> interactions are retrieved from the first eigenvectors, non principal eigenvectors also conveyed relevant information on connected vertices. Hence, we consider the first <italic>k</italic> eigenvectors for which the successive eigenvalues are dissimilar enough as being the best number of eigenvectors to be used for the SCS consensus reconstruction. As an example, our heuristic method evaluated at 30 (14 <italic>%</italic>) the most suitable number of eigenvectors for the ANDES benchmark network. This number approximately corresponds to the number of eigenvectors from which the consensus network achieves better <italic>F-score</italic> results than networks obtained from individually embedded methods (Fig. <xref rid="Fig2" ref-type="fig">2</xref>).</p><p>The SCS approach is mainly designed to reconstruct large unknown biological networks, thus no weights have been assigned to individual reconstruction methods. However, if any prior knowledge is available on the underlying network topology, such as bias in particular connection patterns, weights can be easily assigned when computing the average interaction rank.</p></sec><sec id="Sec19" sec-type="conclusion"><title>Conclusion</title><p>Our contribution addresses the problem of large network reconstructions. The <italic>Spectral Consensus Strategy</italic> aims to reconstruct networks from high-dimensional dataset by overlapping subgraph parallel learning and consensus predictions. Although this approach is not intended to partition the data points, it takes advantage of spectral decomposition to identify tightly related vertices. We show by our experiments on both standard benchmark and real complex data that the performance of the proposed approach is extremely competitive. Our method is efficient from a computational viewpoint, its implementation is straightforward, and no effort has to be spent on hyper-parameter tuning.</p></sec></body><back><app-group><app id="App1"><sec id="Sec20"><title>Additional file</title><p>
<media position="anchor" xlink:href="12859_2016_1308_MOESM1_ESM.pdf" id="MOESM1"><label>Additional file 1</label><caption><p>Contains complementary demonstrations as well as supplementary evaluations for the SCS approach. Specifically, Section 1 provides Propositions and associated <italic>sketches of proof</italic> that support our method. Complementary evaluations of the SCS first steps, namely SCS-<italic>spectral</italic> and SCS-<italic>learn</italic>, are given in Section 2. We also provide in Section 3 complementary evaluations of the SCS last step, named SCS-<italic>consensus</italic>. Execution time comparisons are given in Section 4. Supplementary statistics on the application to human gut microbiota close this Additional file 1. (PDF 606 kb)</p></caption></media>
</p></sec></app></app-group><ack><sec id="d29e3373"><title>Declarations</title><p>This article has been published as part of <italic>BMC Bioinformatics</italic> Volume 17 Supplement 16, 2016: Proceedings of the Tenth International Workshop on Machine Learning in Systems Biology (MLSB 2016). The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="http://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-17-supplement-16">http://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-17-supplement-16</ext-link>.</p></sec><sec id="d29e3386"><title>Funding</title><p>The publication of this article was funded by a grant from the AP-HP to JDZ (Contrat d&#8217;interface APH-HP, 2014). This work is also supported by the European Union&#8217;s Seventh Framework Program under grant agreement HEALTH-F4-2012-305312 (MetaCardis project). SA was financed by an ICAN-Danone Research grant.</p></sec><sec id="d29e3391"><title>Availability of data and materials</title><p>The MetaHIT data we use in our experiments have been already published as a supplementary material of Nielsen H.B., al. Identification and assembly of genomes and genetic elements in complex metagenomic samples without using reference genomes. Nature biotechnology 32(8), 822&#8211;828 (2014). Available from: doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nbt.2939">10.1038/nbt.2939</ext-link>, and the supplementary material can be provided.</p></sec><sec id="d29e3401"><title>Authors&#8217; contributions</title><p>SA, NS, EP and JDZ conceived and performed the research. SA, NS, EP and JDZ wrote the manuscript. All authors read and approved the final manuscript.</p></sec><sec id="d29e3406"><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec id="d29e3411"><title>Consent for publication</title><p>Not applicable.</p></sec><sec id="d29e3416"><title>Ethics approval and consent to participate</title><p>Not applicable.</p></sec></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1</label><mixed-citation publication-type="other">Margolin AA, Nemenman I, Basso K, Wiggins C, Stolovitzky G, Favera RD, Califano A. Aracne: An algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context. BMC Bioinformatics. 2006:7(Suppl 1).</mixed-citation></ref><ref id="CR2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faith</surname><given-names>JJ</given-names></name><name><surname>Hayete</surname><given-names>B</given-names></name><name><surname>Thaden</surname><given-names>JT</given-names></name><name><surname>Mogno</surname><given-names>I</given-names></name><name><surname>Wierzbowski</surname><given-names>J</given-names></name><name><surname>Cottarel</surname><given-names>G</given-names></name><name><surname>Kasif</surname><given-names>S</given-names></name><name><surname>Collins</surname><given-names>JJ</given-names></name><name><surname>Gardner</surname><given-names>TS</given-names></name></person-group><article-title>Large-scale mapping and validation of escherichia coli transcriptional regulation from a compendium of expression profiles</article-title><source>PLoS Biol</source><year>2007</year><volume>5</volume><issue>1</issue><fpage>8</fpage><pub-id pub-id-type="doi">10.1371/journal.pbio.0050008</pub-id></element-citation></ref><ref id="CR3"><label>3</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>N</given-names></name><name><surname>Linial</surname><given-names>M</given-names></name><name><surname>Nachman</surname><given-names>I</given-names></name><name><surname>Pe&#8217;er</surname><given-names>D</given-names></name></person-group><article-title>Using Bayesian networks to analyze expression data</article-title><source>International Conference on Computational Molecular Biology</source><year>2000</year><publisher-loc>New York</publisher-loc><publisher-name>Mary Ann Liebert, Inc.</publisher-name></element-citation></ref><ref id="CR4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Affeldt</surname><given-names>S</given-names></name><name><surname>Verny</surname><given-names>L</given-names></name><name><surname>Isambert</surname><given-names>H</given-names></name></person-group><article-title>3off2: A network reconstruction algorithm based on 2-point and 3-point information statistics</article-title><source>BMC Bioinformatics</source><year>2016</year><volume>17</volume><issue>S-2</issue><fpage>12</fpage><pub-id pub-id-type="doi">10.1186/s12859-015-0856-x</pub-id><?supplied-pmid 26823190?><pub-id pub-id-type="pmid">26823190</pub-id></element-citation></ref><ref id="CR5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marbach</surname><given-names>D</given-names></name><name><surname>Costello</surname><given-names>JC</given-names></name><name><surname>K&#252;ffner</surname><given-names>R</given-names></name><name><surname>Vega</surname><given-names>NM</given-names></name><name><surname>Prill</surname><given-names>RJ</given-names></name><name><surname>Camacho</surname><given-names>DM</given-names></name><name><surname>Allison</surname><given-names>KR</given-names></name><name><surname>Kellis</surname><given-names>M</given-names></name><name><surname>Collins</surname><given-names>JJ</given-names></name><name><surname>Stolovitzky</surname><given-names>G</given-names></name><etal/></person-group><article-title>Wisdom of crowds for robust gene network inference</article-title><source>Nat Methods</source><year>2012</year><volume>9</volume><issue>8</issue><fpage>796</fpage><lpage>804</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2016</pub-id><?supplied-pmid 22796662?><pub-id pub-id-type="pmid">22796662</pub-id></element-citation></ref><ref id="CR6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smet</surname><given-names>RD</given-names></name><name><surname>Marchal</surname><given-names>K</given-names></name></person-group><article-title>Advantages and limitations of current network inference methods</article-title><source>Nat Rev Micro</source><year>2010</year><volume>10</volume><issue>8</issue><fpage>717</fpage><lpage>29</lpage></element-citation></ref><ref id="CR7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellot</surname><given-names>P</given-names></name><name><surname>Olsen</surname><given-names>C</given-names></name><name><surname>Salembier</surname><given-names>P</given-names></name><name><surname>Oliveras</surname><given-names>A</given-names></name><name><surname>Meyer</surname><given-names>PE</given-names></name></person-group><article-title>Netbenchmark: a bioconductor package for reproducible benchmarks of gene regulatory network inference</article-title><source>BMC Bioinformatics</source><year>2015</year><volume>16</volume><issue>312</issue><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="pmid">25591917</pub-id></element-citation></ref><ref id="CR8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marbach</surname><given-names>D</given-names></name><name><surname>Prill</surname><given-names>RJ</given-names></name><name><surname>Schaffter</surname><given-names>T</given-names></name><name><surname>Mattiussi</surname><given-names>C</given-names></name><name><surname>Floreano</surname><given-names>D</given-names></name><name><surname>Stolovitzky</surname><given-names>G</given-names></name></person-group><article-title>Revealing strengths and weaknesses of methods for gene network inference</article-title><source>Proc Natl Acad Sci</source><year>2010</year><volume>107</volume><issue>14</issue><fpage>6286</fpage><lpage>291</lpage><pub-id pub-id-type="doi">10.1073/pnas.0913357107</pub-id><?supplied-pmid 20308593?><pub-id pub-id-type="pmid">20308593</pub-id></element-citation></ref><ref id="CR9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pearl</surname><given-names>J</given-names></name><name><surname>Verma</surname><given-names>TS</given-names></name></person-group><article-title>A theory of inferred causation</article-title><source>Studies in Logic and the Foundations of Mathematics</source><year>1995</year><volume>134</volume><fpage>789</fpage><lpage>811</lpage><pub-id pub-id-type="doi">10.1016/S0049-237X(06)80074-1</pub-id></element-citation></ref><ref id="CR10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spirtes</surname><given-names>P</given-names></name><name><surname>Glymour</surname><given-names>C</given-names></name></person-group><article-title>An algorithm for fast recovery of sparse causal graphs</article-title><source>Soc Sci Comput Rev</source><year>1991</year><volume>9</volume><fpage>62</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1177/089443939100900106</pub-id></element-citation></ref><ref id="CR11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cooper</surname><given-names>GF</given-names></name><name><surname>Herskovits</surname><given-names>E</given-names></name></person-group><article-title>A bayesian method for the induction of probabilistic networks from data</article-title><source>Mach Learn</source><year>1992</year><volume>9</volume><issue>4</issue><fpage>309</fpage><lpage>47</lpage></element-citation></ref><ref id="CR12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heckerman</surname><given-names>D</given-names></name><name><surname>Geiger</surname><given-names>D</given-names></name><name><surname>Chickering</surname><given-names>DM</given-names></name></person-group><article-title>Learning bayesian networks: the combination of knowledge and statistical data</article-title><source>Mach Learn</source><year>1995</year><volume>20</volume><issue>3</issue><fpage>197</fpage><lpage>243</lpage></element-citation></ref><ref id="CR13"><label>13</label><mixed-citation publication-type="other">Cano A, Gomez-Olmedo M, Moral S. A score based ranking of the edges for the PC algorithm. In: Proceedings of the Fourth European Workshop on Probabilistic Graphical Models: 2008. p. 41&#8211;8.</mixed-citation></ref><ref id="CR14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Campos</surname><given-names>L</given-names></name></person-group><article-title>A scoring function for learning bayesian networks based on mutual information and conditional independence tests</article-title><source>J Mach Learn Res</source><year>2006</year><volume>7</volume><fpage>2149</fpage><lpage>187</lpage></element-citation></ref><ref id="CR15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsamardinos</surname><given-names>I</given-names></name><name><surname>Brown</surname><given-names>L</given-names></name><name><surname>Aliferis</surname><given-names>CF</given-names></name></person-group><article-title>The max-min hill-climbing bayesian network structure learning algorithm</article-title><source>Mach Learn</source><year>2006</year><volume>65</volume><issue>1</issue><fpage>31</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1007/s10994-006-6889-7</pub-id></element-citation></ref><ref id="CR16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiedler</surname><given-names>M</given-names></name></person-group><article-title>A property of eigenvectors of nonnegative symmetric matrices and its application to graph theory</article-title><source>Czechoslov Math J</source><year>1975</year><volume>25</volume><issue>100</issue><fpage>619</fpage><lpage>33</lpage></element-citation></ref><ref id="CR17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiedler</surname><given-names>M</given-names></name></person-group><article-title>Algebraic connectivity of graphs</article-title><source>Czechoslov Math J</source><year>1973</year><volume>23</volume><issue>98</issue><fpage>298</fpage><lpage>305</lpage></element-citation></ref><ref id="CR18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shi</surname><given-names>J</given-names></name><name><surname>Malik</surname><given-names>J</given-names></name></person-group><article-title>Normalized cuts and image segmentation</article-title><source>IEEE Trans Pattern Anal Mach Intell</source><year>2000</year><volume>22</volume><issue>8</issue><fpage>888</fpage><lpage>905</lpage><pub-id pub-id-type="doi">10.1109/34.868688</pub-id></element-citation></ref><ref id="CR19"><label>19</label><mixed-citation publication-type="other">Spielman DA, Teng SH. Spectral partitioning works: Planar graphs and finite element meshes. In: Foundations of Computer Science, 1996. Proceedings., 37th Annual Symposium on. IEEE: 1996. p. 96&#8211;105.</mixed-citation></ref><ref id="CR20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newman</surname><given-names>MEJ</given-names></name></person-group><article-title>Modularity and community structure in networks</article-title><source>Proc Natl Acad Sci</source><year>2006</year><volume>103</volume><issue>23</issue><fpage>8577</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1073/pnas.0601602103</pub-id><?supplied-pmid 16723398?><pub-id pub-id-type="pmid">16723398</pub-id></element-citation></ref><ref id="CR21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hotelling</surname><given-names>H</given-names></name></person-group><article-title>Analysis of a complex of statistical variables into principal components</article-title><source>J Educ Psych</source><year>1933</year><volume>24</volume><fpage>417</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1037/h0071325</pub-id></element-citation></ref><ref id="CR22"><label>22</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kruskal</surname><given-names>JB</given-names></name><name><surname>Wish</surname><given-names>M</given-names></name></person-group><source>Multidimensional scaling</source><year>1978</year><publisher-loc>Beverely Hills</publisher-loc><publisher-name>Sage Publications</publisher-name></element-citation></ref><ref id="CR23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sch&#246;lkopf</surname><given-names>B</given-names></name><name><surname>Smola</surname><given-names>A</given-names></name><name><surname>M&#252;ller</surname><given-names>KR</given-names></name></person-group><article-title>Nonlinear component analysis as a kernel eigenvalue problem</article-title><source>Neural Comput</source><year>1998</year><volume>10</volume><issue>5</issue><fpage>1299</fpage><lpage>319</lpage><pub-id pub-id-type="doi">10.1162/089976698300017467</pub-id></element-citation></ref><ref id="CR24"><label>24</label><mixed-citation publication-type="other">Azar Y, Fiat A, Karlin A, McSherry F, Saia J. Spectral analysis of data. In: Proceedings of the thirty-third annual ACM symposium on Theory of computing. ACM: 2001. p. 619&#8211;626.</mixed-citation></ref><ref id="CR25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kannan</surname><given-names>R</given-names></name><name><surname>Vempala</surname><given-names>S</given-names></name><name><surname>Vetta</surname><given-names>A</given-names></name></person-group><article-title>On clusterings: Good, bad and spectral</article-title><source>J ACM</source><year>2004</year><volume>51</volume><issue>3</issue><fpage>497</fpage><lpage>515</lpage><pub-id pub-id-type="doi">10.1145/990308.990313</pub-id></element-citation></ref><ref id="CR26"><label>26</label><mixed-citation publication-type="other">Perona P, Freeman WT. A factorization approach to grouping. In: European Conference on Computer Vision. Springer: 1998. p. 655&#8211;70.</mixed-citation></ref><ref id="CR27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alpert</surname><given-names>C</given-names></name><name><surname>Kahng</surname><given-names>A</given-names></name><name><surname>Yao</surname><given-names>S</given-names></name></person-group><article-title>Spectral partitioning: the more eigenvectors, the better</article-title><source>Discrete Appl Math</source><year>1999</year><volume>90</volume><fpage>3</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1016/S0166-218X(98)00083-3</pub-id></element-citation></ref><ref id="CR28"><label>28</label><mixed-citation publication-type="other">Ng AY, Jordan MI, Weiss Y. On Spectral Clustering: Analysis and an algorithm. In: Advances in Neural Information Processing Systems. MIT Press: 2001. p. 849&#8211;56.</mixed-citation></ref><ref id="CR29"><label>29</label><mixed-citation publication-type="other">Brand M, Huang K. A Unifying Theorem for Spectral Embedding and Clustering. In: Proc. 9th International Workshop on AI and Statistics: 2003. <ext-link ext-link-type="uri" xlink:href="http://www.merl.com/publications/TR2002-042/">http://www.merl.com/publications/TR2002-042/</ext-link>.</mixed-citation></ref><ref id="CR30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrg&#229;rd</surname><given-names>MJ</given-names></name><name><surname>Swainston</surname><given-names>N</given-names></name><name><surname>Dobson</surname><given-names>P</given-names></name><name><surname>Dunn</surname><given-names>WB</given-names></name><name><surname>Arga</surname><given-names>KY</given-names></name><name><surname>Arvas</surname><given-names>M</given-names></name><name><surname>Bl&#252;thgen</surname><given-names>N</given-names></name><name><surname>Borger</surname><given-names>S</given-names></name><name><surname>Costenoble</surname><given-names>R</given-names></name><name><surname>Heinemann</surname><given-names>M</given-names></name><etal/></person-group><article-title>A consensus yeast metabolic network reconstruction obtained from a community approach to systems biology</article-title><source>Nat Biotechnol</source><year>2008</year><volume>26</volume><issue>10</issue><fpage>1155</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1038/nbt1492</pub-id><?supplied-pmid 18846089?><pub-id pub-id-type="pmid">18846089</pub-id></element-citation></ref><ref id="CR31"><label>31</label><mixed-citation publication-type="other">Fr&#246;ehlich H, Klau GW. Reconstructing consensus bayesian network structures with application to learning molecular interaction networks. In: GCB. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik: 2013. p. 46&#8211;55. <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.4230/OASIcs.GCB.2013.46">http://dx.doi.org/10.4230/OASIcs.GCB.2013.46</ext-link>.</mixed-citation></ref><ref id="CR32"><label>32</label><mixed-citation publication-type="other">Berto S, Perdomo-Sabogal A, Gerighausen D, Qin J, Nowick K. A consensus network of gene regulatory factors in the human frontal lobe. Front Genet. 2016; 7.</mixed-citation></ref><ref id="CR33"><label>33</label><mixed-citation publication-type="other">Lancichinetti A, Fortunato S. Consensus clustering in complex networks. Scientific reports. 2012; 2.</mixed-citation></ref><ref id="CR34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qin</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>R</given-names></name><name><surname>Raes</surname><given-names>J</given-names></name><name><surname>Arumugam</surname><given-names>M</given-names></name><name><surname>Burgdorf</surname><given-names>KS</given-names></name><name><surname>Manichanh</surname><given-names>C</given-names></name><name><surname>Nielsen</surname><given-names>T</given-names></name><name><surname>Pons</surname><given-names>N</given-names></name><name><surname>Levenez</surname><given-names>F</given-names></name><name><surname>Yamada</surname><given-names>T</given-names></name><etal/></person-group><article-title>A human gut microbial gene catalogue established by metagenomic sequencing</article-title><source>Nature</source><year>2010</year><volume>464</volume><issue>7285</issue><fpage>59</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1038/nature08821</pub-id><?supplied-pmid 20203603?><pub-id pub-id-type="pmid">20203603</pub-id></element-citation></ref><ref id="CR35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nicholson</surname><given-names>JK</given-names></name><name><surname>Holmes</surname><given-names>E</given-names></name><name><surname>Kinross</surname><given-names>J</given-names></name><name><surname>Burcelin</surname><given-names>R</given-names></name><name><surname>Gibson</surname><given-names>G</given-names></name><name><surname>Jia</surname><given-names>W</given-names></name><name><surname>Pettersson</surname><given-names>S</given-names></name></person-group><article-title>Host-gut microbiota metabolic interactions</article-title><source>Science</source><year>2012</year><volume>336</volume><issue>6086</issue><fpage>1262</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1126/science.1223813</pub-id><?supplied-pmid 22674330?><pub-id pub-id-type="pmid">22674330</pub-id></element-citation></ref><ref id="CR36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lozupone</surname><given-names>CA</given-names></name><name><surname>Stombaugh</surname><given-names>JI</given-names></name><name><surname>Gordon</surname><given-names>JI</given-names></name><name><surname>Jansson</surname><given-names>JK</given-names></name><name><surname>Knight</surname><given-names>R</given-names></name></person-group><article-title>Diversity, stability and resilience of the human gut microbiota</article-title><source>Nature</source><year>2012</year><volume>489</volume><issue>7415</issue><fpage>220</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1038/nature11550</pub-id><?supplied-pmid 22972295?><pub-id pub-id-type="pmid">22972295</pub-id></element-citation></ref><ref id="CR37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walsh</surname><given-names>CJ</given-names></name><name><surname>Guinane</surname><given-names>CM</given-names></name><name><surname>O&#8217;Toole</surname><given-names>PW</given-names></name><name><surname>Cotter</surname><given-names>PD</given-names></name></person-group><article-title>Beneficial modulation of the gut microbiota</article-title><source>FEBS Lett</source><year>2014</year><volume>588</volume><issue>22</issue><fpage>4120</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1016/j.febslet.2014.03.035</pub-id><?supplied-pmid 24681100?><pub-id pub-id-type="pmid">24681100</pub-id></element-citation></ref><ref id="CR38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clarke</surname><given-names>SF</given-names></name><name><surname>Murphy</surname><given-names>EF</given-names></name><name><surname>Nilaweera</surname><given-names>K</given-names></name><name><surname>Ross</surname><given-names>PR</given-names></name><name><surname>Shanahan</surname><given-names>F</given-names></name><name><surname>O&#8217;Toole</surname><given-names>PW</given-names></name><name><surname>Cotter</surname><given-names>PD</given-names></name></person-group><article-title>The gut microbiota and its relationship to diet and obesity: new insights</article-title><source>Gut Microbes</source><year>2012</year><volume>3</volume><issue>3</issue><fpage>186</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.4161/gmic.20168</pub-id><?supplied-pmid 22572830?><pub-id pub-id-type="pmid">22572830</pub-id></element-citation></ref><ref id="CR39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ley</surname><given-names>RE</given-names></name><name><surname>Turnbaugh</surname><given-names>PJ</given-names></name><name><surname>Klein</surname><given-names>S</given-names></name><name><surname>Gordon</surname><given-names>JI</given-names></name></person-group><article-title>Microbial ecology: human gut microbes associated with obesity</article-title><source>Nature</source><year>2006</year><volume>444</volume><issue>7122</issue><fpage>1022</fpage><lpage>3</lpage><pub-id pub-id-type="doi">10.1038/4441022a</pub-id><?supplied-pmid 17183309?><pub-id pub-id-type="pmid">17183309</pub-id></element-citation></ref><ref id="CR40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elson</surname><given-names>CO</given-names></name><name><surname>Cong</surname><given-names>Y</given-names></name></person-group><article-title>Host-microbiota interactions in inflammatory bowel disease</article-title><source>Gut Microbes</source><year>2012</year><volume>3</volume><issue>4</issue><fpage>332</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.4161/gmic.20228</pub-id><?supplied-pmid 22572873?><pub-id pub-id-type="pmid">22572873</pub-id></element-citation></ref><ref id="CR41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lepage</surname><given-names>P</given-names></name><name><surname>H&#228;sler</surname><given-names>R</given-names></name><name><surname>Spehlmann</surname><given-names>ME</given-names></name><name><surname>Rehman</surname><given-names>A</given-names></name><name><surname>Zvirbliene</surname><given-names>A</given-names></name><name><surname>Begun</surname><given-names>A</given-names></name><name><surname>Ott</surname><given-names>S</given-names></name><name><surname>Kupcinskas</surname><given-names>L</given-names></name><name><surname>Dor&#233;</surname><given-names>J</given-names></name><name><surname>Raedler</surname><given-names>A</given-names></name><etal/></person-group><article-title>Twin study indicates loss of interaction between microbiota and mucosa of patients with ulcerative colitis</article-title><source>Gastroenterology</source><year>2011</year><volume>141</volume><issue>1</issue><fpage>227</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1053/j.gastro.2011.04.011</pub-id><?supplied-pmid 21621540?><pub-id pub-id-type="pmid">21621540</pub-id></element-citation></ref><ref id="CR42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bajaj</surname><given-names>JS</given-names></name><name><surname>Thacker</surname><given-names>LR</given-names></name><name><surname>Heuman</surname><given-names>DM</given-names></name><name><surname>Fuchs</surname><given-names>M</given-names></name><name><surname>Sterling</surname><given-names>RK</given-names></name><name><surname>Sanyal</surname><given-names>AJ</given-names></name><name><surname>Puri</surname><given-names>P</given-names></name><name><surname>Siddiqui</surname><given-names>MS</given-names></name><name><surname>Stravitz</surname><given-names>RT</given-names></name><name><surname>Bouneva</surname><given-names>I</given-names></name><etal/></person-group><article-title>The stroop smartphone application is a short and valid method to screen for minimal hepatic encephalopathy</article-title><source>Hepatology</source><year>2013</year><volume>58</volume><issue>3</issue><fpage>1122</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1002/hep.26309</pub-id><?supplied-pmid 23389962?><pub-id pub-id-type="pmid">23389962</pub-id></element-citation></ref><ref id="CR43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qin</surname><given-names>N</given-names></name><name><surname>Yang</surname><given-names>F</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Prifti</surname><given-names>E</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Shao</surname><given-names>L</given-names></name><name><surname>Guo</surname><given-names>J</given-names></name><name><surname>Le Chatelier</surname><given-names>E</given-names></name><name><surname>Yao</surname><given-names>J</given-names></name><name><surname>Wu</surname><given-names>L</given-names></name><etal/></person-group><article-title>Alterations of the human gut microbiome in liver cirrhosis</article-title><source>Nature</source><year>2014</year><volume>513</volume><issue>7516</issue><fpage>59</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1038/nature13568</pub-id><?supplied-pmid 25079328?><pub-id pub-id-type="pmid">25079328</pub-id></element-citation></ref><ref id="CR44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>L</given-names></name><name><surname>Ley</surname><given-names>RE</given-names></name><name><surname>Volchkov</surname><given-names>PY</given-names></name><name><surname>Stranges</surname><given-names>PB</given-names></name><name><surname>Avanesyan</surname><given-names>L</given-names></name><name><surname>Stonebraker</surname><given-names>AC</given-names></name><name><surname>Hu</surname><given-names>C</given-names></name><name><surname>Wong</surname><given-names>FS</given-names></name><name><surname>Szot</surname><given-names>GL</given-names></name><name><surname>Bluestone</surname><given-names>JA</given-names></name><etal/></person-group><article-title>Innate immunity and intestinal microbiota in the development of type 1 diabetes</article-title><source>Nature</source><year>2008</year><volume>455</volume><issue>7216</issue><fpage>1109</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/nature07336</pub-id><?supplied-pmid 18806780?><pub-id pub-id-type="pmid">18806780</pub-id></element-citation></ref><ref id="CR45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karlsson</surname><given-names>FH</given-names></name><name><surname>Tremaroli</surname><given-names>V</given-names></name><name><surname>Nookaew</surname><given-names>I</given-names></name><name><surname>Bergstr&#246;m</surname><given-names>G</given-names></name><name><surname>Behre</surname><given-names>CJ</given-names></name><name><surname>Fagerberg</surname><given-names>B</given-names></name><name><surname>Nielsen</surname><given-names>J</given-names></name><name><surname>B&#228;ckhed</surname><given-names>F</given-names></name></person-group><article-title>Gut metagenome in european women with normal, impaired and diabetic glucose control</article-title><source>Nature</source><year>2013</year><volume>498</volume><issue>7452</issue><fpage>99</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1038/nature12198</pub-id><?supplied-pmid 23719380?><pub-id pub-id-type="pmid">23719380</pub-id></element-citation></ref><ref id="CR46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qin</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Cai</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Zhu</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>F</given-names></name><name><surname>Liang</surname><given-names>S</given-names></name><name><surname>Zhang</surname><given-names>W</given-names></name><name><surname>Guan</surname><given-names>Y</given-names></name><name><surname>Shen</surname><given-names>D</given-names></name><etal/></person-group><article-title>A metagenome-wide association study of gut microbiota in type 2 diabetes</article-title><source>Nature</source><year>2012</year><volume>490</volume><issue>7418</issue><fpage>55</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1038/nature11450</pub-id><?supplied-pmid 23023125?><pub-id pub-id-type="pmid">23023125</pub-id></element-citation></ref><ref id="CR47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nielsen</surname><given-names>HB</given-names></name><name><surname>Almeida</surname><given-names>M</given-names></name><name><surname>Juncker</surname><given-names>AS</given-names></name><name><surname>Rasmussen</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Sunagawa</surname><given-names>S</given-names></name><name><surname>Plichta</surname><given-names>DR</given-names></name><name><surname>Gautier</surname><given-names>L</given-names></name><name><surname>Pedersen</surname><given-names>AG</given-names></name><name><surname>Le Chatelier</surname><given-names>E</given-names></name><etal/></person-group><article-title>Identification and assembly of genomes and genetic elements in complex metagenomic samples without using reference genomes</article-title><source>Nat Biotechnol</source><year>2014</year><volume>32</volume><issue>8</issue><fpage>822</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1038/nbt.2939</pub-id><?supplied-pmid 24997787?><pub-id pub-id-type="pmid">24997787</pub-id></element-citation></ref><ref id="CR48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faust</surname><given-names>K</given-names></name><name><surname>Raes</surname><given-names>J</given-names></name></person-group><article-title>Microbial interactions: from networks to models</article-title><source>Nat Rev Microbiol</source><year>2012</year><volume>10</volume><issue>8</issue><fpage>538</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1038/nrmicro2832</pub-id><?supplied-pmid 22796884?><pub-id pub-id-type="pmid">22796884</pub-id></element-citation></ref><ref id="CR49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohar</surname><given-names>B</given-names></name><name><surname>Alavi</surname><given-names>Y</given-names></name><name><surname>Chartrand</surname><given-names>G</given-names></name><name><surname>Oellermann</surname><given-names>O</given-names></name></person-group><article-title>The laplacian spectrum of graphs</article-title><source>Graph Theory Comb Appl</source><year>1991</year><volume>2</volume><issue>871-898</issue><fpage>12</fpage></element-citation></ref><ref id="CR50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luxburg</surname><given-names>U</given-names></name></person-group><article-title>A tutorial on spectral clustering</article-title><source>Stat Comput</source><year>2007</year><volume>17</volume><issue>4</issue><fpage>395</fpage><lpage>416</lpage><pub-id pub-id-type="doi">10.1007/s11222-007-9033-z</pub-id></element-citation></ref><ref id="CR51"><label>51</label><mixed-citation publication-type="other">Newman MEJ. Finding community structure in networks using the eigenvectors of matrices. Phys Rev E. 2006; 74(3).</mixed-citation></ref><ref id="CR52"><label>52</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Golub</surname><given-names>GH</given-names></name><name><surname>van Loan</surname><given-names>CF</given-names></name></person-group><source>Matrix Computations. Johns Hopkins Series in the Mathematical Sciences</source><year>1989</year><publisher-loc>Favoritenstrasse</publisher-loc><publisher-name>The Johns Hopkins University Press</publisher-name></element-citation></ref><ref id="CR53"><label>53</label><mixed-citation publication-type="other">Pothen A, Simon HD, Liu K. -P. P. Partitioning sparse matrices with eigenvectors of graphs. Technical report NASA Ames Research Center. 1989.</mixed-citation></ref><ref id="CR54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleinberg</surname><given-names>JM</given-names></name></person-group><article-title>Authoritative sources in a hyperlinked environment</article-title><source>J ACM (JACM)</source><year>1999</year><volume>46</volume><issue>5</issue><fpage>604</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1145/324133.324140</pub-id></element-citation></ref><ref id="CR55"><label>55</label><mixed-citation publication-type="other">Miller B, Bliss N, Wolfe PJ. Subgraph detection using eigenvector L1 norms. In: NIPS: 2010. p. 1633&#8211;1641. <ext-link ext-link-type="uri" xlink:href="http://www.bibsonomy.org/bibtex/22fa92e5556307d62c4ed6473f4bba10c/dblp">http://www.bibsonomy.org/bibtex/22fa92e5556307d62c4ed6473f4bba10c/dblp</ext-link>.</mixed-citation></ref><ref id="CR56"><label>56</label><mixed-citation publication-type="other">Russakoff DB, Tomasi C, Rohlfing T, Jr CRM. Image similarity using mutual information of regions. In: 8th European Conference on Computer Vision (ECCV. Springer: 2004. p. 596&#8211;607.</mixed-citation></ref><ref id="CR57"><label>57</label><mixed-citation publication-type="other">Liu R, Gillies DF. An eigenvalue-problem formulation for non-parametric mutual information maximisation for linear dimensionality reduction. In: International Conference on Image Processing, Computer Vision, and Pattern Recognition: 2012. p. 905&#8211;910.</mixed-citation></ref><ref id="CR58"><label>58</label><mixed-citation publication-type="other">Priness I, Maimon O, Ben-Gal IE. Evaluation of gene-expression clustering via mutual information distance measure. BMC Bioinformatics. 2007; 8.</mixed-citation></ref><ref id="CR59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steuer</surname><given-names>R</given-names></name><name><surname>Kurths</surname><given-names>J</given-names></name><name><surname>Daub</surname><given-names>CO</given-names></name><name><surname>Weise</surname><given-names>J</given-names></name><name><surname>Selbig</surname><given-names>J</given-names></name></person-group><article-title>The mutual information: Detecting and evaluating dependencies between variables</article-title><source>Bioinformatics</source><year>2002</year><volume>18</volume><fpage>231</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/18.suppl_2.S231</pub-id></element-citation></ref><ref id="CR60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butte</surname><given-names>AJ</given-names></name><name><surname>Kohane</surname><given-names>IS</given-names></name><name><surname>Kohane</surname><given-names>IS</given-names></name></person-group><article-title>Mutual information relevance networks: Functional genomic clustering using pairwise entropy measurements</article-title><source>Pac Symp Biocomput</source><year>2000</year><volume>5</volume><fpage>415</fpage><lpage>26</lpage></element-citation></ref><ref id="CR61"><label>61</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Scutari</surname><given-names>M</given-names></name><name><surname>Denis</surname><given-names>JB</given-names></name></person-group><source>Bayesian Networks with Examples in R</source><year>2014</year><publisher-loc>Boca Raton</publisher-loc><publisher-name>Chapman and Hall</publisher-name></element-citation></ref><ref id="CR62"><label>62</label><mixed-citation publication-type="other">Conati C, Gertner AS, VanLehn K, Druzdzel MJ. On-line student modeling for coached problem solving using Bayesian networks. In: User Modeling. Springer: 1997. p. 231&#8211;42.</mixed-citation></ref><ref id="CR63"><label>63</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Andreassen</surname><given-names>S</given-names></name><name><surname>Jensen</surname><given-names>F</given-names></name><name><surname>Andersen</surname><given-names>S</given-names></name><name><surname>Falck</surname><given-names>B</given-names></name><name><surname>Kj&#230;rulff</surname><given-names>U</given-names></name><name><surname>Woldbye</surname><given-names>M</given-names></name><name><surname>S&#248;rensen</surname><given-names>A</given-names></name><name><surname>Rosenfalck</surname><given-names>A</given-names></name><name><surname>Jensen</surname><given-names>F</given-names></name></person-group><article-title>MUNIN - an Expert EMG Assistant</article-title><source>Computer-Aided Electromyography and Expert Systems, Chapter 21</source><year>1989</year><publisher-loc>Noth-Holland</publisher-loc><publisher-name>Elsevier</publisher-name></element-citation></ref><ref id="CR64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le Chatelier</surname><given-names>E</given-names></name><name><surname>Nielsen</surname><given-names>T</given-names></name><name><surname>Qin</surname><given-names>J</given-names></name><name><surname>Prifti</surname><given-names>E</given-names></name><name><surname>Hildebrand</surname><given-names>F</given-names></name><name><surname>Falony</surname><given-names>G</given-names></name><name><surname>Almeida</surname><given-names>M</given-names></name><name><surname>Arumugam</surname><given-names>M</given-names></name><name><surname>Batto</surname><given-names>JM</given-names></name><name><surname>Kennedy</surname><given-names>S</given-names></name><etal/></person-group><article-title>Richness of human gut microbiome correlates with metabolic markers</article-title><source>Nature</source><year>2013</year><volume>500</volume><issue>7464</issue><fpage>541</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1038/nature12506</pub-id><?supplied-pmid 23985870?><pub-id pub-id-type="pmid">23985870</pub-id></element-citation></ref><ref id="CR65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sales</surname><given-names>G</given-names></name><name><surname>Romualdi</surname><given-names>C</given-names></name></person-group><article-title>parmigene-a parallel r package for mutual information estimation and gene network reconstruction</article-title><source>Bioinformatics</source><year>2011</year><volume>27</volume><issue>13</issue><fpage>1876</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btr274</pub-id><?supplied-pmid 21531770?><pub-id pub-id-type="pmid">21531770</pub-id></element-citation></ref><ref id="CR66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qiu</surname><given-names>P</given-names></name><name><surname>Gentles</surname><given-names>AJ</given-names></name><name><surname>Plevritis</surname><given-names>SK</given-names></name></person-group><article-title>Fast calculation of pairwise mutual information for gene regulatory network reconstruction</article-title><source>Comput Methods Prog Biomed</source><year>2009</year><volume>94</volume><issue>2</issue><fpage>177</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1016/j.cmpb.2008.11.003</pub-id></element-citation></ref></ref-list></back></article>