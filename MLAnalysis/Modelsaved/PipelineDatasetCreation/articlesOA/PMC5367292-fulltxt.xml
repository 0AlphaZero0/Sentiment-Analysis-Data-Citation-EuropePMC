<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d1 20130915//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 39.96?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">R Soc Open Sci</journal-id><journal-id journal-id-type="iso-abbrev">R Soc Open Sci</journal-id><journal-id journal-id-type="publisher-id">RSOS</journal-id><journal-id journal-id-type="hwp">royopensci</journal-id><journal-title-group><journal-title>Royal Society Open Science</journal-title></journal-title-group><issn pub-type="epub">2054-5703</issn><publisher><publisher-name>The Royal Society Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">5367292</article-id><article-id pub-id-type="doi">10.1098/rsos.160346</article-id><article-id pub-id-type="publisher-id">rsos160346</article-id><article-categories><subj-group subj-group-type="hwp-journal-coll"><subject>1001</subject><subject>14</subject><subject>42</subject></subj-group><subj-group subj-group-type="heading"><subject>Biology (Whole Organism)</subject></subj-group><subj-group subj-group-type="leader"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Cross-modal recognition of familiar conspecifics in goats</article-title><alt-title alt-title-type="short">Cross-modal recognition in goats</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-8580-0343</contrib-id><name><surname>Pitcher</surname><given-names>Benjamin J.</given-names></name><xref ref-type="aff" rid="af1">1</xref><xref ref-type="aff" rid="af2">2</xref><xref ref-type="corresp" rid="cor1"/></contrib><contrib contrib-type="author"><name><surname>Briefer</surname><given-names>Elodie F.</given-names></name><xref ref-type="aff" rid="af1">1</xref><xref ref-type="aff" rid="af3">3</xref></contrib><contrib contrib-type="author"><name><surname>Baciadonna</surname><given-names>Luigi</given-names></name><xref ref-type="aff" rid="af1">1</xref></contrib><contrib contrib-type="author"><name><surname>McElligott</surname><given-names>Alan G.</given-names></name><xref ref-type="aff" rid="af1">1</xref><xref ref-type="corresp" rid="cor2"/></contrib></contrib-group><aff id="af1"><label>1</label><addr-line>Biological and Experimental Psychology, School of Biological and Chemical Sciences</addr-line>, <institution>Queen Mary University of London</institution>, <addr-line>Mile End Road, London E1 4NS</addr-line>, <country>UK</country></aff><aff id="af2"><label>2</label><addr-line>Department of Biological Sciences, Faculty of Science and Engineering</addr-line>, <institution>Macquarie University</institution>, <addr-line>Sydney 2109 New South Wales</addr-line>, <country>Australia</country></aff><aff id="af3"><label>3</label><addr-line>Institute of Agricultural Sciences</addr-line>, <institution>ETH Z&#252;rich</institution>, <addr-line>Universit&#228;tstrasse 2, 8092 Zurich</addr-line>, <country>Switzerland</country></aff><author-notes><corresp id="cor1">Authors for correspondence: Benjamin J. Pitcher e-mail: <email>ben.pitcher@mq.edu.au</email></corresp><corresp id="cor2">Authors for correspondence: Alan G. McElligott e-mail: <email>a.g.mcelligott@qmul.ac.uk</email></corresp><fn fn-type="other"><p>Electronic supplementary material is available online at <uri xlink:href="https://dx.doi.org/10.6084/m9.figshare.c.3679390">https://dx.doi.org/10.6084/m9.figshare.c.3679390</uri>.</p></fn></author-notes><pub-date pub-type="collection"><month>2</month><year>2017</year></pub-date><pub-date pub-type="epub"><day>15</day><month>2</month><year>2017</year></pub-date><pub-date pub-type="pmc-release"><day>15</day><month>2</month><year>2017</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. --><volume>4</volume><issue>2</issue><elocation-id>160346</elocation-id><history><date date-type="received"><day>18</day><month>5</month><year>2016</year></date><date date-type="accepted"><day>13</day><month>1</month><year>2017</year></date></history><permissions><copyright-statement>&#169; 2017 The Authors.</copyright-statement><copyright-year>2017</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>Published by the Royal Society under the terms of the Creative Commons Attribution License <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>, which permits unrestricted use, provided the original author and source are credited.</license-p></license><?release-delay 0|0?></permissions><self-uri content-type="pdf" xlink:href="rsos160346.pdf"/><abstract><p>When identifying other individuals, animals may match current cues with stored information about that individual from the same sensory modality. Animals may also be able to combine current information with previously acquired information from other sensory modalities, indicating that they possess complex cognitive templates of individuals that are independent of modality. We investigated whether goats (<italic>Capra hircus</italic>) possess cross-modal representations (auditory&#8211;visual) of conspecifics. We presented subjects with recorded conspecific calls broadcast equidistant between two individuals, one of which was the caller. We found that, when presented with a stablemate and another herd member, goats looked towards the caller sooner and for longer than the non-caller, regardless of caller identity. By contrast, when choosing between two herd members, other than their stablemate, goats did not show a preference to look towards the caller. Goats show cross-modal recognition of close social partners, but not of less familiar herd members. Goats may employ inferential reasoning when identifying conspecifics, potentially facilitating individual identification based on incomplete information. Understanding the prevalence of cross-modal recognition and the degree to which different sensory modalities are integrated provides insight into how animals learn about other individuals, and the evolution of animal communication.</p></abstract><kwd-group><kwd>individual recognition</kwd><kwd>mammals</kwd><kwd>multimodal communication</kwd><kwd>ungulates</kwd><kwd>visual recognition</kwd><kwd>vocal communication</kwd></kwd-group><funding-group specific-use="FundRef"><award-group><funding-source><institution-wrap><institution>Swiss National Science Foundation</institution></institution-wrap></funding-source></award-group></funding-group><funding-group specific-use="FundRef"><award-group><funding-source><institution-wrap><institution>Fondation Fyssen</institution><institution-id>http://dx.doi.org/10.13039/501100003135</institution-id></institution-wrap></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>cover-date</meta-name><meta-value>February, 2017</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1"><label>1.</label><title>Background</title><p>Despite once being regarded as uniquely human [<xref rid="RSOS160346C1" ref-type="bibr">1</xref>], cross-modal recognition of individuals among non-human animals has received recent interest, with the aim of understanding how animals integrate information from multiple sensory modalities. Many species are capable of identifying conspecific as well as heterospecific individuals through single sensory modalities (e.g. [<xref rid="RSOS160346C2" ref-type="bibr">2</xref>&#8211;<xref rid="RSOS160346C8" ref-type="bibr">8</xref>]). However, the cognitive mechanisms underlying recognition are poorly understood [<xref rid="RSOS160346C9" ref-type="bibr">9</xref>]. The ability to integrate identity cues across sensory modalities would demonstrate the presence of higher-order cognitive representations that are independent of modality [<xref rid="RSOS160346C9" ref-type="bibr">9</xref>,<xref rid="RSOS160346C10" ref-type="bibr">10</xref>]. This may suggest that individuals form multimodal internal representations or templates of other individuals [<xref rid="RSOS160346C10" ref-type="bibr">10</xref>].</p><p>Cross-modal recognition has recently been examined in a small number of species and shown to include both auditory&#8211;visual and auditory&#8211;olfactory recognition of individuals. Auditory (e.g. vocal) and visual information are likely to be frequently encountered together because receivers see a calling individual when looking towards the source of a sound. Horses (<italic>Equus caballus</italic>) [<xref rid="RSOS160346C9" ref-type="bibr">9</xref>], crows (<italic>Corvus macrorhynchos</italic>) [<xref rid="RSOS160346C11" ref-type="bibr">11</xref>], African lions (<italic>Panthera leo</italic>) [<xref rid="RSOS160346C12" ref-type="bibr">12</xref>] and rhesus macaques (<italic>Macaca mulatta</italic>) [<xref rid="RSOS160346C13" ref-type="bibr">13</xref>,<xref rid="RSOS160346C14" ref-type="bibr">14</xref>] are capable of forming auditory&#8211;visual representations of conspecific individuals. This ability extends to heterospecific individuals in horses [<xref rid="RSOS160346C15" ref-type="bibr">15</xref>,<xref rid="RSOS160346C16" ref-type="bibr">16</xref>], rhesus macaques [<xref rid="RSOS160346C14" ref-type="bibr">14</xref>] and dogs (<italic>Canis familiaris</italic>) [<xref rid="RSOS160346C17" ref-type="bibr">17</xref>], which have all been shown to recognize familiar humans through audio-visual matching. In scent-marking species, auditory and olfactory information about an individual may be separated in space and time. Despite this, auditory&#8211;olfactory representations of conspecifics have been identified in lemurs (<italic>Lemur catta</italic>) [<xref rid="RSOS160346C18" ref-type="bibr">18</xref>]. Animals may also form cognitive representations of other individuals using multiple components of information from a single sensory modality. For example, golden hamsters (<italic>Mesocricetus auratus</italic>) integrate different scents from a given conspecific into a cohesive representation [<xref rid="RSOS160346C19" ref-type="bibr">19</xref>]. These studies suggest that some species are capable of integrating information across sensory modalities, including modalities that are not temporally or spatially linked. However, the extent to which familiarity between conspecific individuals influences cross-modal recognition has not been explored. Previous research has examined cross-modal recognition of familiar versus unfamiliar conspecifics (e.g. [<xref rid="RSOS160346C11" ref-type="bibr">11</xref>]), but have not addressed more subtle degrees of familiarity, such as close social affiliates versus &#8216;acquaintances&#8217;. If recognition, and particularly cross-modal recognition, is costly, animals may invest more in recognizing close social partners that are likely to be encountered more frequently, or over long periods of time, than those that are encountered infrequently.</p><p>Goats (<italic>Capra hircus</italic>) possess a number of characteristics that suggest they would benefit from advanced recognition abilities. Goats display good physical cognition abilities and long-term memory [<xref rid="RSOS160346C20" ref-type="bibr">20</xref>,<xref rid="RSOS160346C21" ref-type="bibr">21</xref>]. They also show basic social cognition, following conspecific gaze and human pointing to find hidden food [<xref rid="RSOS160346C22" ref-type="bibr">22</xref>], show audience-dependent human-directed behaviour in problem solving tasks [<xref rid="RSOS160346C23" ref-type="bibr">23</xref>] and learn socially from humans [<xref rid="RSOS160346C24" ref-type="bibr">24</xref>]. Further, goats are capable of some visual perspective taking, preferring to eat food that is out of the view of aggressive dominant individuals [<xref rid="RSOS160346C25" ref-type="bibr">25</xref>]. In the wild, goats live in complex, fission&#8211;fusion social groups where they forage in smaller groups during the day and aggregate in larger &#8216;night camps&#8217; overnight, and these social groups have strong hierarchies [<xref rid="RSOS160346C26" ref-type="bibr">26</xref>&#8211;<xref rid="RSOS160346C29" ref-type="bibr">29</xref>]. Together, these traits indicate potential higher-order cognitive abilities in goats and the presence of complex social relationships that may require the ability to recognize a number of individuals.</p><p>Goat vocalizations provide listeners with a range of information about callers, including their physical characteristics, social group membership, individual identity and emotions [<xref rid="RSOS160346C2" ref-type="bibr">2</xref>,<xref rid="RSOS160346C30" ref-type="bibr">30</xref>&#8211;<xref rid="RSOS160346C32" ref-type="bibr">32</xref>]. Individual stereotypy of calls allows for individual vocal recognition, with both mothers and offspring displaying the ability to recognize each other using vocalizations alone [<xref rid="RSOS160346C2" ref-type="bibr">2</xref>]. Further, goats have long-term memory of individuals' vocalizations and vocal recognition may play an important role in social relationships, such as kin recognition and inbreeding avoidance [<xref rid="RSOS160346C33" ref-type="bibr">33</xref>]. Because of their important role in social interactions, it is likely that vocalizations form part of a cross-modal recognition system in goats.</p><p>The evidence for individual recognition in goats using visual cues is less clear than for auditory cues. Kids may use pelage pigmentation as a cue when searching for mothers in a herd, and are more prone to errors when presented with females with similar pelage coloration as their mothers [<xref rid="RSOS160346C34" ref-type="bibr">34</xref>,<xref rid="RSOS160346C35" ref-type="bibr">35</xref>]. Further, in social contexts, adult goats appear to use visual cues originating from an individual's body to discriminate social group from non-social group members [<xref rid="RSOS160346C36" ref-type="bibr">36</xref>]. While further controlled experiments of non-auditory recognition in goats are necessary, these studies imply that both visual and auditory cues are involved in individual recognition in goats and suggest the potential for cross-modal individual recognition.</p><p>In this study, we examined whether adult goats possess cross-modal representations (auditory combined with visual) of adult individuals that varied in their level of familiarity. Using a cross-modal preferential looking paradigm (e.g. [<xref rid="RSOS160346C37" ref-type="bibr">37</xref>,<xref rid="RSOS160346C38" ref-type="bibr">38</xref>]), we first presented goats with calls of either their stablemate (individual sharing their pen at night) or another familiar herd member in an arena where they could simultaneously observe both individuals. Secondly, we presented them with calls of one of two herd members, in order to test whether goats possess cross-modal representations of other, less familiar individuals than their stablemate. If goats were capable of integrating information across modalities, we predicted that upon hearing the call of an individual, they would look towards the congruent individual (the individual producing the call) faster and for longer than they would look towards the incongruent individual. Further, we predicted that familiarity would influence cross-modal recognition. While all animals in the study population were familiar to each other, we hypothesized that cross-modal recognition would be more developed among close social partners.</p></sec><sec sec-type="methods" id="s2"><label>2.</label><title>Material and methods</title><sec id="s2a"><label>2.1.</label><title>Experimental location and study animals</title><p>This study was conducted at Buttercups Sanctuary for Goats, Kent, UK (<uri xlink:href="http://www.buttercups.org.uk">http://www.buttercups.org.uk</uri>), during June 2012. At the time, the sanctuary housed 125 domestic goats in a mixed herd of sexes and breeds (males in the herd are castrated, females are intact). At night, goats are housed in stables individually or in groups of two or three (average pen size&#8201;=&#8201;3.5&#8201;m<sup>2</sup>) with straw bedding, within a larger stable complex. During the day, all goats are released together and can freely move between the stable complex and a large field (2&#8201;ha) containing several hay racks. Routine care of the animals is provided by sanctuary employees and volunteers. Goats have ad libitum access to hay, grass (during the day) and water, and are also fed with a commercial concentrate in quantities according to their state and age.</p><p>Ten goats (five females and five castrated males) were chosen as experimental subjects. These goats were fully habituated to human presence and had been used in previous studies [<xref rid="RSOS160346C20" ref-type="bibr">20</xref>,<xref rid="RSOS160346C32" ref-type="bibr">32</xref>,<xref rid="RSOS160346C39" ref-type="bibr">39</xref>,<xref rid="RSOS160346C40" ref-type="bibr">40</xref>]. For each subject we identified four individuals to be used as visual and audio stimuli during playbacks. These consisted of a &#8216;stablemate&#8217; (sharing their pen at night) and three, non-stablemate, familiar individuals (herd member). Stablemates were social partners that were housed together at night in pairs with the subjects, seen closely associating during the day and never seen involved in agonistic interactions (E. Briefer 2012, personal observation; C. Nawroth 2012, personal communication). Herd members were also familiar individuals, but not housed with the subjects and not observed to be close social partners. Herd members were randomly chosen from the population. All the individuals had been housed at the sanctuary for at least 3 years prior to the experiment, allowing them to become familiar with other individuals. The pairs of stimulus goats used in each presentation were the same sex.</p></sec><sec id="s2b"><label>2.2.</label><title>Auditory stimulus preparation</title><p>The contact calls of both the stablemates and herd members were recorded using a Sennheiser MKH 70 directional microphone in a Rycote Windshield and Windjammer, connected to a Marantz PMD 661 digital recorder (sampling rate of 44.1&#8201;kHz and amplitude resolution of 16 bits in WAV format). Calls were recorded in May 2012, approximately one month before the playbacks. Contact calls were recorded during 5&#8201;min of isolation in a familiar pen at the study site, as part of another study [<xref rid="RSOS160346C41" ref-type="bibr">41</xref>]. Recordings with good signal-to-noise ratios were used to construct playback presentations. Presentations were prepared using Adobe A<sc>udition</sc> 3 (Adobe Systems Incorporated, San Jose, CA, USA). All calls were normalized to 90% and saved as 44.1&#8201;kHz, 16 bit.wav format sound files for playback. Presentations consisted of two different contact calls (approx. 1&#8201;s duration each). Each call was followed by 10&#8201;s of silence (total duration, approx. 22&#8201;s). Playback presentations were made using an Edirol R-09 audio player at an approximately natural amplitude (76.7&#8201;&#177;&#8201;0.8&#8201;dB (mean&#8201;&#177;&#8201;s.e.)).</p></sec><sec id="s2c"><label>2.3.</label><title>Experimental design and presentation arena</title><p>To examine cross-modal recognition, we used a preferential looking paradigm that is commonly used to examine cross-modal associations in humans and non-human animals [<xref rid="RSOS160346C37" ref-type="bibr">37</xref>,<xref rid="RSOS160346C38" ref-type="bibr">38</xref>]. This experimental design is based on the assumption that if an association exists between two cues, the presence of one cue will stimulate attention towards the other cue. Consequently, in the choice-test used in the present study, if cross-modal recognition existed, the presence of a vocal signal from a known individual was expected to trigger increased attention towards that individual in preference to the other individual.</p><p>Playbacks were conducted in a triangular arena built within the large field surrounding the stable complex, where goats were released during the day (<xref ref-type="fig" rid="RSOS160346F1">figure&#160;1</xref>). The arena was isolated from other goats using fences and consisted of three pens. The subject goat was placed in the central pen, facing the other two pens. A stimulus goat, either a stablemate or a herd member, was placed in each of the other two pens. A speaker (Mackie Thump TH-12A) was located equidistant between the two stimulus goats and obscured by camouflage netting. A video camera (Canon LEGRIA) was mounted on a tripod above the speaker, orientated towards the subject, and a line was marked on the ground between the camera and the subject to facilitate the identification of the subject's gaze direction. The playback arena was located against a fence with vegetation behind the stimulus goats, to prevent other animals from moving behind the stimulus and minimize visual distractions to the subject. Playback presentations were controlled by an experimenter located approximately 10&#8201;m behind the subject and obscured from the subjects' view. Playback treatments consisted of two different calls from the same individual, separated by 10&#8201;s of silence, during which time the subject could look towards either of the stimulus goats.
<fig id="RSOS160346F1" orientation="portrait" position="float"><label>Figure 1.</label><caption><p>(<italic>a</italic>) Presentation arena schematic. The presentation arena was separated from the field by a solid metal fence (solid line). Within the arena, enclosures consisted of portable metal fencing with bars approximately 10&#8201;cm apart (dotted lines). The subject (1) was placed in the central enclosure after two stimulus goats (2) had been placed in the triangular enclosures. A camera and speaker (3) were located equidistant between the stimulus goats, facing the subject. The arena was located against a timber fence (dashed line) with vegetation behind (4) to prevent other animals from moving behind the stimulus and minimize visual distractions to the subject. (<italic>b</italic>) A photo of the presentation arena.
</p></caption><graphic xlink:href="rsos160346-g1"/></fig></p></sec><sec id="s2d"><label>2.4.</label><title>Playback Series One</title><p>During Playback Series One, each subject was presented with a choice between its stablemate and a random herd member (the same goat throughout the series). Subject goats each received three treatments in the following order: (i) calls of the stablemate; (ii) calls of the herd member, while the side where the stablemate was presented (right or left pen, determined randomly) remained unchanged; and (iii) calls of the stablemate again, after exchanging the presentation sides of the stablemate and herd member. The first treatment was presented on one day and the remaining two were presented 6 days later, on the same day, a minimum of 2&#8201;h apart.</p></sec><sec id="s2e"><label>2.5.</label><title>Playback Series Two</title><p>To determine if goats were capable of cross-modal recognition of familiar individuals, in general, or if it was restricted to closer social partners, a second series of playbacks was conducted. During the second series of playbacks, subjects were presented with a choice between two random herd members (different stimulus goats to those used during Playback Series One). Each subject received two treatments: (i) calls of one of the presented herd member, and (ii) calls of the other herd member, while the presentation sides remained unchanged. These two treatments were presented on the same day.</p></sec><sec id="s2f"><label>2.6.</label><title>Playback procedure</title><p>The two stimulus goats were led from the field into the arena by experimenters and tethered in their enclosures on either side of the arena. The subject goat was then led into the central enclosure and tethered so that it faced the speaker and video camera, but was able to turn its head to the sides. Subject goats were allowed to habituate to the presentation arena for approximately 5&#8201;min before presentations. As far as possible, the subject was looking neutrally towards the camera when the first of the playback calls was given (at the beginning of the playback), and not directly at either stimulus goat. Presentations were filmed for later analysis. Stimulus goats did not vocalize during presentations and were not seen to show behaviours such as sudden movements that might attract the attention of the subject. Subjects were not rewarded during presentations. All goats were released back into the field with the herd at the end of the presentation.</p></sec><sec id="s2g"><label>2.7.</label><title>Video analysis</title><p>Videos of the experiments were analysed by an observer who was blind to the presentation type. For each call played back (<italic>n</italic>&#8201;=&#8201;2 per playback), the observer recorded two measures of responses: (i) the latencies from the onset of the call for the subject to look at each of the stimulus goats; and (ii) the duration of time spent looking at each goat, for 10&#8201;s from the onset of the call. This resulted, for each measure of response, in two values per call played back, one for each stimulus goat (i.e. four values for each playback). Looking at a stimulus goat was defined as orienting the head towards an individual in the area of binocular vision, approximately 60&#176; along the midline of the head [<xref rid="RSOS160346C42" ref-type="bibr">42</xref>].</p></sec><sec id="s2h"><label>2.8.</label><title>Statistical analysis</title><p>In order to investigate if subjects were able to attribute the calls played back to the congruent stimulus goat, we compared their latency to look and duration of time spent looking at the congruent and incongruent individuals using linear mixed effects models (LMM; lmer function, lme4 library) in Rv.&#160;3.2.2 (R Development Core Team, 2015). The congruent individual was defined as the stimulus goat whose calls were played back and the incongruent individual was the other stimulus goat. Because the Playback Series One (stablemate versus herd member; <italic>n</italic>&#8201;=&#8201;30 playbacks, 10 goats) and Two (two herd members; <italic>n</italic>&#8201;=&#8201;20 playbacks, 10 goats) were carried out at different times and using different herd members as stimuli, their data were analysed separately. The latency to look and duration of time spent looking were fitted as dependent variables (two separate models for each playback series). Latency values in which the subject did not look at a given stimulus goat (<italic>n</italic>&#8201;=&#8201;63 values for the first series and <italic>n</italic>&#8201;=&#8201;37 values for the second series) were omitted from the analyses (e.g. if the subject did not look at the incongruent individual at all during a playback, no latency to look was included for this stimulus goat). This approach is more conservative than attributing a latency corresponding to a maximum possible value. In addition, latency values of 0 (<italic>n</italic>&#8201;=&#8201;6 values for the first series and <italic>n</italic>&#8201;=&#8201;6 values for the second series), indicating that the subject was already looking at the stimulus goat when the call started were omitted in order to control for initial side biases. In total, we thus included <italic>n</italic>&#8201;=&#8201;51 latency values for the first series of playbacks and <italic>n</italic>&#8201;=&#8201;37 latency values for the second series, whereas all duration values were included (<italic>n</italic>&#8201;=&#8201;120 values: 3 playbacks&#8201;&#215;&#8201;2 calls&#8201;&#215;&#8201;2 stimulus goats&#8201;&#215;&#8201;10 subjects for the first series of playbacks; and <italic>n</italic>&#8201;=&#8201;80 values: 2 playbacks&#8201;&#215;&#8201;2 calls&#8201;&#215;&#8201;2 stimulus goat&#8201;&#215;&#8201;10 subjects for the second series). The type of stimulus goat (congruent individual&#8212;corresponding to the playback; or incongruent&#8212;other individual) was included as a fixed effect, in order to compare the latency to look and duration of time spent looking at each of these goats. In the two models carried out on the first series of playbacks, the caller category (stablemate or herd member), as well as the interaction between caller category and type of stimulus goat (congruent or incongruent), were included as fixed factors, to test if the ability of subjects to attribute calls to the congruent stimulus goats differed between playbacks of stablemate and herd member calls. When it was not significant, the interaction term was removed from the models [<xref rid="RSOS160346C43" ref-type="bibr">43</xref>]. Two control factors were also included in all models: (i) because each playback consisted of two different calls from the same individual, we included the call number (1 or 2) as a fixed factor to control for any order effect; and (ii) the side (right or left) where the congruent individual was situated was included as a fixed factor to control for potential side biases. Finally, all models included as a random factor the playback number (1&#8211;5 for each goat) nested within the subject identity, in order to control for repeated measurements of the same subjects within and between playbacks, and for differences between playbacks (as four values per playbacks were included: 2 calls&#8201;&#215;&#8201;2 stimulus goats).</p><p>We checked the model residuals graphically for normal distribution and homoscedasticity. Models were fit with restricted maximum-likelihood method (RELM). The significance level was set at <italic>&#945;</italic>&#8201;=&#8201;0.05.</p></sec></sec><sec id="s3"><label>3.</label><title>Results</title><p>Subjects presented with a choice between their stablemate and a herd member (Playback Series One) looked faster (<italic>Z</italic>&#8201;=&#8201;2.61, <italic>n</italic>&#8201;=&#8201;51 latencies, <italic>p</italic>&#8201;=&#8201;0.009; <xref ref-type="fig" rid="RSOS160346F2">figure&#160;2</xref>) and for a longer duration (LMM: <italic>Z</italic>&#8201;=&#8201;&#8722;3.37, <italic>n</italic>&#8201;=&#8201;120 durations, <italic>p</italic>&#8201;=&#8201;0.0008; <xref ref-type="fig" rid="RSOS160346F3">figure&#160;3</xref>) at the congruent compared to the incongruent stimulus goat, regardless of whether the calls played were those of the stablemate or herd member (i.e. the caller category and the interaction between caller category and type of stimulus goat had no effect on the results; caller category: latency, <italic>Z</italic>&#8201;=&#8201;0.58, <italic>p</italic>&#8201;=&#8201;0.56; duration, <italic>Z</italic>&#8201;=&#8201;&#8722;0.30, <italic>p</italic>&#8201;=&#8201;0.76; interaction term: latency, <italic>Z</italic>&#8201;=&#8201;&#8722;1.21, <italic>p</italic>&#8201;=&#8201;0.23; duration, <italic>Z</italic>&#8201;=&#8201;1.51, <italic>p</italic>&#8201;=&#8201;0.13). However, when presented with a choice between two random herd members (Playback Series Two), the subjects did not behave differently towards the congruent and incongruent stimulus goat (latency: <italic>Z</italic>&#8201;=&#8201;0.68, <italic>n</italic>&#8201;=&#8201;37 latencies, <italic>p</italic>&#8201;=&#8201;0.50; <xref ref-type="fig" rid="RSOS160346F2">figure&#160;2</xref>; duration: <italic>Z</italic>&#8201;=&#8201;0.14, <italic>n</italic>&#8201;=&#8201;80 durations, <italic>p</italic>&#8201;=&#8201;0.89; <xref ref-type="fig" rid="RSOS160346F3">figure&#160;3</xref>). To summarize, goats looked faster and for longer at the congruent compared to the incongruent stimulus goat, only when presented with a choice between their stablemate and another herd member (electronic supplementary material, Video S1). When presented with two random, less familiar, herd members, goats did not show a preference to look towards either individual.
<fig id="RSOS160346F2" orientation="portrait" position="float"><label>Figure 2.</label><caption><p>Latency to look. Latency to look at the congruent (C) or incongruent (I) stimulus goat during the first series of playbacks (stablemate versus herd member; in white) and during the second series of playbacks (herd member versus herd member; in grey), (box plot: the horizontal line shows the median, the box extends from the lower to the upper quartile and the whiskers to 1.5 times the interquartile range above the upper quartile or below the lower quartile; the black circles indicate the means; <italic>n</italic>&#8201;=&#8201;10 goats; linear mixed effects models: **<italic>p</italic>&#8201;&lt;&#8201;0.01, n.s.&#8201;, non-significant).
</p></caption><graphic xlink:href="rsos160346-g2"/></fig>
<fig id="RSOS160346F3" orientation="portrait" position="float"><label>Figure 3.</label><caption><p>Duration of looks. Duration of time spent looking at the congruent (C) or incongruent (I) stimulus goat during the first series of playbacks (stablemate versus herd member; in white) and during the second series of playbacks (herd member versus herd member; in grey), (box plot: the horizontal line shows the median, the box extends from the lower to the upper quartile and the whiskers to 1.5 times the interquartile range above the upper quartile or below the lower quartile; empty circles indicate outliers; the black circles indicate the means; <italic>n</italic>&#8201;=&#8201;10 goats; linear mixed effects models: ***<italic>p</italic>&#8201;&lt;&#8201;0.001, n.s., non-significant).</p></caption><graphic xlink:href="rsos160346-g3"/></fig></p></sec><sec id="s4"><label>4.</label><title>Discussion</title><p>Using a preferential looking paradigm, we examined cross-modal correspondence between auditory and visual cues during individual recognition in goats. We hypothesized that, upon hearing a pre-recorded call, goats would look more rapidly and for longer towards the individual perceived as the source of the call. Subjects looked sooner and for longer towards the congruent stimulus goat when differentiating between a stablemate and a herd member. Therefore, goats are capable of cross-modal recognition of familiar social partners. However, subjects did not show a preference to look towards a particular individual when presented with two less familiar herd members. Further, goats appeared to exclude their stablemate as a potential caller when they heard the call of another individual. This suggests that goats may use inferential reasoning [<xref rid="RSOS160346C44" ref-type="bibr">44</xref>,<xref rid="RSOS160346C45" ref-type="bibr">45</xref>] during identification of conspecific callers. The circumstances in which cross-modal recognition occurs, and how individuals interpret signals has the potential to reveal how recognition systems evolve. The ways in which animals acquire information and perceive others provides a deeper understanding of animal cognition in general [<xref rid="RSOS160346C9" ref-type="bibr">9</xref>,<xref rid="RSOS160346C10" ref-type="bibr">10</xref>,<xref rid="RSOS160346C44" ref-type="bibr">44</xref>]. Our results show that familiarity influences cross-modal recognition with goats showing cross-modal recognition of close social partners but not of less familiar individuals, and that goats potentially use inference when processing conspecific signals.</p><p>We found that goats are capable of integrating information across two sensory modalities during recognition tasks, and are likely to possess internal templates or representations of other individuals comprising multimodal information. Further, while previous studies on goats have focused on vocal recognition in mother&#8211;offspring dyads [<xref rid="RSOS160346C2" ref-type="bibr">2</xref>], we found that adult goats are capable of cross-modally recognizing adult social partners. The recognition patterns that we observed are consistent with the social structure of these goats. In natural settings, goats typically forage in small groups during the day and congregate in larger groups overnight [<xref rid="RSOS160346C27" ref-type="bibr">27</xref>]. At the study site, the grouping pattern is somewhat reversed, i.e. goats forage in larger groups during the day and are stabled in smaller groups at night. However, it is somewhat surprising that goats did not appear to show cross-modal recognition of the two herd members because, although being less familiar than the stablemate, herd members had previous interactions with the subjects. In capuchin monkeys (<italic>Cebus apella</italic>) the ability to match pairs of images of conspecific faces also appears to be influenced by familiarity [<xref rid="RSOS160346C46" ref-type="bibr">46</xref>]. Capuchins performed better at matching images of familiar faces than unfamiliar faces, but were equally able to match faces of individuals living in their own social group and those living in a neighbouring group that they had daily visual and vocal access to. The ability of goats to cross-modally recognize stablemates, but not other herd members is potentially owing to very high familiarity and more frequent social interactions between stablemates than with other herd members.</p><p>It is often difficult to distinguish between individual recognition and class-level recognition, in which receivers learn individually distinctive characteristics of signallers and associate these with inferred class-specific information about them [<xref rid="RSOS160346C10" ref-type="bibr">10</xref>]. Proops <italic>et al.</italic> [<xref rid="RSOS160346C9" ref-type="bibr">9</xref>] proposed that, in order to demonstrate individual recognition, a paradigm must show that discrimination operates at an individual level and that there is a matching of current sensory information with stored information about that specific individual. Our results show that goats are capable of associating a stablemate's vocalization with visual information about this individual, which they have previously acquired. However, because goats did not show an association between calls and visual cues for other, less familiar herd members, it is difficult to determine if what we observed is class recognition (stablemate versus other) or individual recognition mediated by familiarity and the opportunity to learn other individuals' unique traits. In either case, goats appear to display cognitive representations of close social partners.</p><p>While vocal recognition of conspecifics has been demonstrated in goats [<xref rid="RSOS160346C2" ref-type="bibr">2</xref>], it is unlikely that the sound of the caller alone was sufficient to elicit the response observed. During presentations, the sound source was equidistant between individuals and they remained silent during presentations. Another modality of information, such as visual and/or olfactory, was required to provide the necessary cues for the subject to look towards the congruent individual. In our experimental design, the subject potentially had access to both visual and olfactory information about the stimulus goats. However, previous research that examined olfactory recognition in goats and sheep, particularly in mother&#8211;offspring recognition, found that close contact (i.e. less than 1&#8201;m) is necessary for the successful use of olfactory cues [<xref rid="RSOS160346C47" ref-type="bibr">47</xref>]. The subject and stimulus individuals in the current experiment were separated by at least 1.85&#8201;m, suggesting that subjects were more likely to be using visual&#8211;auditory cross-modal matching than olfactory&#8211;auditory.</p><p>One possible explanation for the association between a stablemate's call and looking towards that individual is a preference for looking towards familiar individuals. Domestic dogs fixate more often on the familiar faces of both conspecifics and humans than on unfamiliar faces [<xref rid="RSOS160346C48" ref-type="bibr">48</xref>]. Similarly, rhesus macaques fixate more rapidly on familiar conspecific faces than unfamiliar individuals [<xref rid="RSOS160346C49" ref-type="bibr">49</xref>]. In the first series of presentations, subjects did look towards the congruent individual faster and for longer than the incongruent individual when choosing between a stablemate and a herd member. However, subjects looked more at the congruent individual, regardless of whether they were the stablemate or not, indicating that goats were not simply looking towards the most familiar individual.</p><p>The current limited body of the literature on cross-modal recognition can provide insights into the factors that may lead to the evolution of cross-modal recognition [<xref rid="RSOS160346C38" ref-type="bibr">38</xref>]. These species all display extended social relationships with conspecifics [<xref rid="RSOS160346C9" ref-type="bibr">9</xref>,<xref rid="RSOS160346C11" ref-type="bibr">11</xref>,<xref rid="RSOS160346C13" ref-type="bibr">13</xref>,<xref rid="RSOS160346C14" ref-type="bibr">14</xref>,<xref rid="RSOS160346C18" ref-type="bibr">18</xref>], while some of those that have been shown to have cross-modal recognition of humans have a long history of domestication, i.e. horses [<xref rid="RSOS160346C15" ref-type="bibr">15</xref>,<xref rid="RSOS160346C16" ref-type="bibr">16</xref>] and dogs [<xref rid="RSOS160346C17" ref-type="bibr">17</xref>,<xref rid="RSOS160346C50" ref-type="bibr">50</xref>]. Goats appear to show similar traits to these species, with complex social relationships [<xref rid="RSOS160346C27" ref-type="bibr">27</xref>], as well as good physical and social cognitive abilities [<xref rid="RSOS160346C20" ref-type="bibr">20</xref>,<xref rid="RSOS160346C22" ref-type="bibr">22</xref>,<xref rid="RSOS160346C25" ref-type="bibr">25</xref>]. Examination of cross-modal recognition of humans by goats would be informative, as would investigation of a broader range of taxa, to determine if cross-modal recognition is associated with particular social or cognitive traits.</p><p>In the first series of presentations, when presented with a stablemate and a herd member, goats looked faster and for longer towards both the stablemate and the herd member after hearing their respective calls. However, in the second series of presentations, goats were unable to identify the caller when choosing between two herd members. This suggests that the choice to look towards the herd member in the first series of presentations may be based on an understanding that the call did not originate from the stablemate. This differential response to herd member calls between the two series suggests that goats may be capable of forming associations between auditory and visual cues through inferential reasoning, particularly &#8216;inference by exclusion&#8217; [<xref rid="RSOS160346C44" ref-type="bibr">44</xref>]. Inference by exclusion involves the selection of the correct alternative by logically excluding other potential alternatives. Inference by exclusion has been proposed as a way by which animals may deal with inconsistent or incomplete information in their environments [<xref rid="RSOS160346C44" ref-type="bibr">44</xref>]. Previously, goats have been shown to use indirect information to locate food during an object-choice task, suggesting that goats potentially use inferential reasoning in other cognitive tasks [<xref rid="RSOS160346C45" ref-type="bibr">45</xref>]. In a social context, inference by exclusion is likely to allow individuals to acquire new associations, such as cross-modal linkages, without directly interacting with all individuals. Further experiments designed to explicitly examine inferential reasoning are needed to determine if goats possess this cognitive ability.</p><p>Using a preferential looking task, Proops &amp; McComb [<xref rid="RSOS160346C16" ref-type="bibr">16</xref>] found that horses did not look towards unfamiliar humans when presented with their voice and a choice between the unfamiliar individual and a familiar handler. They suggest that this might indicate an inability to infer that an unknown voice originates from an unknown individual. Alternatively, they suggest that individuals might not be motivated to respond to a stranger. Further investigation into inference by exclusion in the recognition of other individuals, and its potential role in learning and the formation of cross-modal cognitive representations, would provide a greater understanding of how animals acquire information and perceive others.</p><p>Our results indicate that goats are likely to form cross-modal cognitive representations of conspecifics, and particularly of close social partners. However, the results of this study should be considered in light of its limited sample size. A larger sample size in Playback Series Two may also have shown that goats do cross-modally recognize less familiar individuals. Future studies of cross-modal recognition in goats should explore how individuals acquire information about conspecifics, including further exploring the extent to which familiarity influences the presence and accuracy of recognition abilities, as well as cross-modal recognition of other species such as humans. Further, while we attempted to control for side bias and to limit habituation, future studies could include additional suitable controls for these potential effects (e.g. [<xref rid="RSOS160346C16" ref-type="bibr">16</xref>]).</p></sec><sec id="s5"><label>5.</label><title>Conclusion</title><p>In conclusion, these results suggest that goats are capable of cross-modal recognition, and that the ability to recognize individuals is influenced by the level of familiarity between conspecifics. It is likely that, when recognizing close social partners, goats use cognitive templates that integrate information from multiple sensory modalities [<xref rid="RSOS160346C9" ref-type="bibr">9</xref>,<xref rid="RSOS160346C10" ref-type="bibr">10</xref>]. Further, goats appear to use inference by exclusion when processing social signals [<xref rid="RSOS160346C44" ref-type="bibr">44</xref>,<xref rid="RSOS160346C45" ref-type="bibr">45</xref>]. This may allow individuals to acquire new associations without requiring comprehensive investigation of other individuals. By examining cross-modal recognition in a diverse array of taxa, we can develop an understanding of the degree to which species can integrate information from multiple sensory modalities, and reveal insights into learning and the evolution of animal communication.</p></sec></body><back><ack><title>Acknowledgements</title><p>We thank Bob Hitch and all the staff and volunteers of Buttercups Sanctuary for Goats (<uri xlink:href="http://www.buttercups.org.uk">http://www.buttercups.org.uk</uri>) for their excellent help and free access to the animals. We also thank Amy Donnison for assistance. We thank Natalia Albuquerque and an anonymous reviewer for their time and helpful comments.</p></ack><sec id="s6"><title>Ethics</title><p>Animal care and all experimental procedures were in accordance with the ASAB/ABS Guidelines for the Use of Animals in Research [<xref rid="RSOS160346C51" ref-type="bibr">51</xref>]. Goats were habituated to being led on a leash and experimental arenas. All goats were continually observed by experimenters during presentations, and were released into the field at the conclusion of presentations. The tests were non-invasive and behaviours indicating stress (e.g. vocalizations) were monitored throughout the exposure to playback. None of the goats displayed signs of distress during the study.</p></sec><sec id="s7"><title>Data accessibility</title><p>Data available from the Dryad Digital Repository: <uri xlink:href="http://dx.doi.org/10.5061/dryad.gp8ck">http://dx.doi.org/10.5061/dryad.gp8ck</uri> [<xref rid="RSOS160346C52" ref-type="bibr">52</xref>].</p></sec><sec id="s8"><title>Authors' contributions</title><p>All authors conceived and designed the experiment, drafted the manuscript and gave final approval for publication. B.J.P., E.F.B. and L.B. collected the data. E.F.B. conducted the statistical analysis.</p></sec><sec id="s9"><title>Competing interests</title><p>We have no competing interests.</p></sec><sec id="s10"><title>Funding</title><p>Funding for this project was provided by a Fyssen Foundation Fellowship to B.J.P. and a Swiss National Science Foundation Fellowship to E.F.B.</p></sec><ref-list><title>References</title><ref id="RSOS160346C1"><label>1</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Ettlinger</surname><given-names>G</given-names></name></person-group>
<year>1967</year>
<article-title>Analysis of cross-modal effects and their relationship to language</article-title>. In <source>Brain mechanisms underlying speech</source> (ed. <person-group person-group-type="editor"><name name-style="western"><surname>Darley</surname><given-names>FL</given-names></name></person-group>), pp. <fpage>53</fpage>&#8211;<lpage>60</lpage>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Grune &amp; Stratton</publisher-name>.</mixed-citation></ref><ref id="RSOS160346C2"><label>2</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Briefer</surname><given-names>E</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2011</year>
<article-title>Mutual mother-offspring vocal recognition in an ungulate hider species (<italic>Capra hircus</italic>)</article-title>. <source>Anim. Cogn.</source>
<volume>14</volume>, <fpage>585</fpage>&#8211;<lpage>598</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10071-011-0396-3">doi:10.1007/s10071-011-0396-3</ext-link>)<pub-id pub-id-type="pmid">21503689</pub-id></mixed-citation></ref><ref id="RSOS160346C3"><label>3</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Coulon</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Deputte</surname><given-names>BL</given-names></name>, <name name-style="western"><surname>Heyman</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Baudoin</surname><given-names>C</given-names></name></person-group>
<year>2009</year>
<article-title>Individual recognition in domestic cattle (<italic>Bos taurus</italic>): evidence from 2D-images of heads from different breeds</article-title>. <source>PLoS ONE</source>
<volume>4</volume>, <fpage>e4441</fpage> (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0004441">doi:10.1371/journal.pone.0004441</ext-link>)<pub-id pub-id-type="pmid">19212439</pub-id></mixed-citation></ref><ref id="RSOS160346C4"><label>4</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huber</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Racca</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Scaf</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Vir&#225;nyi</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Range</surname><given-names>F</given-names></name></person-group>
<year>2013</year>
<article-title>Discrimination of familiar human faces in dogs (<italic>Canis familiaris</italic>)</article-title>. <source>Learn. Motiv.</source>
<volume>44</volume>, <fpage>258</fpage>&#8211;<lpage>269</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.lmot.2013.04.005">doi:10.1016/j.lmot.2013.04.005</ext-link>)<pub-id pub-id-type="pmid">24187385</pub-id></mixed-citation></ref><ref id="RSOS160346C5"><label>5</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kendrick</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Atkins</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Hinton</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Broad</surname><given-names>KD</given-names></name>, <name name-style="western"><surname>Fabre-Nys</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Keverne</surname><given-names>B</given-names></name></person-group>
<year>1995</year>
<article-title>Facial and vocal discrimination in sheep</article-title>. <source>Anim. Behav.</source>
<volume>49</volume>, <fpage>1665</fpage>&#8211;<lpage>1676</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0003-3472(95)90088-8">doi:10.1016/0003-3472(95)90088-8</ext-link>)</mixed-citation></ref><ref id="RSOS160346C6"><label>6</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pitcher</surname><given-names>BJ</given-names></name>, <name name-style="western"><surname>Harcourt</surname><given-names>RG</given-names></name>, <name name-style="western"><surname>Charrier</surname><given-names>I</given-names></name></person-group>
<year>2010</year>
<article-title>Rapid onset of maternal vocal recognition in a colonially breeding mammal, the Australian sea lion</article-title>. <source>PLoS ONE</source>
<volume>5</volume>, <fpage>e12195</fpage> (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0012195">doi:10.1371/journal.pone.0012195</ext-link>)<pub-id pub-id-type="pmid">20730045</pub-id></mixed-citation></ref><ref id="RSOS160346C7"><label>7</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pitcher</surname><given-names>BJ</given-names></name>, <name name-style="western"><surname>Harcourt</surname><given-names>RG</given-names></name>, <name name-style="western"><surname>Schaal</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Charrier</surname><given-names>I</given-names></name></person-group>
<year>2010</year>
<article-title>Social olfaction in marine mammals: wild female Australian sea lions can identify their pup's scent</article-title>. <source>Biol. Lett.</source>
<volume>7</volume>, <fpage>60</fpage>&#8211;<lpage>62</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rsbl.2010.0569">doi:10.1098/rsbl.2010.0569</ext-link>)<pub-id pub-id-type="pmid">20685695</pub-id></mixed-citation></ref><ref id="RSOS160346C8"><label>8</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Torriani</surname><given-names>MVG</given-names></name>, <name name-style="western"><surname>Vannoni</surname><given-names>E</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2006</year>
<article-title>Mother-young recognition in an ungulate hider species: a unidirectional process</article-title>. <source>Am. Nat.</source>
<volume>168</volume>, <fpage>412</fpage>&#8211;<lpage>420</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1086/506971">doi:10.1086/506971</ext-link>)<pub-id pub-id-type="pmid">16947115</pub-id></mixed-citation></ref><ref id="RSOS160346C9"><label>9</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Proops</surname><given-names>L</given-names></name>, <name name-style="western"><surname>McComb</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Reby</surname><given-names>D</given-names></name></person-group>
<year>2009</year>
<article-title>Cross-modal individual recognition in domestic horses (<italic>Equus caballus</italic>)</article-title>. <source>Proc. Natl Acad. Sci. USA</source>
<volume>106</volume>, <fpage>947</fpage>&#8211;<lpage>951</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0809127105">doi:10.1073/pnas.0809127105</ext-link>)<pub-id pub-id-type="pmid">19075246</pub-id></mixed-citation></ref><ref id="RSOS160346C10"><label>10</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tibbetts</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>Dale</surname><given-names>J</given-names></name></person-group>
<year>2007</year>
<article-title>Individual recognition: it is good to be different</article-title>. <source>Trends Ecol. Evol.</source>
<volume>22</volume>, <fpage>529</fpage>&#8211;<lpage>537</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tree.2007.09.001">doi:10.1016/j.tree.2007.09.001</ext-link>)<pub-id pub-id-type="pmid">17904686</pub-id></mixed-citation></ref><ref id="RSOS160346C11"><label>11</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kondo</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Izawa</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Watanabe</surname><given-names>S</given-names></name></person-group>
<year>2012</year>
<article-title>Crows cross-modally recognize group members but not non-group members</article-title>. <source>Proc. R. Soc. B</source>
<volume>279</volume>, <fpage>1937</fpage>&#8211;<lpage>1942</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rspb.2011.2419">doi:10.1098/rspb.2011.2419</ext-link>)</mixed-citation></ref><ref id="RSOS160346C12"><label>12</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gilfillan</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Vitale</surname><given-names>J</given-names></name>, <name name-style="western"><surname>McNutt</surname><given-names>JW</given-names></name>, <name name-style="western"><surname>McComb</surname><given-names>K</given-names></name></person-group>
<year>2016</year>
<article-title>Cross-modal individual recognition in wild African lions</article-title>. <source>Biol. Lett.</source>
<volume>12</volume>, <fpage>20160323</fpage> (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rsbl.2016.0323">doi:10.1098/rsbl.2016.0323</ext-link>)<pub-id pub-id-type="pmid">27555649</pub-id></mixed-citation></ref><ref id="RSOS160346C13"><label>13</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Adachi</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Hampton</surname><given-names>RR</given-names></name></person-group>
<year>2011</year>
<article-title>Rhesus monkeys see who they hear: spontaneous cross-modal memory for familiar conspecifics</article-title>. <source>PLoS ONE</source>
<volume>6</volume>, <fpage>e23345</fpage> (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0023345">doi:10.1371/journal.pone.0023345</ext-link>)<pub-id pub-id-type="pmid">21887244</pub-id></mixed-citation></ref><ref id="RSOS160346C14"><label>14</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Silwa</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Duhamel</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Pascalis</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Wirth</surname><given-names>S</given-names></name></person-group>
<year>2011</year>
<article-title>Spontaneous voice-face identity matching by rhesus monkeys for familiar conspecifics and humans</article-title>. <source>Proc. Natl Acad. Sci. USA</source>
<volume>108</volume>, <fpage>1735</fpage>&#8211;<lpage>1740</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1008169108">doi:10.1073/pnas.1008169108</ext-link>)<pub-id pub-id-type="pmid">21220340</pub-id></mixed-citation></ref><ref id="RSOS160346C15"><label>15</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lampe</surname><given-names>JF</given-names></name>, <name name-style="western"><surname>Andre</surname><given-names>J</given-names></name></person-group>
<year>2012</year>
<article-title>Cross-modal recognition of human individuals in domestic horses (<italic>Equus caballus</italic>)</article-title>. <source>Anim. Cogn.</source>
<volume>15</volume>, <fpage>623</fpage>&#8211;<lpage>630</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10071-012-0490-1">doi:10.1007/s10071-012-0490-1</ext-link>)<pub-id pub-id-type="pmid">22526687</pub-id></mixed-citation></ref><ref id="RSOS160346C16"><label>16</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Proops</surname><given-names>L</given-names></name>, <name name-style="western"><surname>McComb</surname><given-names>K</given-names></name></person-group>
<year>2012</year>
<article-title>Cross-modal individual recognition in domestic horses (<italic>Equus caballus</italic>) extends to familiar humans</article-title>. <source>Proc. R. Soc. B</source>
<volume>279</volume>, <fpage>3131</fpage>&#8211;<lpage>3138</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rspb.2012.0626">doi:10.1098/rspb.2012.0626</ext-link>)</mixed-citation></ref><ref id="RSOS160346C17"><label>17</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Adachi</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Kuwahata</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Fujita</surname><given-names>K</given-names></name></person-group>
<year>2007</year>
<article-title>Dogs recall their owner's face upon hearing the owner's voice</article-title>. <source>Anim. Cogn.</source>
<volume>10</volume>, <fpage>17</fpage>&#8211;<lpage>21</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10071-006-0025-8">doi:10.1007/s10071-006-0025-8</ext-link>)<pub-id pub-id-type="pmid">16802145</pub-id></mixed-citation></ref><ref id="RSOS160346C18"><label>18</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kulahci</surname><given-names>IG</given-names></name>, <name name-style="western"><surname>Drea</surname><given-names>CM</given-names></name>, <name name-style="western"><surname>Rubenstein</surname><given-names>DI</given-names></name>, <name name-style="western"><surname>Ghazanfar</surname><given-names>AA</given-names></name></person-group>
<year>2014</year>
<article-title>Individual recognition through olfatory-auditory matching in lemurs</article-title>. <source>Proc. R. Soc. B</source>
<volume>281</volume>, <fpage>20140071</fpage> (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rspb.2014.0071">doi:10.1098/rspb.2014.0071</ext-link>)</mixed-citation></ref><ref id="RSOS160346C19"><label>19</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Johnston</surname><given-names>RE</given-names></name>, <name name-style="western"><surname>Peng</surname><given-names>A</given-names></name></person-group>
<year>2008</year>
<article-title>Memory for individuals: hamsters (<italic>Mesocricetus auratus</italic>) require contact to develop multicomponent representations (concepts) of others</article-title>. <source>J. Comp. Psychol.</source>
<volume>122</volume>, <fpage>121</fpage>&#8211;<lpage>131</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0735-7036.122.2.121">doi:10.1037/0735-7036.122.2.121</ext-link>)<pub-id pub-id-type="pmid">18489228</pub-id></mixed-citation></ref><ref id="RSOS160346C20"><label>20</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Briefer</surname><given-names>EF</given-names></name>, <name name-style="western"><surname>Haque</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Baciadonna</surname><given-names>L</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2014</year>
<article-title>Goats excel at learning and remembering a highly novel cognitive task</article-title>. <source>Front. Zool.</source>
<volume>11</volume>, <fpage>20</fpage> (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/1742-9994-11-20">doi:10.1186/1742-9994-11-20</ext-link>)<pub-id pub-id-type="pmid">24666734</pub-id></mixed-citation></ref><ref id="RSOS160346C21"><label>21</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nawroth</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Prentice</surname><given-names>PM</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2016</year>
<article-title>Individual personality differences in goats predict their performance in visual learning and non-associative cognitive tasks</article-title>. <source>Behav. Proc</source>. <volume>278</volume>, <fpage>266</fpage>&#8211;<lpage>273</lpage>.</mixed-citation></ref><ref id="RSOS160346C22"><label>22</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kaminski</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Riedel</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Call</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Tomasello</surname><given-names>M</given-names></name></person-group>
<year>2005</year>
<article-title>Domestic goats, <italic>Capra hircus</italic>, follow gaze direction and use social cues in an object choice task</article-title>. <source>Anim. Behav.</source>
<volume>69</volume>, <fpage>11</fpage>&#8211;<lpage>18</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.anbehav.2004.05.008">doi:10.1016/j.anbehav.2004.05.008</ext-link>)</mixed-citation></ref><ref id="RSOS160346C23"><label>23</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nawroth</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Brett</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2016</year>
<article-title>Goats display audience-dependent human-directed gazing behaviour in a problem-solving task</article-title>. <source>Biol. Lett.</source>
<volume>12</volume>, <fpage>20160283</fpage> (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rsbl.2016.0283">doi:10.1098/rsbl.2016.0283</ext-link>)<pub-id pub-id-type="pmid">27381884</pub-id></mixed-citation></ref><ref id="RSOS160346C24"><label>24</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nawroth</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Baciadonna</surname><given-names>L</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2016</year>
<article-title>Goats learn socially from humans in a spatial problem-solving task</article-title>. <source>Anim. Behav.</source>
<volume>121</volume>, <fpage>123</fpage>&#8211;<lpage>129</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.anbehav.2016.09.004">doi:10.1016/j.anbehav.2016.09.004</ext-link>)</mixed-citation></ref><ref id="RSOS160346C25"><label>25</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kaminski</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Call</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Tomasello</surname><given-names>M</given-names></name></person-group>
<year>2006</year>
<article-title>Goats&#8217; behaviour in a competitive food paradigm: evidence for perspective taking?</article-title>
<source>Behaviour</source>
<volume>143</volume>, <fpage>1341</fpage>&#8211;<lpage>1356</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1163/156853906778987542">doi:10.1163/156853906778987542</ext-link>)</mixed-citation></ref><ref id="RSOS160346C26"><label>26</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Barroso</surname><given-names>FG</given-names></name>, <name name-style="western"><surname>Alados</surname><given-names>CL</given-names></name>, <name name-style="western"><surname>Boza</surname><given-names>J</given-names></name></person-group>
<year>2000</year>
<article-title>Social heirarchy in the domestic goat: effect on food habits and production</article-title>. <source>Appl. Anim. Behav. Sci.</source>
<volume>69</volume>, <fpage>35</fpage>&#8211;<lpage>53</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0168-1591(00)00113-1">doi:10.1016/S0168-1591(00)00113-1</ext-link>)<pub-id pub-id-type="pmid">10856783</pub-id></mixed-citation></ref><ref id="RSOS160346C27"><label>27</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stanley</surname><given-names>CR</given-names></name>, <name name-style="western"><surname>Dunbar</surname><given-names>RIM</given-names></name></person-group>
<year>2013</year>
<article-title>Consistent social structure and optimal clique size revealed by social network analysis of feral goats, <italic>Capra hircus</italic></article-title>. <source>Anim. Behav.</source>
<volume>85</volume>, <fpage>771</fpage>&#8211;<lpage>779</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.anbehav.2013.01.020">doi:10.1016/j.anbehav.2013.01.020</ext-link>)</mixed-citation></ref><ref id="RSOS160346C28"><label>28</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Saunders</surname><given-names>FC</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name>, <name name-style="western"><surname>Safi</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Hayden</surname><given-names>TJ</given-names></name></person-group>
<year>2005</year>
<article-title>Mating tactics of male feral goats (<italic>Capra hircus</italic>): risks and benefits</article-title>. <source>Acta Ethol.</source>
<volume>8</volume>, <fpage>103</fpage>&#8211;<lpage>110</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10211-005-0006-y">doi:10.1007/s10211-005-0006-y</ext-link>)</mixed-citation></ref><ref id="RSOS160346C29"><label>29</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schino</surname><given-names>G</given-names></name></person-group>
<year>1998</year>
<article-title>Reconciliation in domestic goats</article-title>. <source>Behaviour</source>
<volume>135</volume>, <fpage>343</fpage>&#8211;<lpage>356</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1163/156853998793066302">doi:10.1163/156853998793066302</ext-link>)</mixed-citation></ref><ref id="RSOS160346C30"><label>30</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Briefer</surname><given-names>E</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2011</year>
<article-title>Indicators of age, body size and sex in goat kid calls revealed using the source-filter theory</article-title>. <source>Appl. Anim. Behav. Sci.</source>
<volume>133</volume>, <fpage>175</fpage>&#8211;<lpage>185</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.applanim.2011.05.012">doi:10.1016/j.applanim.2011.05.012</ext-link>)</mixed-citation></ref><ref id="RSOS160346C31"><label>31</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Briefer</surname><given-names>EF</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2012</year>
<article-title>Social effects on vocal ontogeny in an ungulate, the goat, <italic>Capra hircus</italic></article-title>. <source>Anim. Behav.</source>
<volume>83</volume>, <fpage>991</fpage>&#8211;<lpage>1000</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.anbehav.2012.01.020">doi:10.1016/j.anbehav.2012.01.020</ext-link>)</mixed-citation></ref><ref id="RSOS160346C32"><label>32</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Briefer</surname><given-names>EF</given-names></name>, <name name-style="western"><surname>Tettamanti</surname><given-names>F</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2015</year>
<article-title>Emotions in goats: mapping physiological, behavioural and vocal profiles</article-title>. <source>Anim. Behav.</source>
<volume>99</volume>, <fpage>131</fpage>&#8211;<lpage>143</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.anbehav.2014.11.002">doi:10.1016/j.anbehav.2014.11.002</ext-link>)</mixed-citation></ref><ref id="RSOS160346C33"><label>33</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Briefer</surname><given-names>EF</given-names></name>, <name name-style="western"><surname>Padilla de la Torre</surname><given-names>M</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2012</year>
<article-title>Mother goats do not forget their kids&#8217; calls</article-title>. <source>Proc. R. Soc. B</source>
<volume>279</volume>, <fpage>3749</fpage>&#8211;<lpage>3755</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rspb.2012.0986">doi:10.1098/rspb.2012.0986</ext-link>)</mixed-citation></ref><ref id="RSOS160346C34"><label>34</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ruiz-Miranda</surname><given-names>CR</given-names></name></person-group>
<year>1992</year>
<article-title>The use of pelage pigmentation in the recognition of mothers by domestic goat kids (<italic>Capra hircus</italic>)</article-title>. <source>Behaviour</source>
<volume>123</volume>, <fpage>121</fpage>&#8211;<lpage>143</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1163/156853992X00156">doi:10.1163/156853992X00156</ext-link>)</mixed-citation></ref><ref id="RSOS160346C35"><label>35</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ruiz-Miranda</surname><given-names>CR</given-names></name></person-group>
<year>1993</year>
<article-title>Use of pelage pigmentation in the recognition of mothers in a group by 2- to 4-month-old domestic goat kids</article-title>. <source>Appl. Anim. Behav. Sci.</source>
<volume>36</volume>, <fpage>317</fpage>&#8211;<lpage>326</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0168-1591(93)90129-D">doi:10.1016/0168-1591(93)90129-D</ext-link>)</mixed-citation></ref><ref id="RSOS160346C36"><label>36</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Keil</surname><given-names>NM</given-names></name>, <name name-style="western"><surname>Imfeld-Muller</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Aschwanden</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Wechsler</surname><given-names>B</given-names></name></person-group>
<year>2012</year>
<article-title>Are head cues necessary for goats (<italic>Capra hircus</italic>) in recognising group members?</article-title>
<source>Anim. Cogn.</source>
<volume>15</volume>, <fpage>913</fpage>&#8211;<lpage>921</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10071-012-0518-6">doi:10.1007/s10071-012-0518-6</ext-link>)<pub-id pub-id-type="pmid">22644114</pub-id></mixed-citation></ref><ref id="RSOS160346C37"><label>37</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Golinkoff</surname><given-names>RM</given-names></name>, <name name-style="western"><surname>Hirsh-Pasek</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Cauley</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Gordon</surname><given-names>L</given-names></name></person-group>
<year>1987</year>
<article-title>The eyes have it: lexical and syntactic comprehension in a new paradigm</article-title>. <source>J. Child. Lang.</source>
<volume>14</volume>, <fpage>23</fpage>&#8211;<lpage>45</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S030500090001271X">doi:10.1017/S030500090001271X</ext-link>)<pub-id pub-id-type="pmid">3558524</pub-id></mixed-citation></ref><ref id="RSOS160346C38"><label>38</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ratcliffe</surname><given-names>VF</given-names></name>, <name name-style="western"><surname>Taylor</surname><given-names>AM</given-names></name>, <name name-style="western"><surname>Reby</surname><given-names>D</given-names></name></person-group>
<year>2016</year>
<article-title>Cross-modal correspondences in non-human mammal communication</article-title>. <source>Multisens. Res.</source>
<volume>29</volume>, <fpage>49</fpage>&#8211;<lpage>91</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1163/22134808-00002509">doi:10.1163/22134808-00002509</ext-link>)<pub-id pub-id-type="pmid">27311291</pub-id></mixed-citation></ref><ref id="RSOS160346C39"><label>39</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Baciadonna</surname><given-names>L</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name>, <name name-style="western"><surname>Briefer</surname><given-names>EF</given-names></name></person-group>
<year>2013</year>
<article-title>Goats favour personal over social information in an experimental foraging task</article-title>. <source>PeerJ</source>
<volume>1</volume>, <fpage>e172</fpage> (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.7717/peerj.172">doi:10.7717/peerj.172</ext-link>)<pub-id pub-id-type="pmid">24109556</pub-id></mixed-citation></ref><ref id="RSOS160346C40"><label>40</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Briefer</surname><given-names>EF</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2013</year>
<article-title>Rescued goats at a sanctuary display positive mood after former neglect</article-title>. <source>Appl. Anim. Behav. Sci.</source>
<volume>146</volume>, <fpage>45</fpage>&#8211;<lpage>55</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.applanim.2013.03.007">doi:10.1016/j.applanim.2013.03.007</ext-link>)</mixed-citation></ref><ref id="RSOS160346C41"><label>41</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Briefer</surname><given-names>EF</given-names></name>, <name name-style="western"><surname>Oxley</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2015</year>
<article-title>Autonomic nervous system reactivity in a free-ranging mammal: effects of dominace rank and personality</article-title>. <source>Anim. Behav.</source>
<volume>110</volume>, <fpage>121</fpage>&#8211;<lpage>132</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.anbehav.2015.09.022">doi:10.1016/j.anbehav.2015.09.022</ext-link>)</mixed-citation></ref><ref id="RSOS160346C42"><label>42</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Howard</surname><given-names>IP</given-names></name>, <name name-style="western"><surname>Rogers</surname><given-names>BJ</given-names></name></person-group>
<year>1995</year>
<source>Binocular vision and stereopsis</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</mixed-citation></ref><ref id="RSOS160346C43"><label>43</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Engqvist</surname><given-names>L</given-names></name></person-group>
<year>2005</year>
<article-title>The mistreatment of covariate interaction terms in linear model analyses of behavioural and evolutionary ecology studies</article-title>. <source>Anim. Behav.</source>
<volume>70</volume>, <fpage>967</fpage>&#8211;<lpage>971</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.anbehav.2005.01.016">doi:10.1016/j.anbehav.2005.01.016</ext-link>)</mixed-citation></ref><ref id="RSOS160346C44"><label>44</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Call</surname><given-names>J</given-names></name></person-group>
<year>2006</year>
<article-title>Inferences by exclusion in the great apes: the effect of age and species</article-title>. <source>Anim. Cogn.</source>
<volume>9</volume>, <fpage>393</fpage>&#8211;<lpage>403</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10071-006-0037-4">doi:10.1007/s10071-006-0037-4</ext-link>)<pub-id pub-id-type="pmid">16924458</pub-id></mixed-citation></ref><ref id="RSOS160346C45"><label>45</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nawroth</surname><given-names>C</given-names></name>, <name name-style="western"><surname>von Borell</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Langbein</surname><given-names>J</given-names></name></person-group>
<year>2014</year>
<article-title>Exclusion performance in dwarf goats (<italic>Capra aegagrus hircus</italic>) and sheep (<italic>Ovis orientalis aries</italic>)</article-title>. <source>PLoS ONE</source>
<volume>9</volume>, <fpage>e93534</fpage> (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0093534">doi:10.1371/journal.pone.0093534</ext-link>)<pub-id pub-id-type="pmid">24695781</pub-id></mixed-citation></ref><ref id="RSOS160346C46"><label>46</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Talbot</surname><given-names>CF</given-names></name>, <name name-style="western"><surname>Leverett</surname><given-names>KL</given-names></name>, <name name-style="western"><surname>Brosnan</surname><given-names>SF</given-names></name></person-group>
<year>2016</year>
<article-title>Capuchins recognize familiar faces</article-title>. <source>Anim. Behav.</source>
<volume>122</volume>, <fpage>37</fpage>&#8211;<lpage>45</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.anbehav.2016.09.017">doi:10.1016/j.anbehav.2016.09.017</ext-link>)</mixed-citation></ref><ref id="RSOS160346C47"><label>47</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alexander</surname><given-names>G</given-names></name></person-group>
<year>1978</year>
<article-title>Odour, and the recognition of lambs by Merino ewes</article-title>. <source>Appl. Anim. Behav. Sci.</source>
<volume>4</volume>, <fpage>153</fpage>&#8211;<lpage>158</lpage>.</mixed-citation></ref><ref id="RSOS160346C48"><label>48</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Somppi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Tornqvist</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Hanninen</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Krause</surname><given-names>CM</given-names></name>, <name name-style="western"><surname>Vainio</surname><given-names>O</given-names></name></person-group>
<year>2014</year>
<article-title>How dogs scan familiar and inverted faces: an eye movement study</article-title>. <source>Anim. Cogn.</source>
<volume>17</volume>, <fpage>793</fpage>&#8211;<lpage>803</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10071-013-0713-0">doi:10.1007/s10071-013-0713-0</ext-link>)<pub-id pub-id-type="pmid">24305996</pub-id></mixed-citation></ref><ref id="RSOS160346C49"><label>49</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Leonard</surname><given-names>TK</given-names></name>, <name name-style="western"><surname>Blumenthal</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Gothard</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Hoffman</surname><given-names>KL</given-names></name></person-group>
<year>2012</year>
<article-title>How macaques view familiarity and gaze in conspecific faces</article-title>. <source>Behav. Neurosci.</source>
<volume>126</volume>, <fpage>781</fpage>&#8211;<lpage>791</lpage>. (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0030348">doi:10.1037/a0030348</ext-link>)<pub-id pub-id-type="pmid">23067381</pub-id></mixed-citation></ref><ref id="RSOS160346C50"><label>50</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Albuquerque</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Guo</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Wilkinson</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Savalli</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Otta</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Mills</surname><given-names>D</given-names></name></person-group>
<year>2016</year>
<article-title>Dogs recognize dog and human emotions</article-title>. <source>Biol. Lett.</source>
<volume>12</volume>, <fpage>20150883</fpage> (<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rsbl.2015.0883">doi:10.1098/rsbl.2015.0883</ext-link>)<pub-id pub-id-type="pmid">26763220</pub-id></mixed-citation></ref><ref id="RSOS160346C51"><label>51</label><mixed-citation publication-type="journal"><collab>ASAB</collab>. <year>2016</year>
<article-title>Guidelines for the treatment of animals in behavioural research and teaching</article-title>. <source>Anim. Behav</source>. <volume>111</volume>, I&#8211;IX.</mixed-citation></ref><ref id="RSOS160346C52"><label>52</label><mixed-citation publication-type="data"><person-group person-group-type="author"><name name-style="western"><surname>Pitcher</surname><given-names>BJ</given-names></name>, <name name-style="western"><surname>Briefer</surname><given-names>EF</given-names></name>, <name name-style="western"><surname>Baciadonna</surname><given-names>L</given-names></name>, <name name-style="western"><surname>McElligott</surname><given-names>AG</given-names></name></person-group>
<year>2017</year>
<article-title>Data from: Cross-modal recognition of familiar conspecifics in goats</article-title>. <source>Dryad Digital Repository</source>. <comment>(<uri xlink:href="http://dx.doi.org/10.5061/dryad.gp8ck">http://dx.doi.org/10.5061/dryad.gp8ck</uri>)</comment></mixed-citation></ref></ref-list></back></article>