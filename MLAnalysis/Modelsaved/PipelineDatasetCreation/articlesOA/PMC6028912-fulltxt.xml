<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.1?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Behav Sci (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Behav Sci (Basel)</journal-id><journal-id journal-id-type="publisher-id">behavsci</journal-id><journal-title-group><journal-title>Behavioral Sciences</journal-title></journal-title-group><issn pub-type="epub">2076-328X</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6028912</article-id><article-id pub-id-type="doi">10.3390/bs8060056</article-id><article-id pub-id-type="publisher-id">behavsci-08-00056</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Affective Congruence between Sound and Meaning of Words Facilitates Semantic Decision</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-0246-9422</contrib-id><name><surname>Aryani</surname><given-names>Arash</given-names></name><xref ref-type="aff" rid="af1-behavsci-08-00056">1</xref><xref rid="c1-behavsci-08-00056" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Jacobs</surname><given-names>Arthur M.</given-names></name><xref ref-type="aff" rid="af1-behavsci-08-00056">1</xref><xref ref-type="aff" rid="af2-behavsci-08-00056">2</xref></contrib></contrib-group><aff id="af1-behavsci-08-00056"><label>1</label>Department of Experimental and Neurocognitive Psychology, Freie Universit&#228;t Berlin, Habelschwerdter Allee 45, D-14195 Berlin, Germany; <email>ajacobs@zedat.fu-berlin.de</email></aff><aff id="af2-behavsci-08-00056"><label>2</label>Centre for Cognitive Neuroscience Berlin (CCNB), D-14195 Berlin, Germany</aff><author-notes><corresp id="c1-behavsci-08-00056"><label>*</label>Correspondence: <email>Arash.Aryani@fu-berlin.de</email></corresp></author-notes><pub-date pub-type="epub"><day>31</day><month>5</month><year>2018</year></pub-date><pub-date pub-type="collection"><month>6</month><year>2018</year></pub-date><volume>8</volume><issue>6</issue><elocation-id>56</elocation-id><history><date date-type="received"><day>26</day><month>4</month><year>2018</year></date><date date-type="accepted"><day>27</day><month>5</month><year>2018</year></date></history><permissions><copyright-statement>&#169; 2018 by the authors.</copyright-statement><copyright-year>2018</copyright-year><license license-type="open-access"><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>A similarity between the form and meaning of a word (i.e., iconicity) may help language users to more readily access its meaning through direct form-meaning mapping. Previous work has supported this view by providing empirical evidence for this facilitatory effect in sign language, as well as for onomatopoetic words (e.g., cuckoo) and ideophones (e.g., zigzag). Thus, it remains largely unknown whether the beneficial role of iconicity in making semantic decisions can be considered a general feature in spoken language applying also to &#8220;ordinary&#8221; words in the lexicon. By capitalizing on the affective domain, and in particular arousal, we organized words in two distinctive groups of iconic vs. non-iconic based on the congruence vs. incongruence of their lexical (meaning) and sublexical (sound) arousal. In a two-alternative forced choice task, we asked participants to evaluate the arousal of printed words that were lexically either high or low arousing. In line with our hypothesis, iconic words were evaluated more quickly and more accurately than their non-iconic counterparts. These results indicate a processing advantage for iconic words, suggesting that language users are sensitive to sound-meaning mappings even when words are presented visually and read silently.</p></abstract><kwd-group><kwd>sound-meaning mappings</kwd><kwd>sound symbolism</kwd><kwd>effect of sound on meaning</kwd><kwd>semantic decision task</kwd><kwd>neurocognitive poetics</kwd><kwd>processing fluency</kwd><kwd>poetry</kwd></kwd-group></article-meta></front><body><sec id="sec1-behavsci-08-00056"><title>1. Introduction </title><p>Classic linguistic approaches to meaning embed a core assumption that the way a word sounds does not play any contributing role in its meaning [<xref rid="B1-behavsci-08-00056" ref-type="bibr">1</xref>]. Rather, language users would access the meaning of words solely through learned, and per se, arbitrary links between linguistic symbols and their cognitive representations. Recent findings, however, support a more differentiated view by acknowledging the importance of non-arbitrary sound-meaning mappings in language processing and in the organization of vocabulary (see [<xref rid="B2-behavsci-08-00056" ref-type="bibr">2</xref>,<xref rid="B3-behavsci-08-00056" ref-type="bibr">3</xref>,<xref rid="B4-behavsci-08-00056" ref-type="bibr">4</xref>] for reviews). These findings distinguish between two types of motivations for such sound-meaning mappings [<xref rid="B3-behavsci-08-00056" ref-type="bibr">3</xref>]: iconicity, which is based on similarities between aspects of sound and aspects of meaning (e.g., onomatopoeia), versus systematicity, which is based on statistical regularities in language that link specific patterns of sound to specific semantic or grammatical concepts [<xref rid="B5-behavsci-08-00056" ref-type="bibr">5</xref>,<xref rid="B6-behavsci-08-00056" ref-type="bibr">6</xref>,<xref rid="B7-behavsci-08-00056" ref-type="bibr">7</xref>]. However, in many cases, the nature of the relationship between sound and meaning is not particularly clear. The phonaestheme /sn-/ appearing as an initial sound cluster in many English words related to &#8220;mouth&#8221; or &#8220;nose&#8221; may serve to illustrate this issue. It is an ongoing debate whether in this case a specific (nasal) quality of the sound of /sn-/links this sound to the concepts of &#8220;mouth&#8221; or &#8220;nose&#8221;, or if rather the organization of the vocabulary has evolved in a way so that this specific sound cluster over-proportionally appears in words that are related to these concepts.</p><p>In the present study, we aimed at investigating iconicity and its potential facilitatory role in lexico-semantic processing. In addition to a direct acoustic mapping, as in the case of onomatopoeia, iconic words can also evoke other sensory (including visual and tactile), motor, or affective experiences by systematically relating properties of such experiences to phonetic features or acoustic properties [<xref rid="B4-behavsci-08-00056" ref-type="bibr">4</xref>,<xref rid="B8-behavsci-08-00056" ref-type="bibr">8</xref>] as evident in ideophones (e.g., &#8220;twinkle&#8221;, [<xref rid="B9-behavsci-08-00056" ref-type="bibr">9</xref>,<xref rid="B10-behavsci-08-00056" ref-type="bibr">10</xref>,<xref rid="B11-behavsci-08-00056" ref-type="bibr">11</xref>]), in mimetic words [<xref rid="B12-behavsci-08-00056" ref-type="bibr">12</xref>,<xref rid="B13-behavsci-08-00056" ref-type="bibr">13</xref>], or in affective responses associated with the phonology of swear words [<xref rid="B14-behavsci-08-00056" ref-type="bibr">14</xref>,<xref rid="B15-behavsci-08-00056" ref-type="bibr">15</xref>]. Owing to such a sound-meaning mapping, iconic words have been suggested to be capable of directly evoking sensory, motor, or affective experiences by systematically relating properties of such experiences to phonetic features or acoustic properties of words [<xref rid="B4-behavsci-08-00056" ref-type="bibr">4</xref>,<xref rid="B8-behavsci-08-00056" ref-type="bibr">8</xref>,<xref rid="B15-behavsci-08-00056" ref-type="bibr">15</xref>,<xref rid="B16-behavsci-08-00056" ref-type="bibr">16</xref>]. </p><p>From a learning perspective, empirical evidence for both children and adults support an iconic advantage for learning the vocabulary of a language with which they had no prior experience. For instance, the meaning of Japanese iconic verbs, compared to non-iconic verbs, have been shown to be better learned and generalized by English speaking children [<xref rid="B17-behavsci-08-00056" ref-type="bibr">17</xref>,<xref rid="B18-behavsci-08-00056" ref-type="bibr">18</xref>,<xref rid="B19-behavsci-08-00056" ref-type="bibr">19</xref>]. These results are in line with the analyses of longitudinal diary data which suggest that over the course of language development iconic words are in general acquired earlier and potentially employed by infants as a bootstrapping mechanism on both lexical and phonological levels [<xref rid="B20-behavsci-08-00056" ref-type="bibr">20</xref>,<xref rid="B21-behavsci-08-00056" ref-type="bibr">21</xref>,<xref rid="B22-behavsci-08-00056" ref-type="bibr">22</xref>].</p><p>By the same token, as in vocabulary learning, iconicity has shown to facilitate language processing. Particularly, in sign languages, in which iconic relationships between form and meaning are far more prevalent than in spoken languages [<xref rid="B23-behavsci-08-00056" ref-type="bibr">23</xref>,<xref rid="B24-behavsci-08-00056" ref-type="bibr">24</xref>], iconicity has been shown to facilitate a variety of language processing tasks such as picture&#8211;sign matching, phonological decision, and picture naming [<xref rid="B16-behavsci-08-00056" ref-type="bibr">16</xref>], indicating that during lexical processing, iconic words benefit from an additional path between form and meaning by activating conceptual features related to perception and action (see also, [<xref rid="B22-behavsci-08-00056" ref-type="bibr">22</xref>]). Also, onomatopoetic words imitating animal sounds (e.g., &#8220;cuckoo&#8221;) have been shown to recruit brain regions involved in the processing of both verbal and nonverbal sounds [<xref rid="B25-behavsci-08-00056" ref-type="bibr">25</xref>]. These findings indicate that iconic words profit from additional processing networks that can facilitate both vocabulary learning and lexical processing [<xref rid="B3-behavsci-08-00056" ref-type="bibr">3</xref>,<xref rid="B18-behavsci-08-00056" ref-type="bibr">18</xref>].</p><p>Nevertheless, unlike pioneering works on the facilitatory effect of iconicity in sign language [<xref rid="B16-behavsci-08-00056" ref-type="bibr">16</xref>,<xref rid="B22-behavsci-08-00056" ref-type="bibr">22</xref>] which also laid the groundwork for the theoretical framework of such investigation, related research on spoken language still faces some limitations. Previous work on the processing advantage of iconicity in lexico-semantic processing of spoken language has so far mainly focused on either nonwords [<xref rid="B26-behavsci-08-00056" ref-type="bibr">26</xref>,<xref rid="B27-behavsci-08-00056" ref-type="bibr">27</xref>], onomatopoeia, and ideophones, including Japanese mimetic words [<xref rid="B9-behavsci-08-00056" ref-type="bibr">9</xref>,<xref rid="B10-behavsci-08-00056" ref-type="bibr">10</xref>,<xref rid="B11-behavsci-08-00056" ref-type="bibr">11</xref>,<xref rid="B28-behavsci-08-00056" ref-type="bibr">28</xref>], or on cases typically considered as systemticity [<xref rid="B6-behavsci-08-00056" ref-type="bibr">6</xref>,<xref rid="B7-behavsci-08-00056" ref-type="bibr">7</xref>,<xref rid="B29-behavsci-08-00056" ref-type="bibr">29</xref>]. Therefore, empirical evidence on whether iconic mappings in a real word can in general facilitate lexico-semantic processing is missing. This is chiefly due to a lack of appropriate measures for both the sound and meaning aspects of words. This limitation has prevented previous research on real spoken words to move beyond onomatopoeia and ideophones, leaving open the question of whether iconicity could be considered a &#8220;general&#8221; mechanism facilitating language processing. In addition, due to the limited number and the specific properties of onomatopoetic words and ideophones (e.g., phonological construct, frequency, etc.), no empirical research has so far investigated the effect of iconicity on lexico-semantic processing in a carefully controlled experimental paradigm. In the present investigation, we aimed at extending the results of previous works to the facilitatory effect of iconicity in &#8220;ordinary&#8221; words during a semantic decision task. </p><p>By capitalizing on the affective domain, in a recent study, Aryani et al. [<xref rid="B15-behavsci-08-00056" ref-type="bibr">15</xref>] provided quantitative measures for <italic>lexical</italic> affective meaning and <italic>sublexical</italic> affective sound of words in a two dimensional space of valence (ranging from pleasant to unpleasant) and arousal (ranging from calm to excited), with both measures empirically validated at behavioral and neurobiological levels of analysis (see [<xref rid="B30-behavsci-08-00056" ref-type="bibr">30</xref>] for the lexical and [<xref rid="B15-behavsci-08-00056" ref-type="bibr">15</xref>,<xref rid="B31-behavsci-08-00056" ref-type="bibr">31</xref>] for the sublexical measure). The results of the large-scale lexicon analysis suggest that affectivity in the implicit sound of printed words can influence the listener in their judgment about the words&#8217; affective meaning. In the present study, we aimed at extending the scope of the above mentioned work and categorized word in two groups of iconic vs. non-iconic based on the congruence between sound and meaning in the affective domain. We asked whether iconicity can facilitate evaluative decisions on words&#8217; affective content: Imagine two words representing similar lexical affective content (e.g., both high arousing), but one sounds harsh (congruent with the meaning) while the other sounds soft and calming (incongruent with the meaning). Which one will be classified more quickly and more accurately as high arousing in a decision task on affective meaning? A null hypothesis (H0), according to the established notion of linguistic arbitrariness [<xref rid="B1-behavsci-08-00056" ref-type="bibr">1</xref>], will expect no significant differences, while our alternative hypothesis (H1) predicts iconic (i.e., congruent) words to be evaluated more quickly and more accurately than non-iconic (i.e., incongruent) words [<xref rid="B4-behavsci-08-00056" ref-type="bibr">4</xref>,<xref rid="B8-behavsci-08-00056" ref-type="bibr">8</xref>,<xref rid="B16-behavsci-08-00056" ref-type="bibr">16</xref>]. This prediction is supported by previous findings on multimodal emotional convergence that suggest presentation of congruent bimodal emotional cues (e.g., verbal and nonverbal) yield faster and more accurate emotion judgments than unimodal presentations (e.g., only verbal) [<xref rid="B32-behavsci-08-00056" ref-type="bibr">32</xref>,<xref rid="B33-behavsci-08-00056" ref-type="bibr">33</xref>,<xref rid="B34-behavsci-08-00056" ref-type="bibr">34</xref>].</p><p>To test this hypothesis, we focused on the affective dimension of arousal and organized words in two groups of iconic and non-iconic by the orthogonal manipulation of the factors <italic>lexical arousal</italic> and <italic>sublexical arousal</italic> (<xref ref-type="fig" rid="behavsci-08-00056-f001">Figure 1</xref>). In a two-alternative (high arousing vs. low arousing) forced choice task, we then asked participants to decide as quickly and accurately as possible whether the meaning of visually presented words was &#8220;exciting&#8221; or &#8220;calming&#8221; (i.e., an arousal decision task). Note that at both <italic>lexical</italic> and <italic>sublexial</italic> levels our experimental design involves primarily the manipulation of arousal rather than valence. At the <italic>sublexical</italic> level, arousal plays a dominant role in models of vocal emotion communication [<xref rid="B35-behavsci-08-00056" ref-type="bibr">35</xref>,<xref rid="B36-behavsci-08-00056" ref-type="bibr">36</xref>] and in shaping affectivity in a word&#8217;s sound [<xref rid="B15-behavsci-08-00056" ref-type="bibr">15</xref>]. At the <italic>lexical</italic> level, the first emotional appraisal of a stimulus has shown to be related to arousal which qualifies it as the primary factor producing emotional interference in information processing tasks [<xref rid="B37-behavsci-08-00056" ref-type="bibr">37</xref>,<xref rid="B38-behavsci-08-00056" ref-type="bibr">38</xref>,<xref rid="B39-behavsci-08-00056" ref-type="bibr">39</xref>]. Thus, with regard to rather faster sensory processing of words&#8217; sound, arousal seems to be a more suitable candidate for an interactive effect between sound and meaning. Note that since the decision response time for a forced choice task had to be measured accurately, words in this study were presented visually. Therefore, it is important to mention that the use of the term &#8220;sound&#8221; in the present work refers to the implicit sound of words derived from phonological and prosodic recoding [<xref rid="B40-behavsci-08-00056" ref-type="bibr">40</xref>,<xref rid="B41-behavsci-08-00056" ref-type="bibr">41</xref>,<xref rid="B42-behavsci-08-00056" ref-type="bibr">42</xref>].</p></sec><sec id="sec2-behavsci-08-00056"><title>2. Materials and Methods</title><p>The study was approved by the ethics committee of the Freie Universit&#228;t Berlin and was conducted in compliance with the Code of Ethics of the World Medical Association (Declaration of Helsinki). All participants gave their consent in written form prior to participating in the study.</p><sec id="sec2dot1-behavsci-08-00056"><title>2.1. Stimuli</title><p>One hundred and sixty nouns (one to three syllables long) were selected for a 2 &#215; 2 design involving twofold manipulations of <italic>lexical</italic> and <italic>sublexical arousal</italic> (see <xref ref-type="fig" rid="behavsci-08-00056-f001">Figure 1</xref>). For <italic>lexical arousal</italic>, we used ratings for words&#8217; affective meaning (min = 1: very low arousing, max = 5 very high arousing) from the normative database BAWL-R [<xref rid="B43-behavsci-08-00056" ref-type="bibr">43</xref>]. <italic>Sublexical arousal</italic> was calculated using the recent psychoacoustic model [<xref rid="B15-behavsci-08-00056" ref-type="bibr">15</xref>]. This model is based on specific extracted acoustic features of pseudowords (e.g., pitch, formants, and intensity) that predict ratings given on the affectivity of their sound (see study2b in [<xref rid="B15-behavsci-08-00056" ref-type="bibr">15</xref>]). </p><p>Words were then divided into two distinctive conditions of &#8220;high&#8221; and &#8220;low&#8221; arousing for each of factors: <italic>lexical arousal</italic> (&#8220;high&#8221; &gt; 3.25, &#8220;low &lt; 2.75) and <italic>sublexical arousal</italic> (&#8220;high&#8221; &gt; 3, &#8220;low&#8221; &lt; 3) and carefully matched for relevant psycholinguistic factors (see <xref rid="behavsci-08-00056-t001" ref-type="table">Table 1</xref>).</p><p>Due to a natural confound between affective arousal and valence, words in the condition of &#8220;high&#8221; <italic>lexical arousal</italic> were more negative in valence than words in the condition &#8220;low&#8221; <italic>lexical arousal</italic>. In order to prevent participants to build an alternative strategy basing their decision on valence rather than arousal, 60 filler words with the rather rare combination of high <italic>lexical arousal</italic> and positive <italic>lexical valence</italic>, as well as 60 words with low <italic>lexical arousal</italic> and negative <italic>lexical valence</italic> were added to the stimulus set, which were excluded from further analyses.</p></sec><sec id="sec2dot2-behavsci-08-00056" sec-type="subjects"><title>2.2. Participants</title><p>Thirty-six right-handed German native speakers (26 women, mean age: 22.5 years, range: 18&#8211;34 years) with no history of neurological or psychiatric illness volunteered to participate in the study, receiving either five Euros or psychology course credit for their participation. All participants reported normal or corrected-to-normal vision and provided written informed consent to participate in the study. Handedness was determined using the Edinburgh Inventory [<xref rid="B44-behavsci-08-00056" ref-type="bibr">44</xref>]. </p></sec><sec id="sec2dot3-behavsci-08-00056"><title>2.3. Procedure</title><p>Participants were instructed to decide, as quickly and correctly as possible, whether the meaning of a word presented visually was either high or low arousing (exciting or calming), and to correspondingly press one of two designated buttons on the keyboard (in German: &#8220;<italic>Deine Aufgabe ist es, so schnell und so korrekt wie m&#246;glich zu entscheiden, ob du die Bedeutung des pr&#228;sentierten Wortes als aufregend oder beruhigend empfindest&#8230;.F&#252;r deine Entscheidung verwende bitte die beiden Tasten (...) f&#252;r aufregend und (...) f&#252;r beruhigend</italic>&#8221;). The assignment of the response buttons was counterbalanced across participants. Participants worked through 10 practice trials before starting with the 280 (160 experimental + 120 distractors) main trials. Each trial started with a fixation cross in the screen center with a jittered duration between 1.5 and 3 s and continued with the stimulus item being presented for 1.5 s or until a decision was made. The order of item presentation was fully randomized. For each item, we recorded the response of the first button press. </p><p>After the decision task, in a separate study, the same participants were asked to rate the same 160 relevant words for <italic>lexical arousal</italic>. Adapting the instructions used for the original BAWL ratings [<xref rid="B43-behavsci-08-00056" ref-type="bibr">43</xref>], participants were invited to read the presented item and evaluate how exciting or calming the presented word means. The 5-point affective sound of arousal scale ranged from 1 (<italic>sehr beruhigend</italic>/&#8220;very calming&#8221;) to 5 (<italic>sehr aufregend</italic>/&#8220;very exciting&#8221;). We also incorporated the self-assessment manikins (SAM) that were used in the ANEW study [<xref rid="B45-behavsci-08-00056" ref-type="bibr">45</xref>]. The items were randomly presented to minimize primacy or recency effects. We then used these rating values as a reference for evaluating responses given in the decision task, thereby distinguishing between &#8220;wrong&#8221; responses and &#8220;subjectively different&#8221; responses. </p></sec><sec id="sec2dot4-behavsci-08-00056"><title>2.4. Analysis</title><p>Trials without response were excluded from the analyses (2%, N = 110). We then compared the responses of each participant with their own affective judgment given in the rating study. Responses in the decision task that were in accordance with the rating values, but not in alignment with the original ratings used in experimental manipulation, or vice versa, i.e., <italic>subjectively different</italic> responses, were excluded from the analyses (17%, N = 1002), leaving 447 <italic>wrong</italic> responses (7%) and 4201 <italic>correct</italic> responses (73%). Using language stimuli, we chose Linear Mixed Model (LMM) analysis&#8212;over the classic F<sub>1</sub>-F<sub>2</sub> test&#8212;which provides a solution for the long-standing problem of how to analyze experimental data that contain two crossed random effects, i.e., items and participants (see for instance [<xref rid="B46-behavsci-08-00056" ref-type="bibr">46</xref>] for a review). RT and accuracy data for the items were analyzed with a linear mixed fixed and random effects model using the statistical software JMP 13Pro (SAS Institute Inc.), with <italic>lexical</italic> and <italic>sublexical arousal</italic> and their interaction as fixed effects and participants and items as random effects. </p><p>In order to ensure that the exclusion of a large amount of responses (none and <italic>subjectively different</italic>) was randomly distributed across experimental conditions and did not bias the results, we took the 1112 excluded words and ran the same mixed model analysis predicting the RT within these excluded items.</p></sec></sec><sec id="sec3-behavsci-08-00056"><title>3. Results</title><p>A comparison between original ratings for <italic>lexical arousal</italic> (from the BAWL) and the average of post hoc ratings revealed a high consistence between values: r = 0.94, <italic>p</italic> &lt; 0.0001, indicating the reliability of the used measure for <italic>lexical arousal</italic> as experimental factor. </p><p>The analysis of the excluded responses showed that the distribution of these items across experimental conditions was very similar over congruent (9.8%, N = 568) vs. incongruent conditions (9.4%, N = 544) and not significantly different over participants (<italic>p</italic> = 0.96). Within the excluded items, there was no significant effect of any of the experimental factors on the reaction time nor a significant interaction (all ps &gt; 0.3), suggesting that the exclusion of items did not follow a systematic pattern, and consequently, did not bias the results of the remaining responses.</p><p>Results of two main LMM analyses on remaining responses are displayed in <xref ref-type="fig" rid="behavsci-08-00056-f002">Figure 2</xref> and <xref rid="behavsci-08-00056-t002" ref-type="table">Table 2</xref>. A significant effect of <italic>lexical arousal</italic> on accuracy and on RT was observed with lexically high-arousing words classified more correctly and more quickly than low-arousing words (both ps &lt; 0.001). No direct effect of <italic>sublexical arousal</italic> on response accuracy or on RT was observed (<italic>p</italic> = 0.57, <italic>p</italic> = 0.48, respectively). Importantly, there was a significant interaction between <italic>lexical</italic> and <italic>sublexical arousal</italic> for both accuracy and RT (both ps &lt; 0.05). Post hoc analysis showed that within each <italic>lexical</italic> category, iconic words were associated with a higher response accuracy and a shorter RT than non-iconic words (see <xref rid="behavsci-08-00056-t002" ref-type="table">Table 2</xref> for further results).</p></sec><sec id="sec4-behavsci-08-00056"><title>4. Discussion</title><p>In this study, we investigated the effect of iconicity on affective semantic decisions and tested whether language users take the sound aspect implicitly into consideration. In line with our H1, faster latencies and higher accuracy in responses were observed for iconic words, i.e., words that exhibit similarity between meaning and sound in affective domain. Our finding, thus, clearly shows that in the context of language processing, human subjects are sensitive to affective cues that are provided by words&#8217; sound even when they are presented visually and read silently. Such affective cues can be integrated in higher cognitive processes and affect semantic decisions, thereby facilitating the evaluation of words&#8217; affective content when sound and meaning aspects are congruent. Crucially, this effect is evident even when the attentional focus is not directly on the sound aspect of words, suggesting an implicit effect of sound on the evaluation of words&#8217; meaning (see also, [<xref rid="B15-behavsci-08-00056" ref-type="bibr">15</xref>,<xref rid="B47-behavsci-08-00056" ref-type="bibr">47</xref>]). With this study, we aimed to build upon the previous results on the facilitatory effect of iconicity in lexico-semantic processing, which has been reported in sign language [<xref rid="B16-behavsci-08-00056" ref-type="bibr">16</xref>,<xref rid="B22-behavsci-08-00056" ref-type="bibr">22</xref>], in onomatopoetic words and in ideophones [<xref rid="B9-behavsci-08-00056" ref-type="bibr">9</xref>,<xref rid="B10-behavsci-08-00056" ref-type="bibr">10</xref>,<xref rid="B11-behavsci-08-00056" ref-type="bibr">11</xref>,<xref rid="B13-behavsci-08-00056" ref-type="bibr">13</xref>]. By using quantitative measures for both sound and meaning of words, we extended the results of previous findings to a larger number of &#8220;ordinary&#8221; words in the lexicon and in the context of affective meaning.</p><p>Also, the important role of multimodal convergence of emotions in making appropriate and faster decisions in emotional evaluation is supported by our data. A major benefit of multimodal integration has been shown to optimize efficient information processing by minimizing the uncertainty of ambiguous stimuli (see [<xref rid="B32-behavsci-08-00056" ref-type="bibr">32</xref>,<xref rid="B48-behavsci-08-00056" ref-type="bibr">48</xref>] for recent reviews). This is well in line with our behavioral results, in which words possessing congruent affective information from two different sources (i.e., sound and meaning) were categorized more quickly and more accurately.</p><p>The observed effect of lexical arousal on latency and accuracy also supports the previous findings on preferential processing of high arousing compared to low arousing words in decision tasks (e.g., [<xref rid="B49-behavsci-08-00056" ref-type="bibr">49</xref>]), which is proposed to be rooted in a biologically adaptive response leading to a faster and more accurate evaluation of emotionally relevant stimuli.</p><p>Importantly, in line with the results of previous investigations [<xref rid="B15-behavsci-08-00056" ref-type="bibr">15</xref>,<xref rid="B26-behavsci-08-00056" ref-type="bibr">26</xref>], the effect of iconicity facilitates lexico-semantic processing of words even when they are visually presented and silently read (see [<xref rid="B50-behavsci-08-00056" ref-type="bibr">50</xref>] for an ERP study for the effect of implicit sound). Note that visual word recognition generally involves the activation of phonological codes [<xref rid="B40-behavsci-08-00056" ref-type="bibr">40</xref>,<xref rid="B41-behavsci-08-00056" ref-type="bibr">41</xref>,<xref rid="B42-behavsci-08-00056" ref-type="bibr">42</xref>] and language users appear implicitly influenced by affective sound of visually presented words when evaluating the affective meaning of these words [<xref rid="B15-behavsci-08-00056" ref-type="bibr">15</xref>]. However, as we did not control our stimuli for orthographic features, a possible effect of graphemes on the processing of the affective content of words [<xref rid="B51-behavsci-08-00056" ref-type="bibr">51</xref>,<xref rid="B52-behavsci-08-00056" ref-type="bibr">52</xref>] is not precluded.</p><p>With the present study, we also aimed at drawing attention to the role of emotion in language processing, and in particular, in the study of iconicity. Focusing only on perceptuomotor analogies between sound and meaning, previous studies often overlooked investigating emotion as a modality of experience similar to sensory and motor processing [<xref rid="B15-behavsci-08-00056" ref-type="bibr">15</xref>,<xref rid="B53-behavsci-08-00056" ref-type="bibr">53</xref>,<xref rid="B54-behavsci-08-00056" ref-type="bibr">54</xref>]. Affective meaning is, however, a fundamental aspect of human communication that have been proposed as the original impetus for language evolution [<xref rid="B55-behavsci-08-00056" ref-type="bibr">55</xref>,<xref rid="B56-behavsci-08-00056" ref-type="bibr">56</xref>]. Therefore, from a phylogenetic perspective, the effect of iconicity may be most evident in the affective communication. Here, iconicity serves as an interface for accomplishing the need to map linguistic form onto human affective experience as a vital part of meaning making. When analysing the results, we had to exclude a relatively large number of items (17%) that were differently rated from the original ratings used in the experimental manipulation (i.e., the BAWL ratings). This may call for cautious interpretation of the results as it raises a question about the nature of arousal as a semantic feature. A more detailed analysis of these items did not reveal any specific pattern in regard to the degree of arousal nor to a specific group of words. Previous rating studies have repeatedly shown that ratings of valence are relatively consistent across participants while arousal is much more variable [<xref rid="B43-behavsci-08-00056" ref-type="bibr">43</xref>,<xref rid="B57-behavsci-08-00056" ref-type="bibr">57</xref>,<xref rid="B58-behavsci-08-00056" ref-type="bibr">58</xref>]. It has been suggested that valence is a semantic super-feature that results from an integration of both experiential and distributional data [<xref rid="B54-behavsci-08-00056" ref-type="bibr">54</xref>] as assumed by the semantics theory of Andrews et al. [<xref rid="B59-behavsci-08-00056" ref-type="bibr">59</xref>]. Arousal, however, may be derived by way of experience with the physical world and thus being less distributional (i.e., language based) and more experiential (i.e., non-language based). This, in turn, can explain the individual differences of arousal ratings at the level of meaning and, at the same time, its consistence at the level of sound leading to its dominant role in models of vocal emotion communication [<xref rid="B35-behavsci-08-00056" ref-type="bibr">35</xref>,<xref rid="B36-behavsci-08-00056" ref-type="bibr">36</xref>] as outlined in the introduction.</p><p>Concerning the nature of sound-meaning mapping, two different types of mapping, i.e., iconicity and systematicity, have been suggested in the previous work [<xref rid="B3-behavsci-08-00056" ref-type="bibr">3</xref>]. The sound-meaning mapping in a word is considered iconic when both sound and meaning independently refer to a similar specific (sensory, motor, or affective) domain [<xref rid="B4-behavsci-08-00056" ref-type="bibr">4</xref>]. For instance, some swear words are considered iconic because both their sound and their meaning possess negative valence [<xref rid="B14-behavsci-08-00056" ref-type="bibr">14</xref>]. In the present study, we used two different measures for assessing the sound and meaning of words based on their affective arousal. At the meaning level, our measure for the lexical arousal has been cross-validated in various empirical studies regarding experiential, behavioral, and neurobiological levels of analysis [<xref rid="B30-behavsci-08-00056" ref-type="bibr">30</xref>]. Also, at the sound level, the measure of sublexical arousal used in this study has been shown to have an inherent affective quality based on acoustic features that are known to modulate nonverbal emotional communication [<xref rid="B15-behavsci-08-00056" ref-type="bibr">15</xref>] and can evoke affective brain responses similar to other types of affective sounds [<xref rid="B31-behavsci-08-00056" ref-type="bibr">31</xref>]. Consequently, it is reasonable to conclude that our finding on the facilitatory effect of sound-meaning mapping is related to iconic mappings of words rather than statistical regularities in the lexicon.</p><p>Our finding can also help to gain a better understanding of affective and aesthetic processes of literary reading [<xref rid="B60-behavsci-08-00056" ref-type="bibr">60</xref>,<xref rid="B61-behavsci-08-00056" ref-type="bibr">61</xref>]. Poetry, for instance, seems to be one of the most promising forms of literature for sound-meaning investigations. The relation of &#8220;form&#8221; to &#8220;feeling&#8221; supposedly lies at the basis of poetry [<xref rid="B62-behavsci-08-00056" ref-type="bibr">62</xref>], and the &#8220;<italic>differentia specifica</italic>&#8221; of poetry is located in its formal characteristics and iconic properties [<xref rid="B63-behavsci-08-00056" ref-type="bibr">63</xref>]. Poetry is on the one hand inherently concerned with emotional expressions, and on the other hand, is accompanied by the artful deployment of sound patterns [<xref rid="B61-behavsci-08-00056" ref-type="bibr">61</xref>,<xref rid="B64-behavsci-08-00056" ref-type="bibr">64</xref>,<xref rid="B65-behavsci-08-00056" ref-type="bibr">65</xref>,<xref rid="B66-behavsci-08-00056" ref-type="bibr">66</xref>,<xref rid="B67-behavsci-08-00056" ref-type="bibr">67</xref>,<xref rid="B68-behavsci-08-00056" ref-type="bibr">68</xref>]. In this context, our results on the facilitated lexical processing of iconic words can be linked to previous findings on the notion of processing fluency stating higher ease of processing leads to a higher aesthetic pleasure [<xref rid="B69-behavsci-08-00056" ref-type="bibr">69</xref>,<xref rid="B70-behavsci-08-00056" ref-type="bibr">70</xref>]. This may provide additional explanation for the preferential use and the aesthetic effects of stylistic devices such as phonaesthetics and iconicity in poetry. </p></sec></body><back><ack><title>Acknowledgments</title><p>The Article Processing Charges for this article to publish in open access were funded by the Freie Universit&#228;t Berlin in cooperation with the German Research Foundation (DFG).</p></ack><notes><title>Author Contributions</title><p>Conceptualization, A.A. and A.M.J.; Methodology, A.A.; Software, A.A.; Validation, A.A., A.M.J.; Formal Analysis, A.A.; Investigation, A.A. and A.M.J.; Resources, A.M.J.; Data Curation, A.A.; Writing-Original Draft Preparation, A.A.; Writing-Review &amp; Editing, A.A. and A.M.J.; Visualization, A.A.; Supervision, A.M.J.; Project Administration, A.A.</p></notes><notes><title>Funding</title><p>This research received no external funding.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflict of interest.</p></notes><ref-list><title>References</title><ref id="B1-behavsci-08-00056"><label>1.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>De Saussure</surname><given-names>F.</given-names></name></person-group><source>Course in General Linguistics</source><publisher-name>Columbia University Press</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2011</year></element-citation></ref><ref id="B2-behavsci-08-00056"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidtke</surname><given-names>D.S.</given-names></name><name><surname>Conrad</surname><given-names>M.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><article-title>Phonological iconicity</article-title><source>Front. Psychol.</source><year>2014</year><volume>5</volume><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.3389/fpsyg.2014.00080</pub-id><?supplied-pmid 24575062?><pub-id pub-id-type="pmid">24474945</pub-id></element-citation></ref><ref id="B3-behavsci-08-00056"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dingemanse</surname><given-names>M.</given-names></name><name><surname>Blasi</surname><given-names>D.E.</given-names></name><name><surname>Lupyan</surname><given-names>G.</given-names></name><name><surname>Christiansen</surname><given-names>M.H.</given-names></name><name><surname>Monaghan</surname><given-names>P.</given-names></name></person-group><article-title>Arbitrariness, Iconicity, and Systematicity in Language</article-title><source>Trends Cogn. Sci.</source><year>2015</year><volume>19</volume><fpage>603</fpage><lpage>615</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.07.013</pub-id><?supplied-pmid 26412098?><pub-id pub-id-type="pmid">26412098</pub-id></element-citation></ref><ref id="B4-behavsci-08-00056"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perniss</surname><given-names>P.</given-names></name><name><surname>Vigliocco</surname><given-names>G.</given-names></name></person-group><article-title>The bridge of iconicity: From a world of experience to the experience of language</article-title><source>Philos. Trans. R. Soc. B Biol. Sci.</source><year>2014</year><volume>369</volume><fpage>20140179</fpage><pub-id pub-id-type="doi">10.1098/rstb.2014.0179</pub-id></element-citation></ref><ref id="B5-behavsci-08-00056"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christiansen</surname><given-names>M.H.</given-names></name><name><surname>Monaghan</surname><given-names>P.</given-names></name></person-group><article-title>Division of Labor in Vocabulary Structure: Insights from Corpus Analyses</article-title><source>Top. Cogn. Sci.</source><year>2016</year><volume>8</volume><fpage>610</fpage><lpage>624</lpage><pub-id pub-id-type="doi">10.1111/tops.12164</pub-id><?supplied-pmid 26399384?><pub-id pub-id-type="pmid">26399384</pub-id></element-citation></ref><ref id="B6-behavsci-08-00056"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farmer</surname><given-names>T.A.</given-names></name><name><surname>Christiansen</surname><given-names>M.H.</given-names></name><name><surname>Monaghan</surname><given-names>P.</given-names></name></person-group><article-title>Phonological typicality influences on-line sentence comprehension</article-title><source>Proc. Natl. Acad. Sci. USA</source><year>2006</year><volume>103</volume><fpage>12203</fpage><lpage>12208</lpage><pub-id pub-id-type="doi">10.1073/pnas.0602173103</pub-id><?supplied-pmid 16882728?><pub-id pub-id-type="pmid">16882728</pub-id></element-citation></ref><ref id="B7-behavsci-08-00056"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reilly</surname><given-names>J.</given-names></name><name><surname>Westbury</surname><given-names>C.</given-names></name><name><surname>Kean</surname><given-names>J.</given-names></name><name><surname>Peelle</surname><given-names>J.E.</given-names></name></person-group><article-title>Arbitrary symbolism in natural language revisited: When word forms carry meaning</article-title><source>PLoS ONE</source><year>2012</year><volume>7</volume><pub-id pub-id-type="doi">10.1371/journal.pone.0042286</pub-id><?supplied-pmid 22879931?><pub-id pub-id-type="pmid">22879931</pub-id></element-citation></ref><ref id="B8-behavsci-08-00056"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meteyard</surname><given-names>L.</given-names></name><name><surname>Stoppard</surname><given-names>E.</given-names></name><name><surname>Snudden</surname><given-names>D.</given-names></name><name><surname>Cappa</surname><given-names>S.F.</given-names></name><name><surname>Vigliocco</surname><given-names>G.</given-names></name></person-group><article-title>When semantics aids phonology: A processing advantage for iconic word forms in aphasia</article-title><source>Neuropsychologia</source><year>2015</year><volume>76</volume><fpage>264</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2015.01.042</pub-id><?supplied-pmid 25637775?><pub-id pub-id-type="pmid">25637775</pub-id></element-citation></ref><ref id="B9-behavsci-08-00056"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lockwood</surname><given-names>G.</given-names></name><name><surname>Hagoort</surname><given-names>P.</given-names></name><name><surname>Dingemanse</surname><given-names>M.</given-names></name></person-group><article-title>How iconicity helps people learn new words: Neural correlates and individual differences in sound-symbolic bootstrapping</article-title><source>Collabra Psychol.</source><year>2016</year><volume>2</volume><pub-id pub-id-type="doi">10.1525/collabra.42</pub-id></element-citation></ref><ref id="B10-behavsci-08-00056"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dingemanse</surname><given-names>M.</given-names></name><name><surname>Schuerman</surname><given-names>W.</given-names></name><name><surname>Reinisch</surname><given-names>E.</given-names></name><name><surname>Tufvesson</surname><given-names>S.</given-names></name><name><surname>Mitterer</surname><given-names>H.</given-names></name></person-group><article-title>What sound symbolism can and cannot do: Testing the iconicity of ideophones from five languages</article-title><source>Language</source><year>2016</year><volume>92</volume><fpage>e117</fpage><lpage>e133</lpage><pub-id pub-id-type="doi">10.1353/lan.2016.0034</pub-id></element-citation></ref><ref id="B11-behavsci-08-00056"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kwon</surname><given-names>N.</given-names></name><name><surname>Round</surname><given-names>E.R.</given-names></name></person-group><article-title>Phonaesthemes in morphological theory</article-title><source>Morphology</source><year>2014</year><volume>25</volume><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1007/s11525-014-9250-z</pub-id></element-citation></ref><ref id="B12-behavsci-08-00056"><label>12.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Childs</surname><given-names>G.T.</given-names></name></person-group><article-title>Sound Symbolism</article-title><source>The Oxford Handbook of the Word</source><publisher-name>Oxford University Press</publisher-name><publisher-loc>Oxford, UK</publisher-loc><year>2015</year><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1093/oxfordhb/978019964</pub-id></element-citation></ref><ref id="B13-behavsci-08-00056"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kita</surname><given-names>S.</given-names></name></person-group><article-title>Two-dimensional semantic analysis of Japanese mimetics</article-title><source>Linguistics</source><year>1997</year><volume>35</volume><fpage>379</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1515/ling.1997.35.2.379</pub-id></element-citation></ref><ref id="B14-behavsci-08-00056"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowers</surname><given-names>J.S.</given-names></name><name><surname>Pleydell-Pearce</surname><given-names>C.W.</given-names></name></person-group><article-title>Swearing, euphemisms, and linguistic relativity</article-title><source>PLoS ONE</source><year>2011</year><volume>6</volume><pub-id pub-id-type="doi">10.1371/journal.pone.0022341</pub-id><?supplied-pmid 21799832?><pub-id pub-id-type="pmid">21799832</pub-id></element-citation></ref><ref id="B15-behavsci-08-00056"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aryani</surname><given-names>A.</given-names></name><name><surname>Conrad</surname><given-names>M.</given-names></name><name><surname>Schmidtcke</surname><given-names>D.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><article-title>Why &#8220;piss&#8221; is ruder than &#8220;pee&#8221;? The role of sound in affective meaning making</article-title><source>PsyArXiv</source><year>2018</year><pub-id pub-id-type="doi">10.17605/OSF.IO/6N4P8</pub-id></element-citation></ref><ref id="B16-behavsci-08-00056"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinson</surname><given-names>D.</given-names></name><name><surname>Thompson</surname><given-names>R.L.</given-names></name><name><surname>Skinner</surname><given-names>R.</given-names></name><name><surname>Vigliocco</surname><given-names>G.</given-names></name></person-group><article-title>A faster path between meaning and form? Iconicity facilitates sign recognition and production in British Sign Language</article-title><source>J. Mem. Lang.</source><year>2015</year><volume>82</volume><fpage>56</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2015.03.002</pub-id></element-citation></ref><ref id="B17-behavsci-08-00056"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kantartzis</surname><given-names>K.</given-names></name><name><surname>Kita</surname><given-names>S.</given-names></name><name><surname>Imai</surname><given-names>M.</given-names></name></person-group><article-title>Japanese sound symbolism facilitates word learning in English speaking children</article-title><source>Cogn. Sci.</source><year>2011</year><volume>35</volume><fpage>575</fpage><lpage>586</lpage><pub-id pub-id-type="doi">10.1111/j.1551-6709.2010.01169.x</pub-id></element-citation></ref><ref id="B18-behavsci-08-00056"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Imai</surname><given-names>M.</given-names></name><name><surname>Kita</surname><given-names>S.</given-names></name><name><surname>Nagumo</surname><given-names>M.</given-names></name><name><surname>Okada</surname><given-names>H.</given-names></name></person-group><article-title>Sound symbolism facilitates early verb learning</article-title><source>Cognition</source><year>2008</year><volume>109</volume><fpage>54</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2008.07.015</pub-id><?supplied-pmid 18835600?><pub-id pub-id-type="pmid">18835600</pub-id></element-citation></ref><ref id="B19-behavsci-08-00056"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Ruiter</surname><given-names>L.E.</given-names></name><name><surname>Theakston</surname><given-names>A.L.</given-names></name><name><surname>Brandt</surname><given-names>S.</given-names></name><name><surname>Lieven</surname><given-names>E.V.M.</given-names></name></person-group><article-title>Iconicity affects children&#8217;s comprehension of complex sentences: The role of semantics, clause order, input and individual differences</article-title><source>Cognition</source><year>2018</year><volume>171</volume><fpage>202</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2017.10.015</pub-id><?supplied-pmid 29197241?><pub-id pub-id-type="pmid">29197241</pub-id></element-citation></ref><ref id="B20-behavsci-08-00056"><label>20.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Laing</surname><given-names>C.E.</given-names></name></person-group><article-title>What Does the Cow Say? An Exploratory Analysis of Development</article-title><source>Ph.D. Thesis</source><publisher-name>University of York</publisher-name><publisher-loc>York, UK</publisher-loc><year>2015</year></element-citation></ref><ref id="B21-behavsci-08-00056"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Monaghan</surname><given-names>P.</given-names></name><name><surname>Shillcock</surname><given-names>R.C.</given-names></name><name><surname>Christiansen</surname><given-names>M.H.</given-names></name><name><surname>Kirby</surname><given-names>S.</given-names></name></person-group><article-title>How arbitrary is language?</article-title><source>Philos. Trans. R. Soc. B Sci.</source><year>2014</year><volume>369</volume><pub-id pub-id-type="doi">10.1098/rstb.2013.0299</pub-id><?supplied-pmid 25092667?><pub-id pub-id-type="pmid">25092667</pub-id></element-citation></ref><ref id="B22-behavsci-08-00056"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>R.L.</given-names></name><name><surname>Vinson</surname><given-names>D.P.</given-names></name><name><surname>Woll</surname><given-names>B.</given-names></name><name><surname>Vigliocco</surname><given-names>G.</given-names></name></person-group><article-title>The Road to Language Learning Is Iconic: Evidence From British Sign Language</article-title><source>Psychol. Sci.</source><year>2012</year><volume>23</volume><fpage>1443</fpage><lpage>1448</lpage><pub-id pub-id-type="doi">10.1177/0956797612459763</pub-id><?supplied-pmid 23150275?><pub-id pub-id-type="pmid">23150275</pub-id></element-citation></ref><ref id="B23-behavsci-08-00056"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elliott</surname><given-names>E.A.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><article-title>Phonological and morphological faces: Disgust signs in German Sign Language</article-title><source>Sign Lang. Linguist.</source><year>2014</year><volume>17</volume><fpage>123</fpage><lpage>180</lpage><pub-id pub-id-type="doi">10.1075/sll.17.2.01ell</pub-id></element-citation></ref><ref id="B24-behavsci-08-00056"><label>24.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Taub</surname><given-names>S.F.</given-names></name></person-group><source>Language from the Body: Iconicity and Metaphor in American Sign Language</source><publisher-name>Cambridge University Press</publisher-name><publisher-loc>Cambridge, UK</publisher-loc><year>2001</year></element-citation></ref><ref id="B25-behavsci-08-00056"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hashimoto</surname><given-names>T.</given-names></name><name><surname>Usui</surname><given-names>N.</given-names></name><name><surname>Taira</surname><given-names>M.</given-names></name><name><surname>Nose</surname><given-names>I.</given-names></name><name><surname>Haji</surname><given-names>T.</given-names></name><name><surname>Kojima</surname><given-names>S.</given-names></name></person-group><article-title>The neural mechanism associated with the processing of onomatopoeic sounds</article-title><source>Neuroimage</source><year>2006</year><volume>31</volume><fpage>1762</fpage><lpage>1770</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.02.019</pub-id><?supplied-pmid 16616863?><pub-id pub-id-type="pmid">16616863</pub-id></element-citation></ref><ref id="B26-behavsci-08-00056"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westbury</surname><given-names>C.</given-names></name></person-group><article-title>Implicit sound symbolism in lexical access: Evidence from an interference task</article-title><source>Brain Lang.</source><year>2005</year><volume>93</volume><fpage>10</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1016/j.bandl.2004.07.006</pub-id><?supplied-pmid 15766764?><pub-id pub-id-type="pmid">15766764</pub-id></element-citation></ref><ref id="B27-behavsci-08-00056"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parise</surname><given-names>C.V.</given-names></name><name><surname>Pavani</surname><given-names>F.</given-names></name></person-group><article-title>Evidence of sound symbolism in simple vocalizations</article-title><source>Exp. Brain Res.</source><year>2011</year><volume>214</volume><fpage>373</fpage><lpage>380</lpage><pub-id pub-id-type="doi">10.1007/s00221-011-2836-3</pub-id><?supplied-pmid 21901453?><pub-id pub-id-type="pmid">21901453</pub-id></element-citation></ref><ref id="B28-behavsci-08-00056"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iwasaki</surname><given-names>N.</given-names></name><name><surname>Vinson</surname><given-names>D.P.</given-names></name><name><surname>Vigliocco</surname><given-names>G.</given-names></name></person-group><article-title>What do English Speakers Know about gera-gera and yota-yota?: A Cross-linguistic Investigation of Mimetic Words for Laughing and Walking</article-title><source>Jpn. Lang. Educ. Globe</source><year>2007</year><volume>17</volume><fpage>53</fpage><lpage>78</lpage></element-citation></ref><ref id="B29-behavsci-08-00056"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bergen</surname><given-names>B.K.</given-names></name></person-group><article-title>The psychological reality of phonaesthemes</article-title><source>Language</source><year>2004</year><volume>80</volume><fpage>290</fpage><lpage>311</lpage><pub-id pub-id-type="doi">10.1353/lan.2004.0056</pub-id></element-citation></ref><ref id="B30-behavsci-08-00056"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>A.M.</given-names></name><name><surname>V&#245;</surname><given-names>M.L.H.</given-names></name><name><surname>Briesemeister</surname><given-names>B.B.</given-names></name><name><surname>Conrad</surname><given-names>M.</given-names></name><name><surname>Hofmann</surname><given-names>M.J.</given-names></name><name><surname>Kuchinke</surname><given-names>L.</given-names></name><name><surname>L&#252;dtke</surname><given-names>J.</given-names></name><name><surname>Braun</surname><given-names>M.</given-names></name></person-group><article-title>10 years of BAWLing into affective and aesthetic processes in reading: What are the echoes?</article-title><source>Front. Psychol.</source><year>2015</year><volume>6</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.3389/fpsyg.2015.00714</pub-id><?supplied-pmid 26089808?><pub-id pub-id-type="pmid">25688217</pub-id></element-citation></ref><ref id="B31-behavsci-08-00056"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aryani</surname><given-names>A.</given-names></name><name><surname>Hsu</surname><given-names>C.-T.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><article-title>The Sound of Words Evokes Affective Brain Responses</article-title><source>Brain Sci.</source><year>2018</year><volume>8</volume><elocation-id>94</elocation-id><pub-id pub-id-type="doi">10.3390/brainsci8060094</pub-id><?supplied-pmid 29789504?><pub-id pub-id-type="pmid">29789504</pub-id></element-citation></ref><ref id="B32-behavsci-08-00056"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schirmer</surname><given-names>A.</given-names></name><name><surname>Adolphs</surname><given-names>R.</given-names></name></person-group><article-title>Emotion Perception from Face, Voice, and Touch: Comparisons and Convergence</article-title><source>Trends Cogn. Sci.</source><year>2017</year><volume>21</volume><fpage>216</fpage><lpage>228</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.01.001</pub-id><?supplied-pmid 28173998?><pub-id pub-id-type="pmid">28173998</pub-id></element-citation></ref><ref id="B33-behavsci-08-00056"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calvert</surname><given-names>G.A.</given-names></name></person-group><article-title>Crossmodal processing in the human brain: Insights from functional neuroimaging studies</article-title><source>Cereb. Cortex</source><year>2001</year><volume>11</volume><fpage>1110</fpage><lpage>1123</lpage><pub-id pub-id-type="doi">10.1093/cercor/11.12.1110</pub-id><?supplied-pmid 11709482?><pub-id pub-id-type="pmid">11709482</pub-id></element-citation></ref><ref id="B34-behavsci-08-00056"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schr&#246;ger</surname><given-names>E.</given-names></name><name><surname>Widmann</surname><given-names>A.</given-names></name></person-group><article-title>Speeded responses to audiovisual signal changes result from bimodal integration</article-title><source>Psychophysiology</source><year>1998</year><volume>35</volume><fpage>755</fpage><lpage>759</lpage><pub-id pub-id-type="doi">10.1111/1469-8986.3560755</pub-id><?supplied-pmid 9844437?><pub-id pub-id-type="pmid">9844437</pub-id></element-citation></ref><ref id="B35-behavsci-08-00056"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bachorowski</surname><given-names>J.-A.</given-names></name></person-group><article-title>Vocal expression and perception of emotion</article-title><source>Curr. Dir. Psychol. Sci.</source><year>1999</year><volume>8</volume><fpage>53</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1111/1467-8721.00013</pub-id></element-citation></ref><ref id="B36-behavsci-08-00056"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>B&#228;nziger</surname><given-names>T.</given-names></name><name><surname>Hosoya</surname><given-names>G.</given-names></name><name><surname>Scherer</surname><given-names>K.R.</given-names></name></person-group><article-title>Path models of vocal emotion communication</article-title><source>PLoS ONE</source><year>2015</year><volume>10</volume><fpage>1</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0136675</pub-id><?supplied-pmid 26325076?><pub-id pub-id-type="pmid">26325076</pub-id></element-citation></ref><ref id="B37-behavsci-08-00056"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dresler</surname><given-names>T.</given-names></name><name><surname>M&#233;riau</surname><given-names>K.</given-names></name><name><surname>Heekeren</surname><given-names>H.R.</given-names></name><name><surname>Van Der Meer</surname><given-names>E.</given-names></name></person-group><article-title>Emotional Stroop task: Effect of word arousal and subject anxiety on emotional interference</article-title><source>Psychol. Res.</source><year>2009</year><volume>73</volume><fpage>364</fpage><lpage>371</lpage><pub-id pub-id-type="doi">10.1007/s00426-008-0154-6</pub-id><?supplied-pmid 18636272?><pub-id pub-id-type="pmid">18636272</pub-id></element-citation></ref><ref id="B38-behavsci-08-00056"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>A.K.</given-names></name></person-group><article-title>Affective influences on the attentional dynamics supporting awareness</article-title><source>J. Exp. Psychol. Gen.</source><year>2005</year><volume>134</volume><fpage>258</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.134.2.258</pub-id><?supplied-pmid 15869349?><pub-id pub-id-type="pmid">15869349</pub-id></element-citation></ref><ref id="B39-behavsci-08-00056"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schimmack</surname><given-names>U.</given-names></name></person-group><article-title>Attentional interference effects of emotional pictures: Threat, negativity, or arousal?</article-title><source>Emotion</source><year>2005</year><volume>5</volume><fpage>55</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1037/1528-3542.5.1.55</pub-id><?supplied-pmid 15755219?><pub-id pub-id-type="pmid">15755219</pub-id></element-citation></ref><ref id="B40-behavsci-08-00056"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braun</surname><given-names>M.</given-names></name><name><surname>Hutzler</surname><given-names>F.</given-names></name><name><surname>Ziegler</surname><given-names>J.C.</given-names></name><name><surname>Dambacher</surname><given-names>M.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><article-title>Pseudohomophone effects provide evidence of early lexico-phonological processing in visual word recognition</article-title><source>Hum. Brain Mapp.</source><year>2009</year><volume>30</volume><fpage>1977</fpage><lpage>1989</lpage><pub-id pub-id-type="doi">10.1002/hbm.20643</pub-id><?supplied-pmid 18726911?><pub-id pub-id-type="pmid">18726911</pub-id></element-citation></ref><ref id="B41-behavsci-08-00056"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ziegler</surname><given-names>J.C.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><article-title>Phonological information provides early sources of constraint in the processing of letter strings</article-title><source>J. Mem. Lang.</source><year>1995</year><volume>34</volume><fpage>567</fpage><lpage>593</lpage><pub-id pub-id-type="doi">10.1006/jmla.1995.1026</pub-id></element-citation></ref><ref id="B42-behavsci-08-00056"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breen</surname><given-names>M.</given-names></name></person-group><article-title>Empirical investigations of the role of implicit prosody in sentence processing</article-title><source>Linguist. Lang. Compass</source><year>2014</year><volume>8</volume><fpage>37</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1111/lnc3.12061</pub-id></element-citation></ref><ref id="B43-behavsci-08-00056"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>V&#245;</surname><given-names>M.L.H.</given-names></name><name><surname>Conrad</surname><given-names>M.</given-names></name><name><surname>Kuchinke</surname><given-names>L.</given-names></name><name><surname>Urton</surname><given-names>K.</given-names></name><name><surname>Hofmann</surname><given-names>M.J.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><article-title>The Berlin Affective Word List Reloaded (BAWL-R)</article-title><source>Behav. Res. Methods</source><year>2009</year><volume>41</volume><fpage>534</fpage><lpage>538</lpage><pub-id pub-id-type="doi">10.3758/BRM.41.2.534</pub-id><?supplied-pmid 19363195?><pub-id pub-id-type="pmid">19363195</pub-id></element-citation></ref><ref id="B44-behavsci-08-00056"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oldfield</surname><given-names>R.C.</given-names></name></person-group><article-title>The assessment and analysis of handedness: The Edinburgh inventory</article-title><source>Neuropsychologia</source><year>1971</year><volume>9</volume><fpage>97</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1016/0028-3932(71)90067-4</pub-id><pub-id pub-id-type="pmid">5146491</pub-id></element-citation></ref><ref id="B45-behavsci-08-00056"><label>45.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bradley</surname><given-names>M.M.</given-names></name><name><surname>Lang</surname><given-names>P.J.</given-names></name></person-group><source>Affective Norms for English Words (ANEW): Instruction Manual and Affective Ratings</source><publisher-name>University of Florida</publisher-name><publisher-loc>Gainesville, FL, USA</publisher-loc><year>1999</year></element-citation></ref><ref id="B46-behavsci-08-00056"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Janssen</surname><given-names>D.P.</given-names></name></person-group><article-title>Twice random, once mixed: Applying mixed models to simultaneously analyze random effects of language and participants</article-title><source>Behav. Res. Methods</source><year>2012</year><volume>44</volume><fpage>232</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.3758/s13428-011-0145-1</pub-id><?supplied-pmid 21858733?><pub-id pub-id-type="pmid">21858733</pub-id></element-citation></ref><ref id="B47-behavsci-08-00056"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schirmer</surname><given-names>A.</given-names></name><name><surname>Kotz</surname><given-names>S.A.</given-names></name></person-group><article-title>Beyond the right hemisphere: Brain mechanisms mediating vocal emotional processing</article-title><source>Trends Cogn. Sci.</source><year>2006</year><volume>10</volume><fpage>24</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2005.11.009</pub-id><?supplied-pmid 16321562?><pub-id pub-id-type="pmid">16321562</pub-id></element-citation></ref><ref id="B48-behavsci-08-00056"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klasen</surname><given-names>M.</given-names></name><name><surname>Chen</surname><given-names>Y.H.</given-names></name><name><surname>Mathiak</surname><given-names>K.</given-names></name></person-group><article-title>Multisensory emotions: Perception, combination and underlying neural processes</article-title><source>Rev. Neurosci.</source><year>2012</year><volume>23</volume><fpage>381</fpage><lpage>392</lpage><pub-id pub-id-type="doi">10.1515/revneuro-2012-0040</pub-id><?supplied-pmid 23089604?><pub-id pub-id-type="pmid">23089604</pub-id></element-citation></ref><ref id="B49-behavsci-08-00056"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hofmann</surname><given-names>M.J.</given-names></name><name><surname>Tamm</surname><given-names>S.</given-names></name><name><surname>Braun</surname><given-names>M.M.</given-names></name><name><surname>Dambacher</surname><given-names>M.</given-names></name><name><surname>Hahne</surname><given-names>A.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><article-title>Conflict monitoring engages the mediofrontal cortex during nonword processing</article-title><source>Neuroreport</source><year>2008</year><volume>19</volume><fpage>25</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1097/WNR.0b013e3282f3b134</pub-id><?supplied-pmid 18281887?><pub-id pub-id-type="pmid">18281887</pub-id></element-citation></ref><ref id="B50-behavsci-08-00056"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hofmann</surname><given-names>M.J.</given-names></name><name><surname>Kuchinke</surname><given-names>L.</given-names></name><name><surname>Tamm</surname><given-names>S.</given-names></name><name><surname>V&#245;</surname><given-names>M.L.H.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><article-title>Affective processing within 1/10th of a second: High arousal is necessary for early facilitative processing of negative but not positive words</article-title><source>Cogn. Affect. Behav. Neurosci.</source><year>2009</year><volume>9</volume><fpage>389</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.3758/9.4.389</pub-id><?supplied-pmid 19897792?><pub-id pub-id-type="pmid">19897792</pub-id></element-citation></ref><ref id="B51-behavsci-08-00056"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ullrich</surname><given-names>S.</given-names></name><name><surname>Kotz</surname><given-names>S.A.</given-names></name><name><surname>Schmidtke</surname><given-names>D.S.</given-names></name><name><surname>Aryani</surname><given-names>A.</given-names></name><name><surname>Conrad</surname><given-names>M.</given-names></name></person-group><article-title>Phonological iconicity electrifies: An ERP study on affective sound-to-meaning correspondences in German</article-title><source>Front. Psychol.</source><year>2016</year><volume>7</volume><pub-id pub-id-type="doi">10.3389/fpsyg.2016.01200</pub-id><?supplied-pmid 27588008?><pub-id pub-id-type="pmid">27588008</pub-id></element-citation></ref><ref id="B52-behavsci-08-00056"><label>52.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Den Bergh</surname><given-names>O.</given-names></name><name><surname>Vrana</surname><given-names>S.</given-names></name><name><surname>Eelen</surname><given-names>P.</given-names></name></person-group><article-title>Letters from the heart: Affective categorization of letter combinations in typists and nontypists</article-title><source>J. Exp. Psychol. Learn. Mem. Cogn.</source><year>1990</year><volume>16</volume><fpage>1153</fpage><pub-id pub-id-type="doi">10.1037/0278-7393.16.6.1153</pub-id></element-citation></ref><ref id="B53-behavsci-08-00056"><label>53.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cannon</surname><given-names>P.R.</given-names></name><name><surname>Hayes</surname><given-names>A.E.</given-names></name><name><surname>Tipper</surname><given-names>S.P.</given-names></name></person-group><article-title>Sensorimotor fluency influences affect: Evidence from electromyography</article-title><source>Cogn. Emot.</source><year>2010</year><volume>24</volume><fpage>681</fpage><lpage>691</lpage><pub-id pub-id-type="doi">10.1080/02699930902927698</pub-id></element-citation></ref><ref id="B54-behavsci-08-00056"><label>54.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vigliocco</surname><given-names>G.</given-names></name><name><surname>Meteyard</surname><given-names>L.</given-names></name><name><surname>Andrews</surname><given-names>M.</given-names></name><name><surname>Kousta</surname><given-names>S.</given-names></name></person-group><article-title>Toward a theory of semantic representation</article-title><source>Lang. Cogn.</source><year>2009</year><volume>1</volume><fpage>219</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.1515/LANGCOG.2009.011</pub-id></element-citation></ref><ref id="B55-behavsci-08-00056"><label>55.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>A.M.</given-names></name><name><surname>Hofmann</surname><given-names>M.J.</given-names></name><name><surname>Kinder</surname><given-names>A.</given-names></name></person-group><article-title>On elementary affective decisions: To like or not to like, that is the question</article-title><source>Front. Psychol.</source><year>2016</year><volume>7</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.3389/fpsyg.2016.01836</pub-id><?supplied-pmid 27933013?><pub-id pub-id-type="pmid">26858668</pub-id></element-citation></ref><ref id="B56-behavsci-08-00056"><label>56.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Darwin</surname><given-names>C.</given-names></name></person-group><source>The Descent of Man and Selection in Relation to Sex</source><publisher-name>Murray</publisher-name><publisher-loc>London, UK</publisher-loc><year>1888</year><volume>Volume 1</volume></element-citation></ref><ref id="B57-behavsci-08-00056"><label>57.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Panksepp</surname><given-names>J.</given-names></name></person-group><article-title>Emotional causes and consequences of social-affective vocalization</article-title><source>Handbook of Behavioral Neuroscience</source><publisher-name>Elsevier</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2010</year><volume>Volume 19</volume><fpage>201</fpage><lpage>208</lpage></element-citation></ref><ref id="B58-behavsci-08-00056"><label>58.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stadthagen-Gonzalez</surname><given-names>H.</given-names></name><name><surname>Imbault</surname><given-names>C.</given-names></name><name><surname>P&#233;rez S&#225;nchez</surname><given-names>M.A.</given-names></name><name><surname>Brysbaert</surname><given-names>M.</given-names></name></person-group><article-title>Norms of valence and arousal for 14,031 Spanish words</article-title><source>Behav. Res. Methods</source><year>2017</year><volume>49</volume><fpage>111</fpage><lpage>123</lpage><pub-id pub-id-type="doi">10.3758/s13428-015-0700-2</pub-id><?supplied-pmid 26850056?><pub-id pub-id-type="pmid">26850056</pub-id></element-citation></ref><ref id="B59-behavsci-08-00056"><label>59.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warriner</surname><given-names>A.B.</given-names></name><name><surname>Kuperman</surname><given-names>V.</given-names></name><name><surname>Brysbaert</surname><given-names>M.</given-names></name></person-group><article-title>Norms of valence, arousal, and dominance for 13,915 English lemmas</article-title><source>Behav. Res. Methods</source><year>2013</year><volume>45</volume><fpage>1191</fpage><lpage>1207</lpage><pub-id pub-id-type="doi">10.3758/s13428-012-0314-x</pub-id><?supplied-pmid 23404613?><pub-id pub-id-type="pmid">23404613</pub-id></element-citation></ref><ref id="B60-behavsci-08-00056"><label>60.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrews</surname><given-names>M.</given-names></name><name><surname>Vigliocco</surname><given-names>G.</given-names></name><name><surname>Vinson</surname><given-names>D.</given-names></name></person-group><article-title>Integrating Experiential and Distributional Data to Learn Semantic Representations</article-title><source>Psychol. Rev.</source><year>2009</year><volume>116</volume><fpage>463</fpage><lpage>498</lpage><pub-id pub-id-type="doi">10.1037/a0016261</pub-id><?supplied-pmid 19618982?><pub-id pub-id-type="pmid">19618982</pub-id></element-citation></ref><ref id="B61-behavsci-08-00056"><label>61.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><article-title>Neurocognitive poetics: Methods and models for investigating the neuronal and cognitive-affective bases of literature reception</article-title><source>Front. Hum. Neurosci.</source><year>2015</year><volume>9</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.3389/fnhum.2015.00186</pub-id><?supplied-pmid 25932010?><pub-id pub-id-type="pmid">25653611</pub-id></element-citation></ref><ref id="B62-behavsci-08-00056"><label>62.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schrott</surname><given-names>R.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><source>Gehirn Und Gedicht: Wie Wir Unsere Wirklichkeiten Konstruieren</source><publisher-name>Hanser</publisher-name><publisher-loc>Munich, Germany</publisher-loc><year>2011</year></element-citation></ref><ref id="B63-behavsci-08-00056"><label>63.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Langer</surname><given-names>S.K.</given-names></name></person-group><source>Feeling and Form</source><publisher-name>Routledge and Kegan Paul London</publisher-name><publisher-loc>London, UK</publisher-loc><year>1953</year></element-citation></ref><ref id="B64-behavsci-08-00056"><label>64.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jakobson</surname><given-names>R.</given-names></name></person-group><article-title>Linguistics and poetics</article-title><source>Context</source><year>1960</year><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1002/car.1158</pub-id></element-citation></ref><ref id="B65-behavsci-08-00056"><label>65.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>L&#252;dtke</surname><given-names>J.</given-names></name><name><surname>Meyer-Sickendieck</surname><given-names>B.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><article-title>Immersing in the stillness of an early morning: Testing the mood empathy hypothesis of poetry reception</article-title><source>Psychol. Aesthet. Creat. Arts</source><year>2014</year><volume>8</volume><fpage>363</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1037/a0036826</pub-id></element-citation></ref><ref id="B66-behavsci-08-00056"><label>66.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aryani</surname><given-names>A.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name><name><surname>Conrad</surname><given-names>M.</given-names></name></person-group><article-title>Extracting salient sublexical units from written texts: &#8220;Emophon&#8221;, a corpus-based approach to phonological iconicity</article-title><source>Front. Psychol.</source><year>2013</year><volume>4</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.3389/fpsyg.2013.00654</pub-id><?supplied-pmid 24101907?><pub-id pub-id-type="pmid">23382719</pub-id></element-citation></ref><ref id="B67-behavsci-08-00056"><label>67.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aryani</surname><given-names>A.</given-names></name><name><surname>Kraxenberger</surname><given-names>M.</given-names></name><name><surname>Ullrich</surname><given-names>S.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name><name><surname>Conrad</surname><given-names>M.</given-names></name></person-group><article-title>Measuring the Basic Affective Tone of Poems via Phonological Saliency and Iconicity</article-title><source>Psychol. Aesthet. Creat. Arts</source><year>2016</year><volume>10</volume><fpage>191</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1037/aca0000033</pub-id></element-citation></ref><ref id="B68-behavsci-08-00056"><label>68.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ullrich</surname><given-names>S.</given-names></name><name><surname>Aryani</surname><given-names>A.</given-names></name><name><surname>Kraxenberger</surname><given-names>M.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name><name><surname>Conrad</surname><given-names>M.</given-names></name></person-group><article-title>On the relation between the general affective meaning and the basic sublexical, lexical, and inter-lexical features of poetic texts&#8212;A case study using 57 Poems of H. M. Enzensberger</article-title><source>Front. Psychol.</source><year>2017</year><volume>7</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.3389/fpsyg.2016.02073</pub-id><?supplied-pmid 28123376?><pub-id pub-id-type="pmid">28123376</pub-id></element-citation></ref><ref id="B69-behavsci-08-00056"><label>69.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bohrn</surname><given-names>I.C.</given-names></name><name><surname>Altmann</surname><given-names>U.</given-names></name><name><surname>Lubrich</surname><given-names>O.</given-names></name><name><surname>Menninghaus</surname><given-names>W.</given-names></name><name><surname>Jacobs</surname><given-names>A.M.</given-names></name></person-group><article-title>When we like what we know&#8212;A parametric fMRI analysis of beauty and familiarity</article-title><source>Brain Lang.</source><year>2013</year><volume>124</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1016/j.bandl.2012.10.003</pub-id><?supplied-pmid 23332807?><pub-id pub-id-type="pmid">23332807</pub-id></element-citation></ref><ref id="B70-behavsci-08-00056"><label>70.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reber</surname><given-names>R.</given-names></name><name><surname>Schwarz</surname><given-names>N.</given-names></name><name><surname>Winkielman</surname><given-names>P.</given-names></name></person-group><article-title>Processing Fluency and Aesthetic Pleasure: Is Beauty in the Perceiver&#8217;s Processing Experience?</article-title><source>Personal. Soc. Psychol. Rev.</source><year>2004</year><volume>8</volume><fpage>364</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1207/s15327957pspr0804_3</pub-id><?supplied-pmid 15582859?><pub-id pub-id-type="pmid">15582859</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="behavsci-08-00056-f001" orientation="portrait" position="float"><label>Figure 1</label><caption><p>Words were organized in a 2 &#215; 2 design with each of experimental factors (<italic>lexical arousal</italic> and <italic>sublexical arousal</italic>) manipulated in two distinct groups consisting of extreme levels of arousal (High = exciting, and Low = calming). The congruence vs. incongruence of <italic>lexical arousal</italic> (meaning) and <italic>sublexical arousal</italic> (sound) resulted in two groups of iconic vs. non-iconic words, respectively. Two example words (in German) from each category are given in each cell.</p></caption><graphic xlink:href="behavsci-08-00056-g001"/></fig><fig id="behavsci-08-00056-f002" orientation="portrait" position="float"><label>Figure 2</label><caption><p>Congruent words (iconic) were classified more quickly (<bold>right</bold>) and more accurately (<bold>left</bold>) in the corresponding lexical group compared to incongruent words (non-iconic).</p></caption><graphic xlink:href="behavsci-08-00056-g002"/></fig><table-wrap id="behavsci-08-00056-t001" orientation="portrait" position="float"><object-id pub-id-type="pii">behavsci-08-00056-t001_Table 1</object-id><label>Table 1</label><caption><p>Characteristics of word stimuli.</p></caption><table-wrap-foot><fn><p>Note: Sum-F = sum of the frequency of neighbors; HF = number of neighbors with higher frequency than the word itself.</p></fn></table-wrap-foot></table-wrap><table-wrap id="behavsci-08-00056-t002" orientation="portrait" position="float"><object-id pub-id-type="pii">behavsci-08-00056-t002_Table 2</object-id><label>Table 2</label><caption><p>Results of fixed effects, the interaction term, and the intercept of the mixed model analysis.</p></caption></table-wrap></floats-group></article>