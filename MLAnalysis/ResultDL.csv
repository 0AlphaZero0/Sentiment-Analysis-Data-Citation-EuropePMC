f1-score	Precision	Recall	Accuracy	Loss	Combination	Token	Ngram	Lemma	Stem
66.682	69.737	64.388	0.9259259	0.30987081148031387	['Tokenization']	True	False	False	False
65.145	69.486	62.089	0.9158249	0.36198998030364476	['N-gram']	False	True	False	False
66.678	67.35	66.13	0.9225589	0.24724155629323388	['Lemmatization']	False	False	True	False
67.334	67.998	66.792	0.9292929	0.2412558907222768	['Stemming']	False	False	False	True
94.052	95.626	92.774	0.94612795	0.2560072217782589	['Tokenization', 'N-gram']	True	True	False	False
65.032	71.76	60.815	0.9158249	0.44859549420750905	['Tokenization', 'Lemmatization']	True	False	True	False
67.518	69.462	65.981	0.9326599	0.25477754671333563	['N-gram', 'Lemmatization']	False	True	True	False
67.092	66.112	68.741	0.9225589	0.275929758005371	['Tokenization', 'Stemming']	True	False	False	True
94.052	95.626	92.774	0.94612795	0.22517392833275024	['N-gram', 'Stemming']	False	True	False	True
67.37	69.823	65.475	0.9326599	0.30195806218743926	['Lemmatization', 'Stemming']	False	False	True	True
92.803	95.173	90.981	0.93602693	0.2154684598128051	['Tokenization', 'N-gram', 'Lemmatization']	True	True	True	False
67.756	66.843	68.816	0.9292929	0.23414800702421754	['Tokenization', 'N-gram', 'Stemming']	True	True	False	True
67.948	67.891	68.005	0.9326599	0.2541057001360338	['Tokenization', 'Lemmatization', 'Stemming']	True	False	True	True
94.02	96.017	92.35	0.94612795	0.24152452543829428	['N-gram', 'Lemmatization', 'Stemming']	False	True	True	True
93.519	96.75	91.219	0.94276094	0.23751508665305596	['Tokenization', 'N-gram', 'Lemmatization', 'Stemming']	True	True	True	True
