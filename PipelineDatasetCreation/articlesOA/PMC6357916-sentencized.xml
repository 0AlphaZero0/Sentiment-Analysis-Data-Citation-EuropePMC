<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName journalpublishing.dtd?><?SourceDTD.Version 2.3?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6357916</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2019.00021</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title><SecTag type="TITLE"><text><SENT sid="0" pm="."><plain>Survival of the Fittest: Increased Stimulus Competition During Encoding Results in Fewer but More Robust Memory Traces </plain></SENT>
</text></SecTag></article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Baumann</surname><given-names>Oliver</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="c001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/50254/overview"/></contrib><contrib contrib-type="author"><name><surname>Crawshaw</surname><given-names>Eloise</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>McFadyen</surname><given-names>Jessica</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Queensland Brain Institute, The University of Queensland</institution>, <addr-line>Saint Lucia, QLD</addr-line>, <country>Australia</country></aff><aff id="aff2"><sup>2</sup><institution>School of Psychology and Interdisciplinary Centre for the Artificial Mind, Bond University</institution>, <addr-line>Gold Coast, QLD</addr-line>, <country>Australia</country></aff><author-notes><fn fn-type="edited-by"><p><text><SENT sid="1" pm="."><plain>Edited by: Benoit Lemaire, Université Grenoble Alpes, France </plain></SENT>
</text></p></fn><fn fn-type="edited-by"><p><text><SENT sid="2" pm="."><plain>Reviewed by: Bernhard Pastötter, University of Trier, Germany; Sandra S. </plain></SENT>
<SENT sid="3" pm="."><plain>Hale, Washington University in St. Louis, United States; Daniel Schneider, Leibniz Research Centre for Working Environment and Human Factors (IfADo), Germany </plain></SENT>
</text></p></fn><corresp id="c001">*Correspondence: Oliver Baumann, <email>obaumann@bond.edu.au</email>; <email>o.baumann@uq.edu.au</email></corresp><fn fn-type="other" id="fn001"><p><text><SENT sid="4" pm="."><plain>This article was submitted to Cognition, a section of the journal Frontiers in Psychology </plain></SENT>
</text></p></fn></author-notes><pub-date pub-type="epub"><day>22</day><month>1</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>10</volume><elocation-id>21</elocation-id><history><date date-type="received"><day>06</day><month>9</month><year>2018</year></date><date date-type="accepted"><day>07</day><month>1</month><year>2019</year></date></history><permissions><copyright-statement>Copyright © 2019 Baumann, Crawshaw and McFadyen.</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Baumann, Crawshaw and McFadyen</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p><SecTag type="ABS"><text><SENT sid="5" pm="."><plain>Forgetting can be accounted for by time-indexed decay as well as competition-based interference processes. </plain></SENT>
<SENT sid="6" pm="."><plain>Although conventionally seen as competing theories of forgetting processes, Altmann and colleagues argued for a functional interaction between decay and interference. </plain></SENT>
<SENT sid="7" pm="."><plain>They revealed that, in short-term memory, time-based forgetting occurred at a faster rate under conditions of high proactive interference compared to conditions of low proactive interference. </plain></SENT>
<SENT sid="8" pm="."><plain>However, it is unknown whether interactive effects between decay-based forgetting and interference-based forgetting also exist in long-term memory. </plain></SENT>
<SENT sid="9" pm="."><plain>We employed a delayed memory recognition paradigm for visual indoor and outdoor scenes, measuring recognition accuracy at two time-points, immediately after learning and after 1 week, while interference was indexed by the number of images in a semantic category. </plain></SENT>
<SENT sid="10" pm="."><plain>We found that higher levels of interference during encoding led to a slower subsequent decay rate. </plain></SENT>
<SENT sid="11" pm="."><plain>In contrast to the findings in working-memory, our results suggest that a “survival of the fittest” principle applies to long-term memory processes, in which stimulus competition during encoding results in fewer, but also more robust memory traces, which decay at a slower rate. </plain></SENT>
<SENT sid="12" pm="."><plain>Conversely, low levels of interference during encoding allow more memory traces to form initially, which, however, subsequently decay at a faster rate. </plain></SENT>
<SENT sid="13" pm="."><plain>Our findings provide new insights into the mechanism of forgetting and could inform neurobiological models of forgetting. </plain></SENT>
</text></SecTag></p></abstract><SecTag type="KEYWORD"><kwd-group><kwd>interference</kwd><kwd>decay</kwd><kwd>forgetting</kwd><kwd>visual memory</kwd><kwd>long-term memory</kwd></kwd-group></SecTag><funding-group><award-group><funding-source id="cn001">National Health and Medical Research Council<named-content content-type="fundref-id">10.13039/501100000925</named-content></funding-source><award-id rid="cn001">APP1098862</award-id></award-group></funding-group><counts><fig-count count="3"/><table-count count="2"/><equation-count count="0"/><ref-count count="28"/><page-count count="7"/><word-count count="0"/></counts></article-meta></front><body><SecTag type="INTRO"><sec><title><text><SENT sid="14" pm="."><plain>Introduction </plain></SENT>
</text></title><p><text><SENT sid="15" pm="."><plain>Forgetting, defined as the inability to retrieve information, is a central feature of human memory. </plain></SENT>
<SENT sid="16" pm="."><plain>Two explanations for non-pathological memory loss have been proposed; one a time-indexed decay processes, the other involving competition-based interference. </plain></SENT>
<SENT sid="17" pm="."><plain>Forgetting by decay has traditionally been described as a passive gradual loss of the substrate of memory, due to disuse. </plain></SENT>
<SENT sid="18" pm="."><plain>However, newer models inspired by neurobiology describe it as an active process to remove obsolete memories, based on parameters such as relevance or recency (Hardt et al., 2013). </plain></SENT>
<SENT sid="19" pm="."><plain>In contrast, forgetting by interference is thought to be due to concurrent task-related mental activity. </plain></SENT>
<SENT sid="20" pm="."><plain>Previous studies indicate that memories are particularly vulnerable during two specific periods. </plain></SENT>
<SENT sid="21" pm="."><plain>First, newly formed memories are easily compromised by interference during or shortly after initial learning (Wixted, 2005; Dewar et al., 2012). </plain></SENT>
<SENT sid="22" pm="."><plain>Second, already consolidated long-term memories can be disrupted during the retrieval stage (Skaggs, 1933; Anderson and Neely, 1996). </plain></SENT>
<SENT sid="23" pm="."><plain>Further, interference effects during retrieval are strongest if the competing task-related mental activity involves stimulus material that is highly similar to the one to be encoded or retrieved (Konkle et al., 2010a,b). </plain></SENT>
</text></p><p><text><SENT sid="24" pm="."><plain>Throughout the twentieth-century, time-based decay and competition-based interference theories of forgetting tended to be pitted against one another (e.g., Thorndike, 1913; Cason, 1924; Jenkins and Dallenbach, 1924; McGeoch, 1932; Brown, 1958; Keppel and Underwood, 1962; Waugh and Norman, 1965) and were often considered incompatible. </plain></SENT>
<SENT sid="25" pm="."><plain>This trend was broken by Altmann and colleagues (Altmann and Gray, 2002; Altmann and Schunn, 2012), who provided evidence not only for the co-existence of decay and interference, but also for the presence of interactive processes between them. </plain></SENT>
<SENT sid="26" pm="."><plain>Altmann’s studies showed that time-based forgetting occurred at a faster rate under conditions of high proactive interference compared to conditions of low proactive interference. </plain></SENT>
<SENT sid="27" pm="."><plain>These findings were interpreted as evidence for a functional role of time-based decay, which by reducing proactive interference would be instrumental in maintaining optimal working memory performance. </plain></SENT>
<SENT sid="28" pm="."><plain>Irrespective of whether this interaction serves the decluttering function outlined by Altmann and colleagues, such findings leave open the question of whether interactive effects between decay-based forgetting and interference-based forgetting also exist in long-term memory. </plain></SENT>
</text></p><p><text><SENT sid="29" pm="."><plain>To answer this question we employed a delayed memory two-alternative forced choice (2AFC) recognition design for visual scenes, under high and low levels of encoding interference. </plain></SENT>
<SENT sid="30" pm="."><plain>We measured recognition accuracy at two time-points, immediately after learning and after 1 week, while interference was indexed by the number of images in a semantic category. </plain></SENT>
<SENT sid="31" pm="."><plain>The decay rate was therefore defined as the difference between immediate test performance and delayed test performance. </plain></SENT>
<SENT sid="32" pm="."><plain>The choice for this retention interval was based on previous studies, which indicate that forgetting due to decay is a relatively slow process. </plain></SENT>
<SENT sid="33" pm="."><plain>For instance, Vogt and Magnussen (2007) tested long-term memory for 400 visual scenes and observed a decay rate of approximately 16% over a period of 9 days. </plain></SENT>
<SENT sid="34" pm="."><plain>We chose natural scenes as stimulus material for two reasons. </plain></SENT>
<SENT sid="35" pm="."><plain>Firstly, humans have a remarkable capacity to remember visual scenes in long-term memory, even after only a single exposure to the original image. </plain></SENT>
<SENT sid="36" pm="."><plain>This allows testing memory performance for many exemplars and over extended periods of time. </plain></SENT>
<SENT sid="37" pm="."><plain>Secondly, it had been shown that varying the number of exemplars per scene category could effectively control interference levels during scene encoding. Konkle et al. (2010b) asked participants to encode thousands of scene images. </plain></SENT>
<SENT sid="38" pm="."><plain>By varying the number of exemplars presented per scene category and testing memory using exemplar-level foils they observed a 2% decrease in memory performance for each doubling of the number of studied scene exemplars per category. </plain></SENT>
<SENT sid="39" pm="."><plain>In contrast, performance was found to be unaffected by the addition of further single image categories. </plain></SENT>
</text></p><p><text><SENT sid="40" pm="."><plain>Although using natural stimuli increases ecological validity it comes at a cost of experimental control. </plain></SENT>
<SENT sid="41" pm="."><plain>In other words, significant effects could be specific to the stimulus set employed and might not be generalizable. </plain></SENT>
<SENT sid="42" pm="."><plain>To assess stimulus generality we tested recognition memory separately for man-made indoor environments and natural outdoor environments. </plain></SENT>
<SENT sid="43" pm="."><plain>It had been shown previously that these two classes of natural scenes are distinctive in terms of both their semantic and visual characteristics (Vailaya et al., 1998; Oliva and Schyns, 2000; Torralba and Oliva, 2003). </plain></SENT>
<SENT sid="44" pm="."><plain>Any effects observed for both classes of natural scenes would therefore likely be generalizable to other examples of visual scenes. </plain></SENT>
</text></p><p><text><SENT sid="45" pm="."><plain>When attempting to measure decay-based forgetting over multiple test time-points in a repeated measures design, it is possible that stimulus foils employed in the retrieval tasks could cause interference-related forgetting, which would constitute a confound. </plain></SENT>
<SENT sid="46" pm="."><plain>To circumvent this issue, we employed a two-group design, measuring decay-based forgetting as a between-subject variable, across the two classes of natural scenes. </plain></SENT>
</text></p><p><text><SENT sid="47" pm="."><plain>In the absence of existing evidence for interactions between decay-based and interference-based forgetting processes in long-term memory, three competing hypotheses can be formulated. </plain></SENT>
<SENT sid="48" pm="."><plain>(1) Higher interference during encoding leads to few and fragile memory traces, which subsequently decay at a faster rate. </plain></SENT>
<SENT sid="49" pm="."><plain>(2) Higher interference during encoding leads to few but more robust memory traces, which decay at a slower rate. </plain></SENT>
<SENT sid="50" pm="."><plain>(3) Interference does not modulate the decay rate of long-term memories. </plain></SENT>
</text></p></sec></SecTag><SecTag type="METHODS"><sec sec-type="materials|methods" id="s1"><title><text><SENT sid="51" pm="."><plain>Materials and Methods </plain></SENT>
</text></title><sec><title><text><SENT sid="52" pm="."><plain>Participants </plain></SENT>
</text></title><p><text><SENT sid="53" pm="."><plain>For the main study, eighty adults from the University of Queensland gave informed consent and were compensated for their participation with either $10 AUD or course credit. </plain></SENT>
<SENT sid="54" pm="."><plain>Fifty-nine full data sets (Mage = 21 years, 14 male) were collected. </plain></SENT>
<SENT sid="55" pm="."><plain>The remaining 21 datasets were unusable due to attrition (n = 6), technical errors (n = 8), and failure to meet the minimum performance criterion [70% correct in the low interference condition (n = 7)]. </plain></SENT>
</text></p><p><text><SENT sid="56" pm="."><plain>Twenty additional participants (Mage = 22 years, 4 male) provided pilot ratings of target and foil similarity prior to the commencement of testing, in order to ensure that target-foil pairings were not more similar in the low interference condition, compared with the high interference condition. </plain></SENT>
</text></p></sec><sec><title><text><SENT sid="57" pm="."><plain>Stimuli </plain></SENT>
</text></title><p><text><SENT sid="58" pm="."><plain>Stimuli were images of 200 manmade, indoor scenes and 200 outdoor, natural scenes collected using Google image search and in accordance with a number of inclusion criteria. </plain></SENT>
<SENT sid="59" pm="."><plain>All images were taken from human eye level, in the daytime, in color, unlikely to evoke a strong emotional response (e.g., no hospitals, prisons, or great heights). </plain></SENT>
<SENT sid="60" pm="."><plain>Images containing watermarks, people, letters, digits or memorable symbols, distinctive colors, shapes, objects, or extreme weather patterns were either excluded, or these details were removed using Adobe Photoshop CS6. </plain></SENT>
<SENT sid="61" pm="."><plain>Natural outdoor images were required to be free of any obvious human influence, for example, fences, roads or boats. </plain></SENT>
<SENT sid="62" pm="."><plain>We manipulated interference by varying the number of images in a semantic category, following Konkle et al. (2010a) (see Tables 1, 2 for lists of high and low interference categories used). </plain></SENT>
<SENT sid="63" pm="."><plain>For both subsets of stimuli (manmade-indoor and natural-outdoor), low interference conditions were comprised of 50 images from 50 distinct semantic categories (giving one exemplar per category), and high interference conditions were comprised of 50 images from only 5 semantic categories (giving 10 exemplars from each category). </plain></SENT>
<SENT sid="64" pm="."><plain>Every image was paired with a similar “foil” picture during the 2AFC recognition test (hence the need for 400 images in total). </plain></SENT>
<SENT sid="65" pm="."><plain>Target-foil pairings were selected to be highly similar, based on features such as spatial distribution, texture, color, image quality, and object categories in the scene. </plain></SENT>
<SENT sid="66" pm="."><plain>Stimuli were 921 × 691 pixels, presented on a 21-inch monitor, with 1920 × 1080 screen resolution, using Presentation stimulus delivery software, version 16.2 (Neurobehavioral Systems). </plain></SENT>
</text></p><SecTag type="TABLE"><table-wrap id="T1" position="float"><label>Table 1</label><caption><p><text><SENT sid="67" pm="."><plain>Semantic categories for man-made indoor environments. </plain></SENT>
</text></p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><tbody><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="68" pm="."><plain>High interference (50 images from 5 categories) </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="69" pm="."><plain>Bedroom </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="70" pm="."><plain>Church </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="71" pm="."><plain>Laundry </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="72" pm="."><plain>Lecture theatre </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="73" pm="."><plain>Library </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="74" pm="."><plain>Low interference </plain></SENT>
</text></td><td valign="top" align="left" colspan="2" rowspan="1"><text><SENT sid="75" pm="."><plain>(50 images from 50 categories) </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="76" pm="."><plain>Aeroplane </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="77" pm="."><plain>Conservatory </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="78" pm="."><plain>Gym </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="79" pm="."><plain>Recreation centre </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="80" pm="."><plain>Baggage claim </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="81" pm="."><plain>Dance studio </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="82" pm="."><plain>Hair salon </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="83" pm="."><plain>Sauna </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="84" pm="."><plain>Ballroom </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="85" pm="."><plain>Deli </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="86" pm="."><plain>Hallway </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="87" pm="."><plain>Sewing room </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="88" pm="."><plain>Basement car park </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="89" pm="."><plain>Dining room </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="90" pm="."><plain>Indoor pool </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="91" pm="."><plain>Stables </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="92" pm="."><plain>Bathroom </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="93" pm="."><plain>Domestic kitchen </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="94" pm="."><plain>Industrial kitchen </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="95" pm="."><plain>Staircase </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="96" pm="."><plain>Billiards room </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="97" pm="."><plain>Dormitory </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="98" pm="."><plain>Laboratory </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="99" pm="."><plain>Supermarket </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="100" pm="."><plain>Boardroom </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="101" pm="."><plain>Dressing room </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="102" pm="."><plain>Living room </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="103" pm="."><plain>Temple </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="104" pm="."><plain>Bowling alley </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="105" pm="."><plain>Elevator </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="106" pm="."><plain>Locker room </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="107" pm="."><plain>Theatre </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="108" pm="."><plain>Café </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="109" pm="."><plain>Food Hall </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="110" pm="."><plain>Mosque </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="111" pm="."><plain>Train </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="112" pm="."><plain>Cellar </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="113" pm="."><plain>Gallery </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="114" pm="."><plain>Nursery </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="115" pm="."><plain>Waiting room </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="116" pm="."><plain>Child’s bedroom </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="117" pm="."><plain>Garage </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="118" pm="."><plain>Office </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="119" pm="."><plain>Walk in wardrobe </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="120" pm="."><plain>Cinema </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="121" pm="."><plain>Greengrocer </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="122" pm="."><plain>Pantry </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="123" pm="."><plain>Workshop </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="124" pm="."><plain>Greenhouse </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="125" pm="."><plain>Public toilets </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/></tr></tbody></table></table-wrap></SecTag><SecTag type="TABLE"><table-wrap id="T2" position="float"><label>Table 2</label><caption><p><text><SENT sid="126" pm="."><plain>Semantic categories for natural outdoor environments. </plain></SENT>
</text></p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><tbody><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="127" pm="."><plain>High interference (50 images from 5 categories) </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="128" pm="."><plain>Alpine forest-summer </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="129" pm="."><plain>Beach </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="130" pm="."><plain>Desert </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="131" pm="."><plain>Lake </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="132" pm="."><plain>Sclerophyllous forest </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1"><text><SENT sid="133" pm="."><plain>Low interference (50 images from 50 categories) </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="134" pm="."><plain>Alpine </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="135" pm="."><plain>Ice desert </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="136" pm="."><plain>Seagrass meadow </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="137" pm="."><plain>Tidal channel </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="138" pm="."><plain>forest-snow </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="139" pm="."><plain>Kelp forest </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="140" pm="."><plain>Tidewater glacier </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="141" pm="."><plain>Arid desert </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="142" pm="."><plain>Mangroves </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="143" pm="."><plain>Sea-stack </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="144" pm="."><plain>Tombolo </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="145" pm="."><plain>Autumn forest </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="146" pm="."><plain>Marsh </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="147" pm="."><plain>Shale </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="148" pm="."><plain>Tropical rainforest </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="149" pm="."><plain>Bluff </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="150" pm="."><plain>Moorland </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="151" pm="."><plain>Snow-capped mountain </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="152" pm="."><plain>Tundra </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="153" pm="."><plain>Cactus forest </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="154" pm="."><plain>Mudflats </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="155" pm="."><plain>Volcano </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="156" pm="."><plain>Canyon </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="157" pm="."><plain>Oasis </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="158" pm="."><plain>Swamp </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="159" pm="."><plain>Volcano lake </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="160" pm="."><plain>Creek </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="161" pm="."><plain>Pebbled beach </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="162" pm="."><plain>Salt flat </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="163" pm="."><plain>Waterfall </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="164" pm="."><plain>Dragon tree </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="165" pm="."><plain>Prairie </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="166" pm="."><plain>Sand </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="167" pm="."><plain>Wave cut platform </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="168" pm="."><plain>forest </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="169" pm="."><plain>Red sand beach </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="170" pm="."><plain>dunes-coastal </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="171" pm="."><plain>Wet savannah </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="172" pm="."><plain>Dry savannah </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="173" pm="."><plain>Redwood forest </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="174" pm="."><plain>Sea arch </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="175" pm="."><plain>Woodland </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="176" pm="."><plain>Fjord </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="177" pm="."><plain>River </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="178" pm="."><plain>Sea cave </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="179" pm="."><plain>Xanthorrhoea forest </plain></SENT>
</text></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="180" pm="."><plain>Glacier </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="181" pm="."><plain>Rocky coast </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="182" pm="."><plain>Sea cliff </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="183" pm="."><plain>Grassland </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="184" pm="."><plain>Rolling hills </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="185" pm="."><plain>Temperate </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="186" pm="."><plain>Heathland </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><text><SENT sid="187" pm="."><plain>rainforest </plain></SENT>
</text></td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/></tr></tbody></table></table-wrap></SecTag></sec><sec><title><text><SENT sid="188" pm="."><plain>Stimulus Validation: Pilot Similarity Ratings </plain></SENT>
</text></title><p><text><SENT sid="189" pm="."><plain>Prior to testing, we measured the similarity of target-foil stimulus pairs. </plain></SENT>
<SENT sid="190" pm="."><plain>This enabled us to ensure that the difficulty of discriminating target-foil pairs was equivalent for high interference and low interference pairs. </plain></SENT>
<SENT sid="191" pm="."><plain>Twenty participants (Mage = 22 years, 4 male) were asked to subjectively rate the similarity of each target-foil pair (200 pairs in total) on a 5-point Likert scale, ranging from 1 = most similar (almost identical) to 5 = least similar. </plain></SENT>
<SENT sid="192" pm="."><plain>For both sets of stimuli, participants rated target-foil pairings in the low interference condition (manmade indoor stimuli: M = 3.07, SD = 0.49, 95% CI [2.85, 3.29]; natural outdoor stimuli: M = 2.74, SD = 0.59, CI [2.48, 3.00]) at comparable levels of similarity to images in the high interference condition (manmade indoor stimuli: M = 3.27, SD = 0.46, 95% CI [3.07, 3.47]; natural outdoor stimuli: M = 2.95, SD = 0.53, CI [2.72, 3.18]). </plain></SENT>
<SENT sid="193" pm="."><plain>It is important to note that target-foil similarity was actually lower in the high interference condition [manmade indoor: t(19) = 3.504, p = 0.002; natural outdoor: t(19) = 4.524, p &lt; 0.001], which means that lower memory accuracy in the high-inference condition cannot be explained by higher target-foil similarity, but must be due the higher number of images per category. </plain></SENT>
</text></p></sec><sec><title><text><SENT sid="194" pm="."><plain>Procedure </plain></SENT>
</text></title><p><text><SENT sid="195" pm="."><plain>During encoding 200 images of manmade-indoor and natural-outdoor were presented randomly interleaved in the same session, appearing for 5 s, with a 600 ms inter-stimulus interval (see Figure 1A). </plain></SENT>
<SENT sid="196" pm="."><plain>Participants were asked to attend to the stimuli and told that they would be subsequently asked to recognize them. </plain></SENT>
<SENT sid="197" pm="."><plain>Participants were further shown an example trial of the recognition phase to alert them to the fact that they would have to distinguish the target from a highly similar foil image. </plain></SENT>
<SENT sid="198" pm="."><plain>After the encoding session the 60 participants were randomly assigned to two groups. </plain></SENT>
<SENT sid="199" pm="."><plain>The first group was tested immediately for manmade indoor scenes and after 1 week for natural outdoor scenes. </plain></SENT>
<SENT sid="200" pm="."><plain>Accordantly, the second group was tested immediately for natural outdoor scenes and after 1 week for manmade indoor scenes. </plain></SENT>
<SENT sid="201" pm="."><plain>This crosswise design allowed us to measure decay-based forgetting (as a between-subject variable), while avoiding potential confounds due to repeated testing of highly similar stimulus material. </plain></SENT>
<SENT sid="202" pm="."><plain>In addition, it allowed us to assess stimulus generality, by measuring memory accuracy for two sets of semantically and visually distinct scene images. </plain></SENT>
<SENT sid="203" pm="."><plain>The recognition phase consisted of 200 2AFC trials. </plain></SENT>
<SENT sid="204" pm="."><plain>In each trial, two images from the same scene category were presented side by side – one was a previously studied target image, and the other a distractor image that participants had not seen before (see Figure 1B). </plain></SENT>
<SENT sid="205" pm="."><plain>Participants were instructed to indicate which of the two scenes they had previously studied. </plain></SENT>
<SENT sid="206" pm="."><plain>No feedback was provided. </plain></SENT>
<SENT sid="207" pm="."><plain>The same set of target-foil pairs was used for all participants; however, in half of the trials, the target image was on the left side of the screen and the distractor on the right, and vice versa for the other half of the trials. </plain></SENT>
<SENT sid="208" pm="."><plain>Half of the trials (i.e., 100) contained images from the low-interference scene categories and the other half contained images from the high-interference scene categories. </plain></SENT>
<SENT sid="209" pm="."><plain>Participants proceeded at their own pace and were told to emphasize accuracy, not speed. </plain></SENT>
</text></p><SecTag type="FIG"><fig id="F1" position="float"><label>FIGURE 1</label><caption><p><text><SENT sid="210" pm="."><plain>Encoding and recognition procedures. (A) During encoding, participants viewed 200 images for 5 s each, with a 600 ms inter-stimulus interval. (B) During recognition, participants viewed 100 target-foil pairs, and attempted to identify the image they had seen previously. </plain></SENT>
<SENT sid="211" pm="."><plain>Memory was tested immediately as well as after 1 week. </plain></SENT>
</text></p></caption><graphic xlink:href="fpsyg-10-00021-g001"/></fig></SecTag></sec></sec></SecTag><SecTag type="RESULTS"><sec><title><text><SENT sid="212" pm="."><plain>Results </plain></SENT>
</text></title><sec><title><text><SENT sid="213" pm="."><plain>Man-Made Indoor Scenes </plain></SENT>
</text></title><p><text><SENT sid="214" pm="."><plain>Accuracy for man-made indoor scenes averaged over immediate and delayed testing conditions was 85.46% (SD = 11.46%) for low interference images and 75.12% (SD = 8.51%) for high interference images, effectively replicating the finding by Konkle et al. (2010a,b). </plain></SENT>
<SENT sid="215" pm="."><plain>In addition, accuracy averaged over both interference conditions, decreased from 85.07% (SD = 10.24%) at immediate testing, to 75.12% (SD = 10.26%) 1 week later (168 h). </plain></SENT>
<SENT sid="216" pm="."><plain>A two-way mixed ANOVA indicated significant effects of interference (within-subjects factor), F(1,57) = 123.587, p &lt; 0.001, partial-η2 = 0.684, and retention interval (between-subjects factor), F(1,57) = 22.591, p &lt; 0.001, partial-η2 = 0.284. </plain></SENT>
<SENT sid="217" pm="."><plain>Importantly, their interaction was also significant, F(1,57) = 22.734, p &lt; 0.001, partial-η2 = 0.285, such that memory accuracy decayed at a slower rate for images that were encoded under high levels of interference (see Figure 2A; MΔ = 5.32%, SEMΔ = 2.12%), t(57) = 2.507, p = 0.015, than under low levels (MΔ = 14.12%, SEMΔ = 2.38%), t(41) = 2.661, p &lt; 0.001. </plain></SENT>
</text></p><SecTag type="FIG"><fig id="F2" position="float"><label>FIGURE 2</label><caption><p><text><SENT sid="218" pm="."><plain>Recognition accuracy for (A) manmade indoor and (B) natural outdoor scenes encoded under low and high levels of interference, during immediate (0 h) and delayed testing (168 h). </plain></SENT>
<SENT sid="219" pm="."><plain>Error bars indicate 95% confidence intervals. </plain></SENT>
</text></p></caption><graphic xlink:href="fpsyg-10-00021-g002"/></fig></SecTag></sec><sec><title><text><SENT sid="220" pm="."><plain>Natural Outdoor Scenes </plain></SENT>
</text></title><p><text><SENT sid="221" pm="."><plain>The results for natural outdoor scenes followed an analogous pattern. </plain></SENT>
<SENT sid="222" pm="."><plain>While overall accuracy was poorer than for indoor scenes [t(59) = 5.725, p &lt; 0.001], the main effects and interaction remained highly significant. </plain></SENT>
<SENT sid="223" pm="."><plain>When averaging over immediate and delayed testing conditions, low interference images (M = 73.79%, SD = 11.13%) were better recognized than high interference images (M = 65.73%, SD = 10.45%), F(1,57) = 59.076, p &lt; 0.001, partial-η2 = 0.509. </plain></SENT>
<SENT sid="224" pm="."><plain>Averaging over both interference conditions, accuracy also decreased significantly from 76.05% (SD = 10.11%) at immediate testing to 63.67% (SD = 9.28%) 1 week later, F(1,57) = 37.398, p &lt; 0.001, partial-η2 = 0.396. </plain></SENT>
<SENT sid="225" pm="."><plain>Most importantly, as in Experiment 1, interference and retention interval interacted, F(1,57) = 6.906, p = 0.011, partial-η2 = 0.108, and the observed pattern of result (see Figure 2B) indicate once more that memory traces decay at a slower rate for images that were encoded under high levels of interference (MΔ = 9.62%, SEMΔ = 2.43%), t(57) = 3.969, p &lt; 0.001, than under low levels (MΔ = 15.16%, SEMΔ = 2.12%), t(57) = 7.127, p &lt; 0.001. </plain></SENT>
</text></p></sec></sec></SecTag><SecTag type="DISCUSS"><sec><title><text><SENT sid="226" pm="."><plain>Discussion </plain></SENT>
</text></title><p><text><SENT sid="227" pm="."><plain>We investigated the presence of interactive effects between decay-based forgetting and interference-based forgetting in long-term memory. </plain></SENT>
<SENT sid="228" pm="."><plain>We found that higher levels of interference during encoding led to a slower subsequent decay rate. </plain></SENT>
<SENT sid="229" pm="."><plain>This indicates that competition from similar stimuli during encoding results in fewer, but also more robust memory traces, which decay at a slower rate. </plain></SENT>
<SENT sid="230" pm="."><plain>On the other hand, lower levels of interference during encoding allow more memory traces to form initially. </plain></SENT>
<SENT sid="231" pm="."><plain>Yet these memories subsequently decay at a faster rate on average than high interference memories. </plain></SENT>
<SENT sid="232" pm="."><plain>It is important to note that the slower decay rate for memory traces formed under high interference cannot be explained by a floor effect (i.e., no room for accuracy reduction), since performance levels in the high interference condition are significantly above the 50% baseline, for indoor as well as outdoor stimuli (one-sample t-test, p &lt; 0.0001). </plain></SENT>
<SENT sid="233" pm="."><plain>Interactions between decay and interference were also conceptually replicated across two distinct stimulus sets, one containing indoor manmade scenes, and the other containing outdoor natural scenes. </plain></SENT>
<SENT sid="234" pm="."><plain>This suggests that the significant interaction between interference and decay is not specific to the individual stimuli chosen and is likely to be generalizable to a variety of stimulus material. </plain></SENT>
<SENT sid="235" pm="."><plain>Future studies should explore whether the effect generalizes to more abstract visual stimuli, such as printed or spoken words. </plain></SENT>
</text></p><p><text><SENT sid="236" pm="."><plain>Our results suggest that a “survival of the fittest” principle applies to long-term memory processes, in which stimulus competition during encoding acts as “selection pressure.” This pattern is in contrast to the findings in working-memory research (Altmann and Gray, 2002; Altmann and Schunn, 2012), which indicated that higher levels of interference are associated with a faster decay rate. </plain></SENT>
<SENT sid="237" pm="."><plain>Given the differences in the molecular biological processes that underlie short-term and long-term memories it is not surprising that differences also exist on the behavioral level. </plain></SENT>
<SENT sid="238" pm="."><plain>For instance, changes in gene expression are required to convert short-term memory (STM) that lasts less than ∼1 h to long-term memory (LTM). </plain></SENT>
<SENT sid="239" pm="."><plain>Short-term memories are also thought to be associated with alterations in pre-existing proteins, whereas long-term memories require a protein synthesis-dependent form of synaptic plasticity (for an overview see Kandel, 2001). </plain></SENT>
<SENT sid="240" pm="."><plain>Future studies would, however, be necessary to further investigate the neural processes that underlie our finding. </plain></SENT>
</text></p><p><text><SENT sid="241" pm="."><plain>The study by Konkle et al. (2010a) tested the effect of encoding related interference, by varying the number of items per image category during the learning phase, but only tested single items during the recognition phase (i.e., they always tested memory for the first item presented from each category). </plain></SENT>
<SENT sid="242" pm="."><plain>Their findings provide therefore strong evidence for retroactive interference during encoding (i.e., later items impact the encoding of the earlier item). </plain></SENT>
<SENT sid="243" pm="."><plain>As a sidenote, although not tested in their study it is nevertheless possible that proactive interference (i.e., earlier items impact the encoding of later items) would produce comparable results. </plain></SENT>
<SENT sid="244" pm="."><plain>In contrast, to the study by Konkle et al. (2010a), we tested not only one but all items per category in the high interference condition. </plain></SENT>
<SENT sid="245" pm="."><plain>It is therefore possible that the reduced performance we observed during recognition is not only due to encoding related interference (like in the Konkle study), but is also partially caused by interference during the recognition phase. </plain></SENT>
<SENT sid="246" pm="."><plain>For instance, Criss et al. (2011) reported interference effects due to items presented during the test phase, i.e., poorer performance with an increasing number of test items. </plain></SENT>
<SENT sid="247" pm="."><plain>The underlying idea is that each test produces a memory trace, and therefore a source of interference. </plain></SENT>
</text></p><p><text><SENT sid="248" pm="."><plain>To get an approximate measure of the potential impact of recognition-related interference in our study, we conducted a post hoc analysis that only included the first half of items tested during recognition (i.e., the first 5 items for each high interference category and the first 25 items for the low interference indoor and outdoor categories). </plain></SENT>
<SENT sid="249" pm="."><plain>The logic behind this partial analysis was that any improvement in memory accuracy relative to the full analysis would be indicative of a relative contribution of recognition-related interference. </plain></SENT>
<SENT sid="250" pm="."><plain>In addition, it would allow us to evaluate whether the observed interaction between interference and retention interval is still observable, when recognition-related interfered is reduced, while encoding-related interference is kept stable. </plain></SENT>
<SENT sid="251" pm="."><plain>Our analysis revealed (see Figure 3) that, while the overall effect of interference was reduced (suggesting the presence of recognition-related interference), the interaction between interference and retention interval was still significant F(1,57) = 19.359, p &lt; 0.001. </plain></SENT>
<SENT sid="252" pm="."><plain>The data therefore indicate that, although recognition-related interference had an additional impact on recognition accuracy, the interactive relationship between encoding related interference and retention interval was still present. </plain></SENT>
<SENT sid="253" pm="."><plain>Interestingly, the additional analysis showed that, if interference during recognition is accounted for, memory performance for low and high interference items was identical at delayed testing. </plain></SENT>
<SENT sid="254" pm="."><plain>This seems to suggest that the initial advantage of low-interference encoding dissipates after just 1 week. </plain></SENT>
<SENT sid="255" pm="."><plain>It is important to note that our experiment was not designed to distinguish encoding- and recognition-related contribution to memory interference and future studies are needed to disentangle them more effectively. </plain></SENT>
</text></p><SecTag type="FIG"><fig id="F3" position="float"><label>FIGURE 3</label><caption><p><text><SENT sid="256" pm="."><plain>Memory accuracy for the first half of items in the recognition test (averaged over manmade indoor and natural outdoor scenes). </plain></SENT>
<SENT sid="257" pm="."><plain>Error bars indicate 95% confidence intervals. </plain></SENT>
</text></p></caption><graphic xlink:href="fpsyg-10-00021-g003"/></fig></SecTag><p><text><SENT sid="258" pm="."><plain>Although not a theoretically motivated question of our study, we observed that memory for man-made indoor environments is better (80.07%) than for natural outdoor environments (69.78%). </plain></SENT>
<SENT sid="259" pm="."><plain>The difference could be due differences in low-level visual attributes of these two stimulus classes (Szummer and Picard, 1998; Oliva and Torralba, 2001). </plain></SENT>
<SENT sid="260" pm="."><plain>Typically, natural outdoor scenes are less structured and less distinctive than man-made indoor scenes. </plain></SENT>
<SENT sid="261" pm="."><plain>This greater degree of similarity could cause an increased overall level of interference compared to indoor man-made images, an effect that would explain poorer recognition performance for this image category. </plain></SENT>
<SENT sid="262" pm="."><plain>Alternatively, it could be that recognition performance was mediated by differences in visual expertise for the two stimulus classes. </plain></SENT>
<SENT sid="263" pm="."><plain>It has been shown that visual expertise leads to domain-specific increases in memory performance (Vicente and Wang, 1998; Curby et al., 2009) and it is likely that cohort of University students had on average greater exposure to man-made than natural environments. </plain></SENT>
</text></p><p><text><SENT sid="264" pm="."><plain>Our study measured memory performance only for categories with 1 and 10 exemplars. </plain></SENT>
<SENT sid="265" pm="."><plain>Given the findings of Konkle et al. (2010a,b), which show that every doubling of the number of images per category results in a ∼2% change in recognition accuracy, we would expect the interaction effect to logarithmically increase with the number of presented items per scene category. </plain></SENT>
<SENT sid="266" pm="."><plain>Our study measured recognition accuracy at two time points. </plain></SENT>
<SENT sid="267" pm="."><plain>Another objective for future studies would be to measure retention rates at shorter as well as longer retention intervals. </plain></SENT>
<SENT sid="268" pm="."><plain>Although experimentally costly, a finer-grained forgetting function would provide a better indication of how the rate of forgetting of high and low interference image sets varied over time. </plain></SENT>
<SENT sid="269" pm="."><plain>The relationship is unlikely to be linear, given the large body of evidence indicating that forgetting over time is a curvilinear function (Wixted and Ebbesen, 1991; Wixted, 2004). </plain></SENT>
<SENT sid="270" pm="."><plain>In addition, measuring forgetting over longer time periods could enlighten us as to whether images encoded under high interference will eventually be better remembered than images encoded under low interference (i.e., presence of a crossover interaction), or if accuracy rates will simply converge. </plain></SENT>
</text></p><p><text><SENT sid="271" pm="."><plain>A limitation of our study is that, although sources of extra-experimental variation were controlled where possible, with testing distributed throughout the day and working week to avoid time of day and time of week effects, it was not possible to control for interference that could potentially be caused by engaging in daily activities during the 1-week retention interval. </plain></SENT>
<SENT sid="272" pm="."><plain>Yet, this is a common factor in long-term memory research, since it would be practically impossible to isolate participants from all sources of stimulation and new learning to actually determine the potential contribution of extra-experimental interference on recognition accuracy. </plain></SENT>
</text></p><p><text><SENT sid="273" pm="."><plain>In conclusion, our study provided the first evidence for the existence of interactive processes between interference-based and decay-based forgetting in long-term memory for visual scenes. </plain></SENT>
<SENT sid="274" pm="."><plain>Using two conceptually distinct stimulus sets, our results indicate that increased stimulus competition during encoding results in fewer but more robust memory traces, akin to a “survival of the fittest principle.” Our finding suggests that stimulus competition during encoding modulates synaptic plasticity, a hypothesis that could incorporated in computational models of forgetting, and further examined using neurophysiological techniques. </plain></SENT>
<SENT sid="275" pm="."><plain>Finally, our finding might have implications for educational settings, yet further investigations over longer timespans and across sensory modalities are necessary, before its relevance to real-world long-term memory maintenance can be reliably determined. </plain></SENT>
</text></p></sec></SecTag><sec sec-type="data-availability"><title><text><SENT sid="276" pm="."><plain>Data Availability Statement </plain></SENT>
</text></title><p><text><SENT sid="277" pm="."><plain>The data and program code are available at Open Science Framework: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/K7YW4">doi: 10.17605/OSF.IO/K7YW4</ext-link>. </plain></SENT>
<SENT sid="278" pm="."><plain>The analysis scripts use “importPresentationLog.m” written by Tobias Otto, which is available at GitHub. </plain></SENT>
</text></p></sec><sec><title><text><SENT sid="279" pm="."><plain>Ethics Statement </plain></SENT>
</text></title><p><text><SENT sid="280" pm="."><plain>All subjects gave a written informed consent in accordance with the Declaration of Helsinki. </plain></SENT>
<SENT sid="281" pm="."><plain>The study was approved by the Human Research Ethics Committee of The University of Queensland. </plain></SENT>
</text></p></sec><SecTag type="AUTH_CONT"><sec><title><text><SENT sid="282" pm="."><plain>Author Contributions </plain></SENT>
</text></title><p><text><SENT sid="283" pm="."><plain>OB and EC were responsible for study design and data acquisition. </plain></SENT>
<SENT sid="284" pm="."><plain>OB, EC, and JM were responsible data analysis and manuscript writing. </plain></SENT>
</text></p></sec></SecTag><SecTag type="COMP_INT"><sec><title><text><SENT sid="285" pm="."><plain>Conflict of Interest Statement </plain></SENT>
</text></title><p><text><SENT sid="286" pm="."><plain>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. </plain></SENT>
</text></p></sec></SecTag></body><back><fn-group><SecTag type="ACK_FUND"><fn fn-type="financial-disclosure"><p><text4fund><text><SENT sid="287" pm="."><plain>Funding. This work was supported by the National Health and Medical Research Council (NHMRC; APP1098862) to OB. </plain></SENT>
</text></text4fund></p></fn></SecTag></fn-group><SecTag type="REF"><ref-list><title>References</title><ref id="B1"><text><SENT sid="288" pm="."><plain>AltmannE. </plain></SENT>
<SENT sid="289" pm="."><plain>M.GrayW. </plain></SENT>
<SENT sid="290" pm="."><plain>D. (2002). Forgetting to remember: the functional relationship of decay and interference. Psychol. </plain></SENT>
<SENT sid="291" pm="."><plain>Sci. 13 27–33. 10.1111/1467-9280.00405 <?supplied-pmid 11892775?>11892775 </plain></SENT>
</text></ref><ref id="B2"><text><SENT sid="292" pm="."><plain>AltmannE. </plain></SENT>
<SENT sid="293" pm="."><plain>M.SchunnC. </plain></SENT>
<SENT sid="294" pm="."><plain>D. (2012). Decay versus interference: a new look at an old interaction. Psychol. </plain></SENT>
<SENT sid="295" pm="."><plain>Sci. 23 1435–1437. 10.1177/0956797612446027 <?supplied-pmid 23012268?>23012268 </plain></SENT>
</text></ref><ref id="B3"><text><SENT sid="296" pm="."><plain>AndersonM. </plain></SENT>
<SENT sid="297" pm="."><plain>C.NeelyJ. </plain></SENT>
<SENT sid="298" pm="."><plain>H. (1996). “Interference and inhibition in memory retrieval,” in Memory Handbook of Perception and Cognition, 2nd Edn, eds BjorkE. </plain></SENT>
<SENT sid="299" pm="."><plain>L.BjorkR. </plain></SENT>
<SENT sid="300" pm="."><plain>A. (San Diego, CA: Academic Press), 237–313. </plain></SENT>
</text></ref><ref id="B4"><text><SENT sid="301" pm="."><plain>BrownJ. (1958). Some tests of the decay theory of immediate memory. Q. </plain></SENT>
<SENT sid="302" pm="."><plain>J. </plain></SENT>
<SENT sid="303" pm="."><plain>Exp. </plain></SENT>
<SENT sid="304" pm="."><plain>Psychol. 10 12–21. 10.1080/17470215808416249 </plain></SENT>
</text></ref><ref id="B5"><text><SENT sid="305" pm="."><plain>CasonH. (1924). Criticisms of the laws of exercise and effect. Psychol. </plain></SENT>
<SENT sid="306" pm="."><plain>Rev. 31 397–417. 10.1037/h0073009 <?supplied-pmid 12951745?>12951745 </plain></SENT>
</text></ref><ref id="B6"><text><SENT sid="307" pm="."><plain>CrissA. </plain></SENT>
<SENT sid="308" pm="."><plain>H.MalmbergK. </plain></SENT>
<SENT sid="309" pm="."><plain>J.ShiffrinR. </plain></SENT>
<SENT sid="310" pm="."><plain>M. (2011). Output interference in recognition memory. J. </plain></SENT>
<SENT sid="311" pm="."><plain>Mem. </plain></SENT>
<SENT sid="312" pm="."><plain>Lang. 64 316–326. </plain></SENT>
</text></ref><ref id="B7"><text><SENT sid="313" pm="."><plain>CurbyK. </plain></SENT>
<SENT sid="314" pm="."><plain>M.GlazekK.GauthierI. (2009). A visual short-term memory advantage for objects of expertise. J. </plain></SENT>
<SENT sid="315" pm="."><plain>Exp. </plain></SENT>
<SENT sid="316" pm="."><plain>Psychol. </plain></SENT>
<SENT sid="317" pm="."><plain>Hum. </plain></SENT>
<SENT sid="318" pm="."><plain>Percept. </plain></SENT>
<SENT sid="319" pm="."><plain>Perform. 35 94–107. 10.1037/0096-1523.35.1.94 <?supplied-pmid 19170473?>19170473 </plain></SENT>
</text></ref><ref id="B8"><text><SENT sid="320" pm="."><plain>DewarM.AlberJ.ButlerC.CowanN.Della SalaS. (2012). Brief wakeful resting boosts new memories over the long term. Psychol. </plain></SENT>
<SENT sid="321" pm="."><plain>Sci. 23 955–960. 10.1177/0956797612441220 <?supplied-pmid 22829465?>22829465 </plain></SENT>
</text></ref><ref id="B9"><text><SENT sid="322" pm="."><plain>HardtO.NaderK.NadelL. (2013). Decay happens: the role of active forgetting in memory. Trends Cogn. </plain></SENT>
<SENT sid="323" pm="."><plain>Sci. 17 111–120. 10.1016/j.tics.2013.01.001 <?supplied-pmid 23369831?>23369831 </plain></SENT>
</text></ref><ref id="B10"><text><SENT sid="324" pm="."><plain>JenkinsJ. </plain></SENT>
<SENT sid="325" pm="."><plain>G.DallenbachC. </plain></SENT>
<SENT sid="326" pm="."><plain>M. (1924). Obliviscence during sleep and waking. Am. </plain></SENT>
<SENT sid="327" pm="."><plain>J. </plain></SENT>
<SENT sid="328" pm="."><plain>Psychol. 35 605–612. 10.2307/1414040 </plain></SENT>
</text></ref><ref id="B11"><text><SENT sid="329" pm="."><plain>KandelE. </plain></SENT>
<SENT sid="330" pm="."><plain>R. (2001). The molecular biology of memory storage: a dialogue between genes and synapses. Science 294 1030–1038. 10.1126/science.1067020 <?supplied-pmid 11691980?>11691980 </plain></SENT>
</text></ref><ref id="B12"><text><SENT sid="331" pm="."><plain>KeppelG.UnderwoodB. </plain></SENT>
<SENT sid="332" pm="."><plain>J. (1962). Proactive inhibition in short-term retention of single items. J. </plain></SENT>
<SENT sid="333" pm="."><plain>Verbal Learning Verbal Behav. 1 153–161. 10.1016/S0022-5371(62)80023-1 </plain></SENT>
</text></ref><ref id="B13"><text><SENT sid="334" pm="."><plain>KonkleT.BradyT. </plain></SENT>
<SENT sid="335" pm="."><plain>F.AlvarezG. </plain></SENT>
<SENT sid="336" pm="."><plain>A.OlivaA. (2010a). Conceptual distinctiveness supports detailed visual long-term memory for real-world objects. J. </plain></SENT>
<SENT sid="337" pm="."><plain>Exp. </plain></SENT>
<SENT sid="338" pm="."><plain>Psychol. </plain></SENT>
<SENT sid="339" pm="."><plain>Gen. 139 558–578. 10.1037/a0019165 <?supplied-pmid 20677899?>20677899 </plain></SENT>
</text></ref><ref id="B14"><text><SENT sid="340" pm="."><plain>KonkleT.BradyT. </plain></SENT>
<SENT sid="341" pm="."><plain>F.AlvarezG. </plain></SENT>
<SENT sid="342" pm="."><plain>A.OlivaA. (2010b). Scene memory is more detailed than you think: the role of categories in visual long-term memory. Psychol. </plain></SENT>
<SENT sid="343" pm="."><plain>Sci. 21 1551–1556. 10.1177/0956797610385359 <?supplied-pmid 20921574?>20921574 </plain></SENT>
</text></ref><ref id="B15"><text><SENT sid="344" pm="."><plain>McGeochJ. </plain></SENT>
<SENT sid="345" pm="."><plain>A. (1932). Forgetting and the law of disuse. Psychol. </plain></SENT>
<SENT sid="346" pm="."><plain>Rev. 39 352–370. 10.1037/h0069819 </plain></SENT>
</text></ref><ref id="B16"><text><SENT sid="347" pm="."><plain>OlivaA.SchynsP. </plain></SENT>
<SENT sid="348" pm="."><plain>G. (2000). Diagnostic colors mediate scene recognition. Cogn. </plain></SENT>
<SENT sid="349" pm="."><plain>Psychol. 41 176–210. <?supplied-pmid 10968925?>10968925 </plain></SENT>
</text></ref><ref id="B17"><text><SENT sid="350" pm="."><plain>OlivaA.TorralbaA. (2001). Modeling the shape of the scene: a holistic representation of the spatial envelope. Int. </plain></SENT>
<SENT sid="351" pm="."><plain>J. </plain></SENT>
<SENT sid="352" pm="."><plain>Comput. </plain></SENT>
<SENT sid="353" pm="."><plain>Vis. 42 145–175. 10.1023/A:1011139631724 <?supplied-pmid 16387345?>16387345 </plain></SENT>
</text></ref><ref id="B18"><text><SENT sid="354" pm="."><plain>SkaggsE. </plain></SENT>
<SENT sid="355" pm="."><plain>B. (1933). A discussion on the temporal point of interpolation and degree of retroactive inhibition. J. </plain></SENT>
<SENT sid="356" pm="."><plain>Comp. </plain></SENT>
<SENT sid="357" pm="."><plain>Psychol. 16 411–414. 10.1037/h0074460 </plain></SENT>
</text></ref><ref id="B19"><text><SENT sid="358" pm="."><plain>SzummerM.PicardR. (1998). “Indoor-outdoor image classification. in content-based access of image and video database,” in Proceedings of the 1998 IEEE International Workshop, (San Jose, CA: IEEE), 42–51. </plain></SENT>
</text></ref><ref id="B20"><text><SENT sid="359" pm="."><plain>ThorndikeE. (1913). The Psychology of Learning. New York, NY: Teachers College, Columbia University. </plain></SENT>
</text></ref><ref id="B21"><text><SENT sid="360" pm="."><plain>TorralbaA.OlivaA. (2003). Statistics of natural image categories. Network 14 391–412.12938764 </plain></SENT>
</text></ref><ref id="B22"><text><SENT sid="361" pm="."><plain>VailayaA.JainA.ZhangH. </plain></SENT>
<SENT sid="362" pm="."><plain>J. (1998). On image classification: city images vs Landscapes. Pattern Recognit. 31 1921–1935. </plain></SENT>
</text></ref><ref id="B23"><text><SENT sid="363" pm="."><plain>VicenteK. </plain></SENT>
<SENT sid="364" pm="."><plain>J.WangJ. </plain></SENT>
<SENT sid="365" pm="."><plain>H. (1998). An ecological theory of expertise effects in memory recall. Psychol. </plain></SENT>
<SENT sid="366" pm="."><plain>Rev. 105 33–57. <?supplied-pmid 9450371?>9450371 </plain></SENT>
</text></ref><ref id="B24"><text><SENT sid="367" pm="."><plain>VogtS.MagnussenS. (2007). Long-term memory for 400 pictures on a common theme. Exp. </plain></SENT>
<SENT sid="368" pm="."><plain>Psychol. 54 298–303. 10.1027/1618-3169.54.4.298 <?supplied-pmid 17953150?>17953150 </plain></SENT>
</text></ref><ref id="B25"><text><SENT sid="369" pm="."><plain>WaughN.NormanD. (1965). Primary memory. Psychol. </plain></SENT>
<SENT sid="370" pm="."><plain>Rev. 72 89–104.14282677 </plain></SENT>
</text></ref><ref id="B26"><text><SENT sid="371" pm="."><plain>WixtedJ. </plain></SENT>
<SENT sid="372" pm="."><plain>T. (2004). The psychology and neuroscience of forgetting. Annu. </plain></SENT>
<SENT sid="373" pm="."><plain>Rev. </plain></SENT>
<SENT sid="374" pm="."><plain>Psychol. 55 235–269. 10.1146/annurev.psych.55.090902.14155514744216 </plain></SENT>
</text></ref><ref id="B27"><text><SENT sid="375" pm="."><plain>WixtedJ. </plain></SENT>
<SENT sid="376" pm="."><plain>T. (2005). A theory about why we forget what we once knew. Curr. </plain></SENT>
<SENT sid="377" pm="."><plain>Dir. </plain></SENT>
<SENT sid="378" pm="."><plain>Psychol. </plain></SENT>
<SENT sid="379" pm="."><plain>Sci. 14 6–9. 10.1111/j.0963-7214.2005.00324.x <?supplied-pmid 24767478?>24767478 </plain></SENT>
</text></ref><ref id="B28"><text><SENT sid="380" pm="."><plain>WixtedJ. </plain></SENT>
<SENT sid="381" pm="."><plain>T.EbbesenE. </plain></SENT>
<SENT sid="382" pm="."><plain>B. (1991). On the form of forgetting. Psychol. </plain></SENT>
<SENT sid="383" pm="."><plain>Sci. 2 409–415. 10.1111/j.1467-9280.1991.tb00175.x </plain></SENT>
</text></ref></ref-list></SecTag></back></article>
