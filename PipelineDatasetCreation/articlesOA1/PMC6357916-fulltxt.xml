<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName journalpublishing.dtd?><?SourceDTD.Version 2.3?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6357916</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2019.00021</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Survival of the Fittest: Increased Stimulus Competition During Encoding Results in Fewer but More Robust Memory Traces</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Baumann</surname><given-names>Oliver</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="c001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/50254/overview"/></contrib><contrib contrib-type="author"><name><surname>Crawshaw</surname><given-names>Eloise</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>McFadyen</surname><given-names>Jessica</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Queensland Brain Institute, The University of Queensland</institution>, <addr-line>Saint Lucia, QLD</addr-line>, <country>Australia</country></aff><aff id="aff2"><sup>2</sup><institution>School of Psychology and Interdisciplinary Centre for the Artificial Mind, Bond University</institution>, <addr-line>Gold Coast, QLD</addr-line>, <country>Australia</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Benoit Lemaire, Universit&#x000e9; Grenoble Alpes, France</p></fn><fn fn-type="edited-by"><p>Reviewed by: Bernhard Past&#x000f6;tter, University of Trier, Germany; Sandra S. Hale, Washington University in St. Louis, United States; Daniel Schneider, Leibniz Research Centre for Working Environment and Human Factors (IfADo), Germany</p></fn><corresp id="c001">*Correspondence: Oliver Baumann, <email>obaumann@bond.edu.au</email>; <email>o.baumann@uq.edu.au</email></corresp><fn fn-type="other" id="fn001"><p>This article was submitted to Cognition, a section of the journal Frontiers in Psychology</p></fn></author-notes><pub-date pub-type="epub"><day>22</day><month>1</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>10</volume><elocation-id>21</elocation-id><history><date date-type="received"><day>06</day><month>9</month><year>2018</year></date><date date-type="accepted"><day>07</day><month>1</month><year>2019</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2019 Baumann, Crawshaw and McFadyen.</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Baumann, Crawshaw and McFadyen</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Forgetting can be accounted for by time-indexed decay as well as competition-based interference processes. Although conventionally seen as competing theories of forgetting processes, Altmann and colleagues argued for a functional interaction between decay and interference. They revealed that, in short-term memory, time-based forgetting occurred at a faster rate under conditions of high proactive interference compared to conditions of low proactive interference. However, it is unknown whether interactive effects between decay-based forgetting and interference-based forgetting also exist in long-term memory. We employed a delayed memory recognition paradigm for visual indoor and outdoor scenes, measuring recognition accuracy at two time-points, immediately after learning and after 1 week, while interference was indexed by the number of images in a semantic category. We found that higher levels of interference during encoding led to a slower subsequent decay rate. In contrast to the findings in working-memory, our results suggest that a &#x0201c;survival of the fittest&#x0201d; principle applies to long-term memory processes, in which stimulus competition during encoding results in fewer, but also more robust memory traces, which decay at a slower rate. Conversely, low levels of interference during encoding allow more memory traces to form initially, which, however, subsequently decay at a faster rate. Our findings provide new insights into the mechanism of forgetting and could inform neurobiological models of forgetting.</p></abstract><kwd-group><kwd>interference</kwd><kwd>decay</kwd><kwd>forgetting</kwd><kwd>visual memory</kwd><kwd>long-term memory</kwd></kwd-group><funding-group><award-group><funding-source id="cn001">National Health and Medical Research Council<named-content content-type="fundref-id">10.13039/501100000925</named-content></funding-source><award-id rid="cn001">APP1098862</award-id></award-group></funding-group><counts><fig-count count="3"/><table-count count="2"/><equation-count count="0"/><ref-count count="28"/><page-count count="7"/><word-count count="0"/></counts></article-meta></front><body><sec><title>Introduction</title><p>Forgetting, defined as the inability to retrieve information, is a central feature of human memory. Two explanations for non-pathological memory loss have been proposed; one a time-indexed decay processes, the other involving competition-based interference. Forgetting by decay has traditionally been described as a passive gradual loss of the substrate of memory, due to disuse. However, newer models inspired by neurobiology describe it as an active process to remove obsolete memories, based on parameters such as relevance or recency (<xref rid="B9" ref-type="bibr">Hardt et al., 2013</xref>). In contrast, forgetting by interference is thought to be due to concurrent task-related mental activity. Previous studies indicate that memories are particularly vulnerable during two specific periods. First, newly formed memories are easily compromised by interference during or shortly after initial learning (<xref rid="B27" ref-type="bibr">Wixted, 2005</xref>; <xref rid="B8" ref-type="bibr">Dewar et al., 2012</xref>). Second, already consolidated long-term memories can be disrupted during the retrieval stage (<xref rid="B18" ref-type="bibr">Skaggs, 1933</xref>; <xref rid="B3" ref-type="bibr">Anderson and Neely, 1996</xref>). Further, interference effects during retrieval are strongest if the competing task-related mental activity involves stimulus material that is highly similar to the one to be encoded or retrieved (<xref rid="B13" ref-type="bibr">Konkle et al., 2010a</xref>,<xref rid="B14" ref-type="bibr">b</xref>).</p><p>Throughout the twentieth-century, time-based decay and competition-based interference theories of forgetting tended to be pitted against one another (e.g., <xref rid="B20" ref-type="bibr">Thorndike, 1913</xref>; <xref rid="B5" ref-type="bibr">Cason, 1924</xref>; <xref rid="B10" ref-type="bibr">Jenkins and Dallenbach, 1924</xref>; <xref rid="B15" ref-type="bibr">McGeoch, 1932</xref>; <xref rid="B4" ref-type="bibr">Brown, 1958</xref>; <xref rid="B12" ref-type="bibr">Keppel and Underwood, 1962</xref>; <xref rid="B25" ref-type="bibr">Waugh and Norman, 1965</xref>) and were often considered incompatible. This trend was broken by Altmann and colleagues (<xref rid="B1" ref-type="bibr">Altmann and Gray, 2002</xref>; <xref rid="B2" ref-type="bibr">Altmann and Schunn, 2012</xref>), who provided evidence not only for the co-existence of decay and interference, but also for the presence of interactive processes between them. Altmann&#x02019;s studies showed that time-based forgetting occurred at a faster rate under conditions of high proactive interference compared to conditions of low proactive interference. These findings were interpreted as evidence for a functional role of time-based decay, which by reducing proactive interference would be instrumental in maintaining optimal working memory performance. Irrespective of whether this interaction serves the decluttering function outlined by Altmann and colleagues, such findings leave open the question of whether interactive effects between decay-based forgetting and interference-based forgetting also exist in long-term memory.</p><p>To answer this question we employed a delayed memory two-alternative forced choice (2AFC) recognition design for visual scenes, under high and low levels of encoding interference. We measured recognition accuracy at two time-points, immediately after learning and after 1 week, while interference was indexed by the number of images in a semantic category. The decay rate was therefore defined as the difference between immediate test performance and delayed test performance. The choice for this retention interval was based on previous studies, which indicate that forgetting due to decay is a relatively slow process. For instance, <xref rid="B24" ref-type="bibr">Vogt and Magnussen (2007)</xref> tested long-term memory for 400 visual scenes and observed a decay rate of approximately 16% over a period of 9 days. We chose natural scenes as stimulus material for two reasons. Firstly, humans have a remarkable capacity to remember visual scenes in long-term memory, even after only a single exposure to the original image. This allows testing memory performance for many exemplars and over extended periods of time. Secondly, it had been shown that varying the number of exemplars per scene category could effectively control interference levels during scene encoding. <xref rid="B14" ref-type="bibr">Konkle et al. (2010b)</xref> asked participants to encode thousands of scene images. By varying the number of exemplars presented per scene category and testing memory using exemplar-level foils they observed a 2% decrease in memory performance for each doubling of the number of studied scene exemplars per category. In contrast, performance was found to be unaffected by the addition of further single image categories.</p><p>Although using natural stimuli increases ecological validity it comes at a cost of experimental control. In other words, significant effects could be specific to the stimulus set employed and might not be generalizable. To assess stimulus generality we tested recognition memory separately for man-made indoor environments and natural outdoor environments. It had been shown previously that these two classes of natural scenes are distinctive in terms of both their semantic and visual characteristics (<xref rid="B22" ref-type="bibr">Vailaya et al., 1998</xref>; <xref rid="B16" ref-type="bibr">Oliva and Schyns, 2000</xref>; <xref rid="B21" ref-type="bibr">Torralba and Oliva, 2003</xref>). Any effects observed for both classes of natural scenes would therefore likely be generalizable to other examples of visual scenes.</p><p>When attempting to measure decay-based forgetting over multiple test time-points in a repeated measures design, it is possible that stimulus foils employed in the retrieval tasks could cause interference-related forgetting, which would constitute a confound. To circumvent this issue, we employed a two-group design, measuring decay-based forgetting as a between-subject variable, across the two classes of natural scenes.</p><p>In the absence of existing evidence for interactions between decay-based and interference-based forgetting processes in long-term memory, three competing hypotheses can be formulated. (1) Higher interference during encoding leads to few and fragile memory traces, which subsequently decay at a faster rate. (2) Higher interference during encoding leads to few but more robust memory traces, which decay at a slower rate. (3) Interference does not modulate the decay rate of long-term memories.</p></sec><sec sec-type="materials|methods" id="s1"><title>Materials and Methods</title><sec><title>Participants</title><p>For the main study, eighty adults from the University of Queensland gave informed consent and were compensated for their participation with either $10 AUD or course credit. Fifty-nine full data sets (<italic>M</italic><sub>age</sub> = 21 years, 14 male) were collected. The remaining 21 datasets were unusable due to attrition (<italic>n</italic> = 6), technical errors (<italic>n</italic> = 8), and failure to meet the minimum performance criterion [70% correct in the low interference condition (<italic>n</italic> = 7)].</p><p>Twenty additional participants (<italic>M</italic><sub>age</sub> = 22 years, 4 male) provided pilot ratings of target and foil similarity prior to the commencement of testing, in order to ensure that target-foil pairings were not more similar in the low interference condition, compared with the high interference condition.</p></sec><sec><title>Stimuli</title><p>Stimuli were images of 200 manmade, indoor scenes and 200 outdoor, natural scenes collected using Google image search and in accordance with a number of inclusion criteria. All images were taken from human eye level, in the daytime, in color, unlikely to evoke a strong emotional response (e.g., no hospitals, prisons, or great heights). Images containing watermarks, people, letters, digits or memorable symbols, distinctive colors, shapes, objects, or extreme weather patterns were either excluded, or these details were removed using Adobe Photoshop CS6. Natural outdoor images were required to be free of any obvious human influence, for example, fences, roads or boats. We manipulated interference by varying the number of images in a semantic category, following <xref rid="B13" ref-type="bibr">Konkle et al. (2010a)</xref> (see Tables <xref rid="T1" ref-type="table">1</xref>, <xref rid="T2" ref-type="table">2</xref> for lists of high and low interference categories used). For both subsets of stimuli (manmade-indoor and natural-outdoor), low interference conditions were comprised of 50 images from 50 distinct semantic categories (giving one exemplar per category), and high interference conditions were comprised of 50 images from only 5 semantic categories (giving 10 exemplars from each category). Every image was paired with a similar &#x0201c;foil&#x0201d; picture during the 2AFC recognition test (hence the need for 400 images in total). Target-foil pairings were selected to be highly similar, based on features such as spatial distribution, texture, color, image quality, and object categories in the scene. Stimuli were 921 &#x000d7; 691 pixels, presented on a 21-inch monitor, with 1920 &#x000d7; 1080 screen resolution, using Presentation stimulus delivery software, version 16.2 (<italic>Neurobehavioral Systems</italic>).</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Semantic categories for man-made indoor environments.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><tbody><tr><td valign="top" align="left" colspan="4" rowspan="1"><bold>High interference</bold> (50 images from 5 categories)</td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1">Bedroom</td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1">Church</td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1">Laundry</td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1">Lecture theatre</td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1">Library</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Low interference</bold></td><td valign="top" align="left" colspan="2" rowspan="1">(50 images from 50 categories)</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Aeroplane</td><td valign="top" align="left" rowspan="1" colspan="1">Conservatory</td><td valign="top" align="left" rowspan="1" colspan="1">Gym</td><td valign="top" align="left" rowspan="1" colspan="1">Recreation centre</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Baggage claim</td><td valign="top" align="left" rowspan="1" colspan="1">Dance studio</td><td valign="top" align="left" rowspan="1" colspan="1">Hair salon</td><td valign="top" align="left" rowspan="1" colspan="1">Sauna</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Ballroom</td><td valign="top" align="left" rowspan="1" colspan="1">Deli</td><td valign="top" align="left" rowspan="1" colspan="1">Hallway</td><td valign="top" align="left" rowspan="1" colspan="1">Sewing room</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Basement car park</td><td valign="top" align="left" rowspan="1" colspan="1">Dining room</td><td valign="top" align="left" rowspan="1" colspan="1">Indoor pool</td><td valign="top" align="left" rowspan="1" colspan="1">Stables</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Bathroom</td><td valign="top" align="left" rowspan="1" colspan="1">Domestic kitchen</td><td valign="top" align="left" rowspan="1" colspan="1">Industrial kitchen</td><td valign="top" align="left" rowspan="1" colspan="1">Staircase</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Billiards room</td><td valign="top" align="left" rowspan="1" colspan="1">Dormitory</td><td valign="top" align="left" rowspan="1" colspan="1">Laboratory</td><td valign="top" align="left" rowspan="1" colspan="1">Supermarket</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Boardroom</td><td valign="top" align="left" rowspan="1" colspan="1">Dressing room</td><td valign="top" align="left" rowspan="1" colspan="1">Living room</td><td valign="top" align="left" rowspan="1" colspan="1">Temple</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Bowling alley</td><td valign="top" align="left" rowspan="1" colspan="1">Elevator</td><td valign="top" align="left" rowspan="1" colspan="1">Locker room</td><td valign="top" align="left" rowspan="1" colspan="1">Theatre</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Caf&#x000e9;</td><td valign="top" align="left" rowspan="1" colspan="1">Food Hall</td><td valign="top" align="left" rowspan="1" colspan="1">Mosque</td><td valign="top" align="left" rowspan="1" colspan="1">Train</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cellar</td><td valign="top" align="left" rowspan="1" colspan="1">Gallery</td><td valign="top" align="left" rowspan="1" colspan="1">Nursery</td><td valign="top" align="left" rowspan="1" colspan="1">Waiting room</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Child&#x02019;s bedroom</td><td valign="top" align="left" rowspan="1" colspan="1">Garage</td><td valign="top" align="left" rowspan="1" colspan="1">Office</td><td valign="top" align="left" rowspan="1" colspan="1">Walk in wardrobe</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cinema</td><td valign="top" align="left" rowspan="1" colspan="1">Greengrocer</td><td valign="top" align="left" rowspan="1" colspan="1">Pantry</td><td valign="top" align="left" rowspan="1" colspan="1">Workshop</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Greenhouse</td><td valign="top" align="left" rowspan="1" colspan="1">Public toilets</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/></tr></tbody></table></table-wrap><table-wrap id="T2" position="float"><label>Table 2</label><caption><p>Semantic categories for natural outdoor environments.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><tbody><tr><td valign="top" align="left" colspan="4" rowspan="1"><bold>High interference</bold> (50 images from 5 categories)</td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1">Alpine forest-summer</td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1">Beach</td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1">Desert</td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1">Lake</td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1">Sclerophyllous forest</td></tr><tr><td valign="top" align="left" colspan="4" rowspan="1"><bold>Low interference</bold> (50 images from 50 categories)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Alpine</td><td valign="top" align="left" rowspan="1" colspan="1">Ice desert</td><td valign="top" align="left" rowspan="1" colspan="1">Seagrass meadow</td><td valign="top" align="left" rowspan="1" colspan="1">Tidal channel</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">forest-snow</td><td valign="top" align="left" rowspan="1" colspan="1">Kelp forest</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Tidewater glacier</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Arid desert</td><td valign="top" align="left" rowspan="1" colspan="1">Mangroves</td><td valign="top" align="left" rowspan="1" colspan="1">Sea-stack</td><td valign="top" align="left" rowspan="1" colspan="1">Tombolo</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Autumn forest</td><td valign="top" align="left" rowspan="1" colspan="1">Marsh</td><td valign="top" align="left" rowspan="1" colspan="1">Shale</td><td valign="top" align="left" rowspan="1" colspan="1">Tropical rainforest</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Bluff</td><td valign="top" align="left" rowspan="1" colspan="1">Moorland</td><td valign="top" align="left" rowspan="1" colspan="1">Snow-capped mountain</td><td valign="top" align="left" rowspan="1" colspan="1">Tundra</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cactus forest</td><td valign="top" align="left" rowspan="1" colspan="1">Mudflats</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Volcano</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Canyon</td><td valign="top" align="left" rowspan="1" colspan="1">Oasis</td><td valign="top" align="left" rowspan="1" colspan="1">Swamp</td><td valign="top" align="left" rowspan="1" colspan="1">Volcano lake</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Creek</td><td valign="top" align="left" rowspan="1" colspan="1">Pebbled beach</td><td valign="top" align="left" rowspan="1" colspan="1">Salt flat</td><td valign="top" align="left" rowspan="1" colspan="1">Waterfall</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Dragon tree</td><td valign="top" align="left" rowspan="1" colspan="1">Prairie</td><td valign="top" align="left" rowspan="1" colspan="1">Sand</td><td valign="top" align="left" rowspan="1" colspan="1">Wave cut platform</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">forest</td><td valign="top" align="left" rowspan="1" colspan="1">Red sand beach</td><td valign="top" align="left" rowspan="1" colspan="1">dunes-coastal</td><td valign="top" align="left" rowspan="1" colspan="1">Wet savannah</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Dry savannah</td><td valign="top" align="left" rowspan="1" colspan="1">Redwood forest</td><td valign="top" align="left" rowspan="1" colspan="1">Sea arch</td><td valign="top" align="left" rowspan="1" colspan="1">Woodland</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Fjord</td><td valign="top" align="left" rowspan="1" colspan="1">River</td><td valign="top" align="left" rowspan="1" colspan="1">Sea cave</td><td valign="top" align="left" rowspan="1" colspan="1">Xanthorrhoea forest</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Glacier</td><td valign="top" align="left" rowspan="1" colspan="1">Rocky coast</td><td valign="top" align="left" rowspan="1" colspan="1">Sea cliff</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Grassland</td><td valign="top" align="left" rowspan="1" colspan="1">Rolling hills</td><td valign="top" align="left" rowspan="1" colspan="1">Temperate</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Heathland</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">rainforest</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/></tr></tbody></table></table-wrap></sec><sec><title>Stimulus Validation: Pilot Similarity Ratings</title><p>Prior to testing, we measured the similarity of target-foil stimulus pairs. This enabled us to ensure that the difficulty of discriminating target-foil pairs was equivalent for high interference and low interference pairs. Twenty participants (<italic>M</italic><sub>age</sub> = 22 years, 4 male) were asked to subjectively rate the similarity of each target-foil pair (200 pairs in total) on a 5-point Likert scale, ranging from <italic>1 = most similar (almost identical) to 5 = least similar</italic>. For both sets of stimuli, participants rated target-foil pairings in the <italic>low interference</italic> condition (manmade indoor stimuli: <italic>M</italic> = 3.07, <italic>SD</italic> = 0.49, 95% CI [2.85, 3.29]; natural outdoor stimuli: <italic>M</italic> = 2.74, <italic>SD</italic> = 0.59, CI [2.48, 3.00]) at comparable levels of similarity to images in the <italic>high interference</italic> condition (manmade indoor stimuli: <italic>M</italic> = 3.27, <italic>SD</italic> = 0.46, 95% CI [3.07, 3.47]; natural outdoor stimuli: <italic>M</italic> = 2.95, <italic>SD</italic> = 0.53, CI [2.72, 3.18]). It is important to note that target-foil similarity was actually lower in the high interference condition [manmade indoor: <italic>t</italic>(19) = 3.504, <italic>p</italic> = 0.002; natural outdoor: <italic>t</italic>(19) = 4.524, <italic>p</italic> &#x0003c; 0.001], which means that lower memory accuracy in the high-inference condition cannot be explained by higher target-foil similarity, but must be due the higher number of images per category.</p></sec><sec><title>Procedure</title><p>During encoding 200 images of manmade-indoor and natural-outdoor were presented randomly interleaved in the same session, appearing for 5 s, with a 600 ms inter-stimulus interval (see Figure <xref ref-type="fig" rid="F1">1A</xref>). Participants were asked to attend to the stimuli and told that they would be subsequently asked to recognize them. Participants were further shown an example trial of the recognition phase to alert them to the fact that they would have to distinguish the target from a highly similar foil image. After the encoding session the 60 participants were randomly assigned to two groups. The first group was tested immediately for manmade indoor scenes and after 1 week for natural outdoor scenes. Accordantly, the second group was tested immediately for natural outdoor scenes and after 1 week for manmade indoor scenes. This crosswise design allowed us to measure decay-based forgetting (as a between-subject variable), while avoiding potential confounds due to repeated testing of highly similar stimulus material. In addition, it allowed us to assess stimulus generality, by measuring memory accuracy for two sets of semantically and visually distinct scene images. The recognition phase consisted of 200 2AFC trials. In each trial, two images from the same scene category were presented side by side &#x02013; one was a previously studied target image, and the other a distractor image that participants had not seen before (see Figure <xref ref-type="fig" rid="F1">1B</xref>). Participants were instructed to indicate which of the two scenes they had previously studied. No feedback was provided. The same set of target-foil pairs was used for all participants; however, in half of the trials, the target image was on the left side of the screen and the distractor on the right, and vice versa for the other half of the trials. Half of the trials (i.e., 100) contained images from the low-interference scene categories and the other half contained images from the high-interference scene categories. Participants proceeded at their own pace and were told to emphasize accuracy, not speed.</p><fig id="F1" position="float"><label>FIGURE 1</label><caption><p>Encoding and recognition procedures. <bold>(A)</bold> During encoding, participants viewed 200 images for 5 s each, with a 600 ms inter-stimulus interval. <bold>(B)</bold> During recognition, participants viewed 100 target-foil pairs, and attempted to identify the image they had seen previously. Memory was tested immediately as well as after 1 week.</p></caption><graphic xlink:href="fpsyg-10-00021-g001"/></fig></sec></sec><sec><title>Results</title><sec><title>Man-Made Indoor Scenes</title><p>Accuracy for man-made indoor scenes averaged over immediate and delayed testing conditions was 85.46% (<italic>SD</italic> = 11.46%) for low interference images and 75.12% (<italic>SD</italic> = 8.51%) for high interference images, effectively replicating the finding by <xref rid="B13" ref-type="bibr">Konkle et al. (2010a</xref>,<xref rid="B14" ref-type="bibr">b)</xref>. In addition, accuracy averaged over both interference conditions, decreased from 85.07% (<italic>SD</italic> = 10.24%) at immediate testing, to 75.12% (<italic>SD</italic> = 10.26%) 1 week later (168 h). A two-way mixed ANOVA indicated significant effects of interference (within-subjects factor), <italic>F</italic>(1,57) = 123.587, <italic>p</italic> &#x0003c; 0.001, partial-&#x003b7;<sup>2</sup> = 0.684, and retention interval (between-subjects factor), <italic>F</italic>(1,57) = 22.591, <italic>p</italic> &#x0003c; 0.001, partial-&#x003b7;<sup>2</sup> = 0.284. Importantly, their interaction was also significant, <italic>F</italic>(1,57) = 22.734, <italic>p</italic> &#x0003c; 0.001, partial-&#x003b7;<sup>2</sup> = 0.285, such that memory accuracy decayed at a slower rate for images that were encoded under high levels of interference (see Figure <xref ref-type="fig" rid="F2">2A</xref>; M&#x00394; = 5.32%, SEM&#x00394; = 2.12%), <italic>t</italic>(57) = 2.507, <italic>p</italic> = 0.015, than under low levels (M&#x00394; = 14.12%, SEM&#x00394; = 2.38%), <italic>t</italic>(41) = 2.661, <italic>p</italic> &#x0003c; 0.001.</p><fig id="F2" position="float"><label>FIGURE 2</label><caption><p>Recognition accuracy for <bold>(A)</bold> manmade indoor and <bold>(B)</bold> natural outdoor scenes encoded under low and high levels of interference, during immediate (0 h) and delayed testing (168 h). Error bars indicate 95% confidence intervals.</p></caption><graphic xlink:href="fpsyg-10-00021-g002"/></fig></sec><sec><title>Natural Outdoor Scenes</title><p>The results for natural outdoor scenes followed an analogous pattern. While overall accuracy was poorer than for indoor scenes [<italic>t</italic>(59) = 5.725, <italic>p</italic> &#x0003c; 0.001], the main effects and interaction remained highly significant. When averaging over immediate and delayed testing conditions, low interference images (<italic>M</italic> = 73.79%, <italic>SD</italic> = 11.13%) were better recognized than high interference images (<italic>M</italic> = 65.73%, <italic>SD</italic> = 10.45%), <italic>F</italic>(1,57) = 59.076, <italic>p</italic> &#x0003c; 0.001, partial-&#x003b7;<sup>2</sup> = 0.509. Averaging over both interference conditions, accuracy also decreased significantly from 76.05% (<italic>SD</italic> = 10.11%) at immediate testing to 63.67% (<italic>SD</italic> = 9.28%) 1 week later, <italic>F</italic>(1,57) = 37.398, <italic>p</italic> &#x0003c; 0.001, partial-&#x003b7;<sup>2</sup> = 0.396. Most importantly, as in Experiment 1, interference and retention interval interacted, <italic>F</italic>(1,57) = 6.906, <italic>p</italic> = 0.011, partial-&#x003b7;<sup>2</sup> = 0.108, and the observed pattern of result (see Figure <xref ref-type="fig" rid="F2">2B</xref>) indicate once more that memory traces decay at a slower rate for images that were encoded under high levels of interference (M&#x00394; = 9.62%, SEM&#x00394; = 2.43%), <italic>t</italic>(57) = 3.969, <italic>p</italic> &#x0003c; 0.001, than under low levels (M&#x00394; = 15.16%, SEM&#x00394; = 2.12%), <italic>t</italic>(57) = 7.127, <italic>p</italic> &#x0003c; 0.001.</p></sec></sec><sec><title>Discussion</title><p>We investigated the presence of interactive effects between decay-based forgetting and interference-based forgetting in long-term memory. We found that higher levels of interference during encoding led to a slower subsequent decay rate. This indicates that competition from similar stimuli during encoding results in fewer, but also more robust memory traces, which decay at a slower rate. On the other hand, lower levels of interference during encoding allow more memory traces to form initially. Yet these memories subsequently decay at a faster rate on average than high interference memories. It is important to note that the slower decay rate for memory traces formed under high interference cannot be explained by a floor effect (i.e., no room for accuracy reduction), since performance levels in the high interference condition are significantly above the 50% baseline, for indoor as well as outdoor stimuli (one-sample <italic>t</italic>-test, <italic>p</italic> &#x0003c; 0.0001). Interactions between decay and interference were also conceptually replicated across two distinct stimulus sets, one containing indoor manmade scenes, and the other containing outdoor natural scenes. This suggests that the significant interaction between interference and decay is not specific to the individual stimuli chosen and is likely to be generalizable to a variety of stimulus material. Future studies should explore whether the effect generalizes to more abstract visual stimuli, such as printed or spoken words.</p><p>Our results suggest that a &#x0201c;survival of the fittest&#x0201d; principle applies to long-term memory processes, in which stimulus competition during encoding acts as &#x0201c;selection pressure.&#x0201d; This pattern is in contrast to the findings in working-memory research (<xref rid="B1" ref-type="bibr">Altmann and Gray, 2002</xref>; <xref rid="B2" ref-type="bibr">Altmann and Schunn, 2012</xref>), which indicated that higher levels of interference are associated with a faster decay rate. Given the differences in the molecular biological processes that underlie short-term and long-term memories it is not surprising that differences also exist on the behavioral level. For instance, changes in gene expression are required to convert short-term memory (STM) that lasts less than &#x0223c;1 h to long-term memory (LTM). Short-term memories are also thought to be associated with alterations in pre-existing proteins, whereas long-term memories require a protein synthesis-dependent form of synaptic plasticity (for an overview see <xref rid="B11" ref-type="bibr">Kandel, 2001</xref>). Future studies would, however, be necessary to further investigate the neural processes that underlie our finding.</p><p>The study by <xref rid="B13" ref-type="bibr">Konkle et al. (2010a)</xref> tested the effect of encoding related interference, by varying the number of items per image category during the learning phase, but only tested single items during the recognition phase (i.e., they always tested memory for the first item presented from each category). Their findings provide therefore strong evidence for retroactive interference during encoding (i.e., later items impact the encoding of the earlier item). As a sidenote, although not tested in their study it is nevertheless possible that proactive interference (i.e., earlier items impact the encoding of later items) would produce comparable results. In contrast, to the study by <xref rid="B13" ref-type="bibr">Konkle et al. (2010a)</xref>, we tested not only one but all items per category in the high interference condition. It is therefore possible that the reduced performance we observed during recognition is not only due to encoding related interference (like in the Konkle study), but is also partially caused by interference during the recognition phase. For instance, <xref rid="B6" ref-type="bibr">Criss et al. (2011)</xref> reported interference effects due to items presented during the test phase, i.e., poorer performance with an increasing number of test items. The underlying idea is that each test produces a memory trace, and therefore a source of interference.</p><p>To get an approximate measure of the potential impact of recognition-related interference in our study, we conducted a <italic>post hoc</italic> analysis that only included the first half of items tested during recognition (i.e., the first 5 items for each high interference category and the first 25 items for the low interference indoor and outdoor categories). The logic behind this partial analysis was that any improvement in memory accuracy relative to the full analysis would be indicative of a relative contribution of recognition-related interference. In addition, it would allow us to evaluate whether the observed interaction between interference and retention interval is still observable, when recognition-related interfered is reduced, while encoding-related interference is kept stable. Our analysis revealed (see Figure <xref ref-type="fig" rid="F3">3</xref>) that, while the overall effect of interference was reduced (suggesting the presence of recognition-related interference), the interaction between interference and retention interval was still significant <italic>F</italic>(1,57) = 19.359, <italic>p</italic> &#x0003c; 0.001. The data therefore indicate that, although recognition-related interference had an additional impact on recognition accuracy, the interactive relationship between encoding related interference and retention interval was still present. Interestingly, the additional analysis showed that, if interference during recognition is accounted for, memory performance for low and high interference items was identical at delayed testing. This seems to suggest that the initial advantage of low-interference encoding dissipates after just 1 week. It is important to note that our experiment was not designed to distinguish encoding- and recognition-related contribution to memory interference and future studies are needed to disentangle them more effectively.</p><fig id="F3" position="float"><label>FIGURE 3</label><caption><p>Memory accuracy for the first half of items in the recognition test (averaged over manmade indoor and natural outdoor scenes). Error bars indicate 95% confidence intervals.</p></caption><graphic xlink:href="fpsyg-10-00021-g003"/></fig><p>Although not a theoretically motivated question of our study, we observed that memory for man-made indoor environments is better (80.07%) than for natural outdoor environments (69.78%). The difference could be due differences in low-level visual attributes of these two stimulus classes (<xref rid="B19" ref-type="bibr">Szummer and Picard, 1998</xref>; <xref rid="B17" ref-type="bibr">Oliva and Torralba, 2001</xref>). Typically, natural outdoor scenes are less structured and less distinctive than man-made indoor scenes. This greater degree of similarity could cause an increased overall level of interference compared to indoor man-made images, an effect that would explain poorer recognition performance for this image category. Alternatively, it could be that recognition performance was mediated by differences in visual expertise for the two stimulus classes. It has been shown that visual expertise leads to domain-specific increases in memory performance (<xref rid="B23" ref-type="bibr">Vicente and Wang, 1998</xref>; <xref rid="B7" ref-type="bibr">Curby et al., 2009</xref>) and it is likely that cohort of University students had on average greater exposure to man-made than natural environments.</p><p>Our study measured memory performance only for categories with 1 and 10 exemplars. Given the findings of <xref rid="B13" ref-type="bibr">Konkle et al. (2010a</xref>,<xref rid="B14" ref-type="bibr">b)</xref>, which show that every doubling of the number of images per category results in a &#x0223c;2% change in recognition accuracy, we would expect the interaction effect to logarithmically increase with the number of presented items per scene category. Our study measured recognition accuracy at two time points. Another objective for future studies would be to measure retention rates at shorter as well as longer retention intervals. Although experimentally costly, a finer-grained forgetting function would provide a better indication of how the rate of forgetting of high and low interference image sets varied over time. The relationship is unlikely to be linear, given the large body of evidence indicating that forgetting over time is a curvilinear function (<xref rid="B28" ref-type="bibr">Wixted and Ebbesen, 1991</xref>; <xref rid="B26" ref-type="bibr">Wixted, 2004</xref>). In addition, measuring forgetting over longer time periods could enlighten us as to whether images encoded under high interference will eventually be better remembered than images encoded under low interference (i.e., presence of a crossover interaction), or if accuracy rates will simply converge.</p><p>A limitation of our study is that, although sources of extra-experimental variation were controlled where possible, with testing distributed throughout the day and working week to avoid time of day and time of week effects, it was not possible to control for interference that could potentially be caused by engaging in daily activities during the 1-week retention interval. Yet, this is a common factor in long-term memory research, since it would be practically impossible to isolate participants from all sources of stimulation and new learning to actually determine the potential contribution of extra-experimental interference on recognition accuracy.</p><p>In conclusion, our study provided the first evidence for the existence of interactive processes between interference-based and decay-based forgetting in long-term memory for visual scenes. Using two conceptually distinct stimulus sets, our results indicate that increased stimulus competition during encoding results in fewer but more robust memory traces, akin to a &#x0201c;survival of the fittest principle.&#x0201d; Our finding suggests that stimulus competition during encoding modulates synaptic plasticity, a hypothesis that could incorporated in computational models of forgetting, and further examined using neurophysiological techniques. Finally, our finding might have implications for educational settings, yet further investigations over longer timespans and across sensory modalities are necessary, before its relevance to real-world long-term memory maintenance can be reliably determined.</p></sec><sec sec-type="data-availability"><title>Data Availability Statement</title><p>The data and program code are available at Open Science Framework: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/K7YW4">doi: 10.17605/OSF.IO/K7YW4</ext-link>. The analysis scripts use &#x0201c;importPresentationLog.m&#x0201d; written by Tobias Otto, which is available at GitHub.</p></sec><sec><title>Ethics Statement</title><p>All subjects gave a written informed consent in accordance with the Declaration of Helsinki. The study was approved by the Human Research Ethics Committee of The University of Queensland.</p></sec><sec><title>Author Contributions</title><p>OB and EC were responsible for study design and data acquisition. OB, EC, and JM were responsible data analysis and manuscript writing.</p></sec><sec><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></body><back><fn-group><fn fn-type="financial-disclosure"><p><bold>Funding.</bold> This work was supported by the National Health and Medical Research Council (NHMRC; APP1098862) to OB.</p></fn></fn-group><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altmann</surname><given-names>E. M.</given-names></name><name><surname>Gray</surname><given-names>W. D.</given-names></name></person-group> (<year>2002</year>). <article-title>Forgetting to remember: the functional relationship of decay and interference.</article-title>
<source><italic>Psychol. Sci.</italic></source>
<volume>13</volume>
<fpage>27</fpage>&#x02013;<lpage>33</lpage>. <pub-id pub-id-type="doi">10.1111/1467-9280.00405</pub-id>
<?supplied-pmid 11892775?><pub-id pub-id-type="pmid">11892775</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altmann</surname><given-names>E. M.</given-names></name><name><surname>Schunn</surname><given-names>C. D.</given-names></name></person-group> (<year>2012</year>). <article-title>Decay versus interference: a new look at an old interaction.</article-title>
<source><italic>Psychol. Sci.</italic></source>
<volume>23</volume>
<fpage>1435</fpage>&#x02013;<lpage>1437</lpage>. <pub-id pub-id-type="doi">10.1177/0956797612446027</pub-id>
<?supplied-pmid 23012268?><pub-id pub-id-type="pmid">23012268</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>M. C.</given-names></name><name><surname>Neely</surname><given-names>J. H.</given-names></name></person-group> (<year>1996</year>). &#x0201c;<article-title>Interference and inhibition in memory retrieval</article-title>,&#x0201d; in <source><italic>Memory Handbook of Perception and Cognition</italic></source>, <edition>2nd</edition> Edn, <role>eds</role>
<person-group person-group-type="editor"><name><surname>Bjork</surname><given-names>E. L.</given-names></name><name><surname>Bjork</surname><given-names>R. A.</given-names></name></person-group> (<publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Academic Press</publisher-name>), <fpage>237</fpage>&#x02013;<lpage>313</lpage>.</mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>J.</given-names></name></person-group> (<year>1958</year>). <article-title>Some tests of the decay theory of immediate memory.</article-title>
<source><italic>Q. J. Exp. Psychol.</italic></source>
<volume>10</volume>
<fpage>12</fpage>&#x02013;<lpage>21</lpage>. <pub-id pub-id-type="doi">10.1080/17470215808416249</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cason</surname><given-names>H.</given-names></name></person-group> (<year>1924</year>). <article-title>Criticisms of the laws of exercise and effect.</article-title>
<source><italic>Psychol. Rev.</italic></source>
<volume>31</volume>
<fpage>397</fpage>&#x02013;<lpage>417</lpage>. <pub-id pub-id-type="doi">10.1037/h0073009</pub-id>
<?supplied-pmid 12951745?><pub-id pub-id-type="pmid">12951745</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Criss</surname><given-names>A. H.</given-names></name><name><surname>Malmberg</surname><given-names>K. J.</given-names></name><name><surname>Shiffrin</surname><given-names>R. M.</given-names></name></person-group> (<year>2011</year>). <article-title>Output interference in recognition memory.</article-title>
<source><italic>J. Mem. Lang.</italic></source>
<volume>64</volume>
<fpage>316</fpage>&#x02013;<lpage>326</lpage>.</mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curby</surname><given-names>K. M.</given-names></name><name><surname>Glazek</surname><given-names>K.</given-names></name><name><surname>Gauthier</surname><given-names>I.</given-names></name></person-group> (<year>2009</year>). <article-title>A visual short-term memory advantage for objects of expertise.</article-title>
<source><italic>J. Exp. Psychol. Hum. Percept. Perform.</italic></source>
<volume>35</volume>
<fpage>94</fpage>&#x02013;<lpage>107</lpage>. <pub-id pub-id-type="doi">10.1037/0096-1523.35.1.94</pub-id>
<?supplied-pmid 19170473?><pub-id pub-id-type="pmid">19170473</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dewar</surname><given-names>M.</given-names></name><name><surname>Alber</surname><given-names>J.</given-names></name><name><surname>Butler</surname><given-names>C.</given-names></name><name><surname>Cowan</surname><given-names>N.</given-names></name><name><surname>Della Sala</surname><given-names>S.</given-names></name></person-group> (<year>2012</year>). <article-title>Brief wakeful resting boosts new memories over the long term.</article-title>
<source><italic>Psychol. Sci.</italic></source>
<volume>23</volume>
<fpage>955</fpage>&#x02013;<lpage>960</lpage>. <pub-id pub-id-type="doi">10.1177/0956797612441220</pub-id>
<?supplied-pmid 22829465?><pub-id pub-id-type="pmid">22829465</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardt</surname><given-names>O.</given-names></name><name><surname>Nader</surname><given-names>K.</given-names></name><name><surname>Nadel</surname><given-names>L.</given-names></name></person-group> (<year>2013</year>). <article-title>Decay happens: the role of active forgetting in memory.</article-title>
<source><italic>Trends Cogn. Sci.</italic></source>
<volume>17</volume>
<fpage>111</fpage>&#x02013;<lpage>120</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2013.01.001</pub-id>
<?supplied-pmid 23369831?><pub-id pub-id-type="pmid">23369831</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkins</surname><given-names>J. G.</given-names></name><name><surname>Dallenbach</surname><given-names>C. M.</given-names></name></person-group> (<year>1924</year>). <article-title>Obliviscence during sleep and waking.</article-title>
<source><italic>Am. J. Psychol.</italic></source>
<volume>35</volume>
<fpage>605</fpage>&#x02013;<lpage>612</lpage>. <pub-id pub-id-type="doi">10.2307/1414040</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kandel</surname><given-names>E. R.</given-names></name></person-group> (<year>2001</year>). <article-title>The molecular biology of memory storage: a dialogue between genes and synapses.</article-title>
<source><italic>Science</italic></source>
<volume>294</volume>
<fpage>1030</fpage>&#x02013;<lpage>1038</lpage>. <pub-id pub-id-type="doi">10.1126/science.1067020</pub-id>
<?supplied-pmid 11691980?><pub-id pub-id-type="pmid">11691980</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keppel</surname><given-names>G.</given-names></name><name><surname>Underwood</surname><given-names>B. J.</given-names></name></person-group> (<year>1962</year>). <article-title>Proactive inhibition in short-term retention of single items.</article-title>
<source><italic>J. Verbal Learning Verbal Behav.</italic></source>
<volume>1</volume>
<fpage>153</fpage>&#x02013;<lpage>161</lpage>. <pub-id pub-id-type="doi">10.1016/S0022-5371(62)80023-1</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Konkle</surname><given-names>T.</given-names></name><name><surname>Brady</surname><given-names>T. F.</given-names></name><name><surname>Alvarez</surname><given-names>G. A.</given-names></name><name><surname>Oliva</surname><given-names>A.</given-names></name></person-group> (<year>2010a</year>). <article-title>Conceptual distinctiveness supports detailed visual long-term memory for real-world objects.</article-title>
<source><italic>J. Exp. Psychol. Gen.</italic></source>
<volume>139</volume>
<fpage>558</fpage>&#x02013;<lpage>578</lpage>. <pub-id pub-id-type="doi">10.1037/a0019165</pub-id>
<?supplied-pmid 20677899?><pub-id pub-id-type="pmid">20677899</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Konkle</surname><given-names>T.</given-names></name><name><surname>Brady</surname><given-names>T. F.</given-names></name><name><surname>Alvarez</surname><given-names>G. A.</given-names></name><name><surname>Oliva</surname><given-names>A.</given-names></name></person-group> (<year>2010b</year>). <article-title>Scene memory is more detailed than you think: the role of categories in visual long-term memory.</article-title>
<source><italic>Psychol. Sci.</italic></source>
<volume>21</volume>
<fpage>1551</fpage>&#x02013;<lpage>1556</lpage>. <pub-id pub-id-type="doi">10.1177/0956797610385359</pub-id>
<?supplied-pmid 20921574?><pub-id pub-id-type="pmid">20921574</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGeoch</surname><given-names>J. A.</given-names></name></person-group> (<year>1932</year>). <article-title>Forgetting and the law of disuse.</article-title>
<source><italic>Psychol. Rev.</italic></source>
<volume>39</volume>
<fpage>352</fpage>&#x02013;<lpage>370</lpage>. <pub-id pub-id-type="doi">10.1037/h0069819</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oliva</surname><given-names>A.</given-names></name><name><surname>Schyns</surname><given-names>P. G.</given-names></name></person-group> (<year>2000</year>). <article-title>Diagnostic colors mediate scene recognition.</article-title>
<source><italic>Cogn. Psychol.</italic></source>
<volume>41</volume>
<fpage>176</fpage>&#x02013;<lpage>210</lpage>. <?supplied-pmid 10968925?><pub-id pub-id-type="pmid">10968925</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oliva</surname><given-names>A.</given-names></name><name><surname>Torralba</surname><given-names>A.</given-names></name></person-group> (<year>2001</year>). <article-title>Modeling the shape of the scene: a holistic representation of the spatial envelope.</article-title>
<source><italic>Int. J. Comput. Vis.</italic></source>
<volume>42</volume>
<fpage>145</fpage>&#x02013;<lpage>175</lpage>. <pub-id pub-id-type="doi">10.1023/A:1011139631724</pub-id>
<?supplied-pmid 16387345?><pub-id pub-id-type="pmid">16387345</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname><given-names>E. B.</given-names></name></person-group> (<year>1933</year>). <article-title>A discussion on the temporal point of interpolation and degree of retroactive inhibition.</article-title>
<source><italic>J. Comp. Psychol.</italic></source>
<volume>16</volume>
<fpage>411</fpage>&#x02013;<lpage>414</lpage>. <pub-id pub-id-type="doi">10.1037/h0074460</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szummer</surname><given-names>M.</given-names></name><name><surname>Picard</surname><given-names>R.</given-names></name></person-group> (<year>1998</year>). &#x0201c;<article-title>Indoor-outdoor image classification. in content-based access of image and video database</article-title>,&#x0201d; in <source><italic>Proceedings of the 1998 IEEE International Workshop</italic></source>, (San Jose, CA: IEEE), <fpage>42</fpage>&#x02013;<lpage>51</lpage>.</mixed-citation></ref><ref id="B20"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Thorndike</surname><given-names>E.</given-names></name></person-group> (<year>1913</year>). <source><italic>The Psychology of Learning.</italic></source>
<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Teachers College, Columbia University</publisher-name>.</mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torralba</surname><given-names>A.</given-names></name><name><surname>Oliva</surname><given-names>A.</given-names></name></person-group> (<year>2003</year>). <article-title>Statistics of natural image categories.</article-title>
<source><italic>Network</italic></source>
<volume>14</volume>
<fpage>391</fpage>&#x02013;<lpage>412</lpage>.<pub-id pub-id-type="pmid">12938764</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vailaya</surname><given-names>A.</given-names></name><name><surname>Jain</surname><given-names>A.</given-names></name><name><surname>Zhang</surname><given-names>H. J.</given-names></name></person-group> (<year>1998</year>). <article-title>On image classification: city images vs Landscapes.</article-title>
<source><italic>Pattern Recognit.</italic></source>
<volume>31</volume>
<fpage>1921</fpage>&#x02013;<lpage>1935</lpage>.</mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vicente</surname><given-names>K. J.</given-names></name><name><surname>Wang</surname><given-names>J. H.</given-names></name></person-group> (<year>1998</year>). <article-title>An ecological theory of expertise effects in memory recall.</article-title>
<source><italic>Psychol. Rev.</italic></source>
<volume>105</volume>
<fpage>33</fpage>&#x02013;<lpage>57</lpage>. <?supplied-pmid 9450371?><pub-id pub-id-type="pmid">9450371</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogt</surname><given-names>S.</given-names></name><name><surname>Magnussen</surname><given-names>S.</given-names></name></person-group> (<year>2007</year>). <article-title>Long-term memory for 400 pictures on a common theme.</article-title>
<source><italic>Exp. Psychol.</italic></source>
<volume>54</volume>
<fpage>298</fpage>&#x02013;<lpage>303</lpage>. <pub-id pub-id-type="doi">10.1027/1618-3169.54.4.298</pub-id>
<?supplied-pmid 17953150?><pub-id pub-id-type="pmid">17953150</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waugh</surname><given-names>N.</given-names></name><name><surname>Norman</surname><given-names>D.</given-names></name></person-group> (<year>1965</year>). <article-title>Primary memory.</article-title>
<source><italic>Psychol. Rev.</italic></source>
<volume>72</volume>
<fpage>89</fpage>&#x02013;<lpage>104</lpage>.<pub-id pub-id-type="pmid">14282677</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wixted</surname><given-names>J. T.</given-names></name></person-group> (<year>2004</year>). <article-title>The psychology and neuroscience of forgetting.</article-title>
<source><italic>Annu. Rev. Psychol.</italic></source>
<volume>55</volume>
<fpage>235</fpage>&#x02013;<lpage>269</lpage>. <pub-id pub-id-type="doi">10.1146/annurev.psych.55.090902.141555</pub-id><pub-id pub-id-type="pmid">14744216</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wixted</surname><given-names>J. T.</given-names></name></person-group> (<year>2005</year>). <article-title>A theory about why we forget what we once knew.</article-title>
<source><italic>Curr. Dir. Psychol. Sci.</italic></source>
<volume>14</volume>
<fpage>6</fpage>&#x02013;<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1111/j.0963-7214.2005.00324.x</pub-id>
<?supplied-pmid 24767478?><pub-id pub-id-type="pmid">24767478</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wixted</surname><given-names>J. T.</given-names></name><name><surname>Ebbesen</surname><given-names>E. B.</given-names></name></person-group> (<year>1991</year>). <article-title>On the form of forgetting.</article-title>
<source><italic>Psychol. Sci.</italic></source>
<volume>2</volume>
<fpage>409</fpage>&#x02013;<lpage>415</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9280.1991.tb00175.x</pub-id></mixed-citation></ref></ref-list></back></article>