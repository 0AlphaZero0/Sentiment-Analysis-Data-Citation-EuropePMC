<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName journalpublishing.dtd?><?SourceDTD.Version 2.3?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 2?><front><journal-meta><journal-id journal-id-type="nlm-ta">Genetics</journal-id><journal-id journal-id-type="iso-abbrev">Genetics</journal-id><journal-id journal-id-type="hwp">genetics</journal-id><journal-id journal-id-type="pmc">genetics</journal-id><journal-id journal-id-type="publisher-id">genetics</journal-id><journal-title-group><journal-title>Genetics</journal-title></journal-title-group><issn pub-type="ppub">0016-6731</issn><issn pub-type="epub">1943-2631</issn><publisher><publisher-name>Genetics Society of America</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">3697978</article-id><article-id pub-id-type="pmid">23636737</article-id><article-id pub-id-type="publisher-id">151217</article-id><article-id pub-id-type="doi">10.1534/genetics.113.151217</article-id><article-categories><subj-group subj-group-type="heading"><subject>Investigations</subject><subj-group><subject>Genetics of Complex Traits</subject></subj-group></subj-group></article-categories><title-group><article-title>Dissecting High-Dimensional Phenotypes with Bayesian Sparse Factor Analysis of Genetic Covariance Matrices</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Runcie</surname><given-names>Daniel E.</given-names></name><xref ref-type="aff" rid="aff1">*</xref><xref ref-type="corresp" rid="cor1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Mukherjee</surname><given-names>Sayan</given-names></name><xref ref-type="aff" rid="aff2"><sup>&#x02020;</sup></xref></contrib><aff id="aff1"><label>*</label>Department of Biology, Duke University, Durham, North Carolina 27708</aff><aff id="aff2"><label>&#x02020;</label>Departments of Statistical Science, Computer Science, and Mathematics, Institute for Genome Sciences &#x00026; Policy, Duke University, Durham, North Carolina 27708</aff></contrib-group><author-notes><fn id="afn1"><p><?release-delay 0|0?>Supporting information is available online at <ext-link ext-link-type="uri" xlink:href="http://www.genetics.org/lookup/suppl/doi:10.1534/genetics.113.151217/-/DC1">http://www.genetics.org/lookup/suppl/doi:10.1534/genetics.113.151217/-/DC1</ext-link>.</p></fn><corresp id="cor1"><label>1</label>Corresponding author: Department of Evolution and Ecology, University of California Davis, 1 Shields Ave., Davis, CA 95616. E-mail: <email>daniel.e.runcie@gmail.com</email></corresp></author-notes><pub-date pub-type="epub-ppub"><month>7</month><year>2013</year></pub-date><!--Fake ppub date generated by PMC from publisher
							pub-date/@pub-type='epub-ppub' --><pub-date pub-type="ppub"><month>7</month><year>2013</year></pub-date><pub-date pub-type="pmc-release"><month>7</month><year>2013</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="epub-ppub"/>. --><volume>194</volume><issue>3</issue><fpage>753</fpage><lpage>767</lpage><history><date date-type="received"><day>12</day><month>3</month><year>2013</year></date><date date-type="accepted"><day>17</day><month>4</month><year>2013</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2013 by the Genetics Society of America</copyright-statement><copyright-year>2013</copyright-year><license license-type="open-access"><license-p>Available freely online through the author-supported open access option.</license-p></license></permissions><self-uri xlink:title="pdf" xlink:type="simple" xlink:href="753.pdf"/><abstract><p>Quantitative genetic studies that model complex, multivariate phenotypes are important for both evolutionary prediction and artificial selection. For example, changes in gene expression can provide insight into developmental and physiological mechanisms that link genotype and phenotype. However, classical analytical techniques are poorly suited to quantitative genetic studies of gene expression where the number of traits assayed per individual can reach many thousand. Here, we derive a Bayesian genetic sparse factor model for estimating the genetic covariance matrix (G-matrix) of high-dimensional traits, such as gene expression, in a mixed-effects model. The key idea of our model is that we need consider only G-matrices that are biologically plausible. An organism&#x02019;s entire phenotype is the result of processes that are modular and have limited complexity. This implies that the G-matrix will be highly structured. In particular, we assume that a limited number of intermediate traits (or factors, <italic>e.g.</italic>, variations in development or physiology) control the variation in the high-dimensional phenotype, and that each of these intermediate traits is sparse &#x02013; affecting only a few observed traits. The advantages of this approach are twofold. First, sparse factors are interpretable and provide biological insight into mechanisms underlying the genetic architecture. Second, enforcing sparsity helps prevent sampling errors from swamping out the true signal in high-dimensional data. We demonstrate the advantages of our model on simulated data and in an analysis of a published <italic>Drosophila melanogaster</italic> gene expression data set.</p></abstract><kwd-group><kwd>G matrix</kwd><kwd>factor model</kwd><kwd>sparsity</kwd><kwd>Bayesian inference</kwd><kwd>animal model</kwd></kwd-group><counts><page-count count="15"/></counts><custom-meta-group><custom-meta><meta-name> DJS Export </meta-name><meta-value>v1</meta-value></custom-meta></custom-meta-group></article-meta></front><body><p>QUANTITATIVE studies of evolution or artificial selection often focus on a single or a handful of traits, such as size, survival, or crop yield. Recently, there has been an effort to collect more comprehensive phenotypic information on traits such as morphology, behavior, physiology, or gene expression (<xref rid="bib27" ref-type="bibr">Houle 2010</xref>). For example, the expression of thousands of genes can be measured simultaneously (<xref rid="bib18" ref-type="bibr">Gibson and Weir 2005</xref>; <xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> 2009</xref>; <xref rid="bib40" ref-type="bibr">McGraw <italic>et al.</italic> 2011</xref>), together capturing complex patterns of gene regulation that reflect molecular networks, cellular stresses, and disease states (<xref rid="bib12" ref-type="bibr">de la Cruz <italic>et al.</italic> 2010</xref>; <xref rid="bib62" ref-type="bibr">Xiong <italic>et al.</italic> 2012</xref>). Studying the quantitative genetics of multiple correlated traits requires a joint modeling approach (<xref rid="bib60" ref-type="bibr">Walsh and Blows 2009</xref>). However, applying the tools of quantitative genetics to high-dimensional, highly correlated data sets presents considerable analytical and computational challenges (<xref rid="bib46" ref-type="bibr">Meyer and Kirkpatrick 2010</xref>). In this article we formulate a modeling framework to address these challenges for a common quantitative genetic analysis: estimating the matrix of additive genetic variances and covariances, or G-matrix (<xref rid="bib39" ref-type="bibr">Lynch and Walsh 1998</xref>). The G-matrix encodes information about responses to selection (<xref rid="bib37" ref-type="bibr">Lande 1979</xref>), evolutionary constraints (<xref rid="bib31" ref-type="bibr">Kirkpatrick 2009</xref>), and modularity (<xref rid="bib9" ref-type="bibr">Cheverud 1996</xref>) and is important for predicting evolutionary change (<xref rid="bib53" ref-type="bibr">Schluter 1996</xref>).</p><p>The challenge in scaling classic methods to hundreds or thousands of traits is that the number of modeling parameters grows rapidly. An unconstrained G-matrix for <italic>p</italic> traits requires <italic>p</italic>(<italic>p</italic> + 1)/2 parameters, and modeling environmental variation and measurement error <xref rid="bib33" ref-type="bibr">(Kirkpatrick and Meyer 2004)</xref> requires at least as many additional parameters. Such large numbers of parameters can lead to instability in parameter estimates&#x02014;analyses that are highly sensitive to outliers and have high variance. Previous methods for overcoming this instability include (1) &#x0201c;bending&#x0201d; or smoothing unconstrained estimates of G-matrices, such as from pairwise estimates of genetic covariation (<xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> 2009</xref>; <xref rid="bib56" ref-type="bibr">Stone and Ayroles 2009</xref>) or moments estimators (<xref rid="bib24" ref-type="bibr">Hayes and Hill 1981</xref>), and (2) estimating a constrained G-matrix that is low rank and is thus specified with fewer parameters (<italic>e.g.</italic>, <xref rid="bib33" ref-type="bibr">Kirkpatrick and Meyer 2004</xref>). Constraining the G-matrix has computational and analytical advantages: fewer parameters results in more robust estimates and lower computational requirements (<xref rid="bib33" ref-type="bibr">Kirkpatrick and Meyer 2004</xref>). Constrained estimators of G-matrices include methods based on moments estimators (<xref rid="bib26" ref-type="bibr">Hine and Blows 2006</xref>; <xref rid="bib40" ref-type="bibr">McGraw <italic>et al.</italic> 2011</xref>) and mixed-effects models [<italic>e.g.</italic>, the &#x0201c;animal model&#x0201d; and other related models (<xref rid="bib25" ref-type="bibr">Henderson 1984</xref>; <xref rid="bib35" ref-type="bibr">Kruuk 2004</xref>; <xref rid="bib33" ref-type="bibr">Kirkpatrick and Meyer 2004</xref>; <xref rid="bib13" ref-type="bibr">de los Campos and Gianola 2007</xref>)]. Mixed-effects models are particularly powerful for studies in large breeding programs and wild populations. These methods perform well on moderate-dimensional data. However, they are computationally costly and not sufficiently robust to analyze high-dimensional traits.</p><p>Our objective in this article is to develop a model for estimating G-matrices that is scalable to large numbers of traits and is applicable to a variety of experimental designs, including both experimental crosses and pedigreed populations. We build on the Bayesian mixed-effects model of <xref rid="bib13" ref-type="bibr">de los Campos and Gianola (2007)</xref> and model the G-matrix with a factor model. But, we add additional constraints by using a highly informative, biologically motivated, prior distribution on the G-matrix. The key idea that allows us to scale to large numbers of traits is that we believe the vast majority of the space of covariance matrices does not contain matrices that are biologically plausible as a G-matrix. In particular, we expect the G-matrix to be <italic>sparse</italic>, by which we mean that we favor G-matrices that are <italic>modular</italic> and <italic>low rank</italic>. Sparsity in statistics refers to models in which many parameters are expected to be zero (<xref rid="bib38" ref-type="bibr">Lucas <italic>et al.</italic> 2006</xref>). By modular, we mean that small groups of traits will covary together. By low rank, we mean that there will be few (important) modules. We call a G-matrix with these properties <italic>sparse</italic> because there exists a low-rank factorization (most of the possible dimensions are zero) of the matrix with many of its values equal to (or close to) zero. This constrains the class of covariance matrices that we search over, a necessary procedure for inference of covariance matrices from high-dimensional data (<xref rid="bib4" ref-type="bibr">Bickel and Levina 2008a</xref>,<xref rid="bib5" ref-type="bibr">b</xref>; <xref rid="bib8" ref-type="bibr">Carvalho <italic>et al.</italic> 2008</xref>; <xref rid="bib14" ref-type="bibr">El Karoui 2008</xref>; <xref rid="bib46" ref-type="bibr">Meyer and Kirkpatrick 2010</xref>; <xref rid="bib20" ref-type="bibr">Hahn <italic>et al.</italic> 2013</xref>). Under these assumptions, we can also interpret the modules underlying our factorization without imposing additional constraints such as orthogonality (<xref rid="bib15" ref-type="bibr">Engelhardt and Stephens 2010</xref>), something not possible with earlier mixed-effect factor models (<xref rid="bib43" ref-type="bibr">Meyer 2009</xref>).</p><p>The biological argument behind our assumption of a sparse G-matrix is that the traits we measure on an organism arise from developmental processes of limited complexity, and developmental processes tend to be modular (<xref rid="bib9" ref-type="bibr">Cheverud 1996</xref>; <xref rid="bib59" ref-type="bibr">Wagner and Altenberg 1996</xref>; <xref rid="bib10" ref-type="bibr">Davidson and Levine 2008</xref>). For gene expression, regulatory networks control gene expression, and variation in gene expression can often be linked to variation in pathways (<xref rid="bib62" ref-type="bibr">Xiong <italic>et al.</italic> 2012</xref>; <xref rid="bib12" ref-type="bibr">de la Cruz <italic>et al.</italic> 2010</xref>). For a given data set, we make two assumptions about the modules (pathways): (1) a limited number of modules contribute to trait variation and (2) each module affects a limited number of traits. There is support and evidence for these modeling assumptions in the quantitative genetics literature as G-matrices tend to be highly structured (<xref rid="bib60" ref-type="bibr">Walsh and Blows 2009</xref>) and the majority of genetic variation is contained in a few dimensions regardless of the number of traits studied (<xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> 2009</xref>; <xref rid="bib40" ref-type="bibr">Mcgraw <italic>et al.</italic> 2011</xref>). Note that while we focus on developmental mechanisms underlying trait covariation, ecological or physiological processes can also lead to modularity in observed traits and our prior may be applied to these situations as well.</p><p>Based on these assumptions, we present a Bayesian sparse factor model for inferring G-matrices for hundreds or thousands of traits which we call Bayesian sparse factor analysis of genetic covariance matrices or BSFG. We demonstrate the advantages of the model on simulated data and reanalyze gene expression data from a published study on <italic>Drosophila melanogaster</italic> (<xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> 2009</xref>). Although high-dimensional sparse models have been widely used in genetic association studies (<xref rid="bib7" ref-type="bibr">Cantor <italic>et al.</italic> 2010</xref>; <xref rid="bib15" ref-type="bibr">Engelhardt and Stephens 2010</xref>; <xref rid="bib55" ref-type="bibr">Stegle <italic>et al.</italic> 2010</xref>; <xref rid="bib49" ref-type="bibr">Parts <italic>et al.</italic> 2011</xref>; <xref rid="bib63" ref-type="bibr">Zhou and Stephens 2012</xref>) to our knowledge, sparsity has not yet been applied to estimating a G-matrix.</p><sec sec-type="methods" id="s1"><title>Methods</title><p>In this section, we derive the BSFG model, by extending the classic multivariate animal model to the high-dimensional setting, where hundreds or thousands of traits are simultaneously examined. A factor model posits that a set of unobserved (latent) traits called <italic>factors</italic> underly the variation in the observed (measured) traits. For example, variation in gene expression might be the downstream output of variation in the activity of a gene regulatory network. Here, the activity of this gene network is a latent trait, and gene expression is a very high-dimensional set of observed traits. We use the animal model framework to partition variation in the observed traits and the latent factor traits into additive genetic variation and residuals. We encode our two main biological assumptions on the G-matrix as priors on the factors: sparsity in the number of factors that are important, and sparsity in the number of observed traits related to each factor. These priors constrain our estimation to realistic G-matrices and thus prevent sampling errors from swamping out the true signal in high-dimensional data.</p><sec id="s2"><title>Model</title><p>For a single trait the following linear mixed-effects model is commonly used to explain phenotypic variation (<xref rid="bib25" ref-type="bibr">Henderson 1984</xref>),<disp-formula id="eq1"><mml:math id="me1"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math><label>(1)</label></disp-formula>where <bold>y</bold><italic><sub>i</sub></italic> is the vector of observations of the trait on <italic>n</italic> individuals; <bold>b</bold><italic><sub>i</sub></italic> is the vector of coefficients for fixed effects and environmental covariates such as sex or age with design matrix <bold>X</bold>; <inline-formula><mml:math id="me2"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:msub><mml:mtext>G</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the random vector of additive genetic effects with incidence matrix <bold>Z</bold>, and <inline-formula><mml:math id="me3"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:msub><mml:mtext>R</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the residual error caused by nonadditive genetic variation, random environmental effects, and measurement error. The residuals are assumed to be independent of the additive genetic effects. Here, <bold>A</bold> is the known <italic>r</italic> &#x000d7; <italic>r</italic> additive relationship matrix among the individuals; <italic>r</italic> generally equals <italic>n</italic>, but will not if there are unmeasured parents, or if several individuals are clones and share the same genetic background (<italic>e.g.</italic>, see the <italic>Drosophila</italic> gene expression data below).</p><p>In going from one trait to <italic>p</italic> traits we can align the vectors for each trait in (1) to form the following multivariate model,<disp-formula id="eq2"><mml:math id="me4"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Y</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi><mml:mi>B</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi><mml:mi>U</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:math><label>(2)</label></disp-formula>where <bold>Y</bold> = [<bold>y</bold><sub>1</sub> &#x02026; <bold>y</bold><italic><sub>p</sub></italic>], <bold>B</bold> = [<bold>b</bold><sub>1</sub> &#x02026; <bold>b</bold><italic><sub>p</sub></italic>], <bold>U</bold> = [<bold>u</bold><sub>1</sub> &#x02026; <bold>u</bold><italic><sub>p</sub></italic>] and <bold>E</bold> = [<bold>e</bold><sub>1</sub> &#x02026; <bold>e</bold><italic><sub>p</sub></italic>]. <bold>U</bold> and <bold>E</bold> are therefore random variables drawn from matrix normal distributions (<xref rid="bib11" ref-type="bibr">Dawid 1981</xref>),<disp-formula id="eq3"><mml:math id="me5"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mrow><mml:mtext>MN</mml:mtext></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>&#x02003;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mrow><mml:mtext>MN</mml:mtext></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math><label>(3)</label></disp-formula>where the subscripts <italic>r</italic>, <italic>p</italic> and <italic>n</italic>, <italic>p</italic> specify the dimensions of the matrices, <bold>0</bold> is a matrix of zeros, <bold>A</bold> and <bold>I</bold><italic><sub>n</sub></italic> specify the covariances of <italic>each</italic> trait among individuals, and <bold>G</bold> and <bold>R</bold> specify the additive genetic and residual covariances among traits.</p><p>We estimate the covariance matrices <bold>G</bold> and <bold>R</bold>. To do so, we assume that any covariance among the observed traits is caused by a number of latent factors. Specifically, we model <italic>k</italic> latent traits that each linearly relate to one or more of the observed traits. We specify <bold>U</bold> and <bold>E</bold> via the following hierarchical factor model,<disp-formula id="eq4"><mml:math id="me6"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:msup><mml:mi mathvariant="bold">&#x0039b;</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02003;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext></mml:msub><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mtext>MN</mml:mtext><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>&#x02003;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mtext>MN</mml:mtext><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mtext>MN</mml:mtext><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">&#x003a8;</mml:mi><mml:mtext>a</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>&#x02003;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mtext>MN</mml:mtext><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">&#x003a8;</mml:mi><mml:mtext>r</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="bold">&#x0039b;</mml:mi><mml:mo>&#x0223c;</mml:mo><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><label>(4)</label></disp-formula>where <bold>&#x0039b;</bold> is a <italic>p</italic> &#x000d7; <italic>k</italic> matrix called the &#x0201c;factor loadings&#x0201d; matrix. Each column specifies the relationship between one latent trait and all observed traits. Just as <bold>U</bold> and <bold>E</bold> partition the among-individual variation in the <italic>observed</italic> traits into additive genetic effects and residuals in (2), the matrices <bold>F</bold><sub>a</sub> and <bold>F</bold><sub>r</sub> partition the among-individual variation in the <italic>latent</italic> traits into additive genetic effects and residuals. <bold>&#x003a3;</bold><sub>a</sub> and <bold>&#x003a3;</bold><sub>r</sub> model the among-factor (within-individual) covariances of <bold>F</bold><sub>a</sub> and <bold>F</bold><sub>r</sub>, which we assume to be diagonal <inline-formula><mml:math id="me7"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mtext>Diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mtext>Diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. <bold>&#x003a8;</bold><sub>a</sub> and <bold>&#x003a8;</bold><sub>r</sub> are the idiosyncratic (trait-specific) variances of the factor model and are assumed to be diagonal.</p><p>In model (4), as in any factor model (<italic>e.g.</italic>, <xref rid="bib61" ref-type="bibr">West 2003</xref>), <bold>&#x0039b;</bold> is not identifiable without adding extra constraints. In general, the factors in <bold>&#x0039b;</bold> can be rotated arbitrarily. This is not an issue for estimating <bold>G</bold> itself, but prevents biological interpretations of <bold>&#x0039b;</bold> and makes assessing MCMC convergence difficult. To solve this problem, we introduce constraints on the orientation of <bold>&#x0039b;</bold> through our prior distribution <italic>&#x003c0;</italic>(<italic>&#x003b8;</italic>) specified below. However, even after fixing a rotation, the relative scaling of corresponding columns of <bold>F</bold><sub>a</sub>, <bold>F</bold><sub>r,</sub> and <bold>&#x0039b;</bold> are still not well defined. For example, if the <italic>j</italic>th column of <bold>F</bold><sub>a</sub> and <bold>F</bold><sub>r</sub> are both multiplied by a constant <italic>c</italic>, the same model is recovered if the <italic>j</italic>th column of <bold>&#x0039b;</bold> is multiplied by 1/<italic>c</italic>. To fix <italic>c</italic>, we require the column variances (<inline-formula><mml:math id="me8"><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="me9"><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>) to sum to one, <italic>i.e.</italic>, <bold>&#x003a3;</bold><sub>a</sub>+<bold>&#x003a3;</bold><sub>r</sub> = <bold>I</bold><italic><sub>k</sub></italic>. Therefore, the single matrix <inline-formula><mml:math id="me10"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>k</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> is sufficient to specify both variances. The diagonal elements of this matrix specify the narrow-sense heritability <inline-formula><mml:math id="me11"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of latent trait <italic>j</italic>.</p><p>Given the properties of the matrix normal distribution (<xref rid="bib11" ref-type="bibr">Dawid 1981</xref>) and models (3) and (4) we can recover <bold>G</bold> and <bold>R</bold> as<disp-formula id="eq5"><mml:math id="me12"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msub><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a8;</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>k</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a8;</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><label>(5)</label></disp-formula>Therefore, our model for the total phenotypic covariance <bold>P</bold> = <bold>G</bold> + <bold>R</bold> is<disp-formula id="eq6"><mml:math id="me13"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>P</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a8;</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a8;</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math><label>(6)</label></disp-formula>Our specification of the BSFG model in (4) differs from earlier methods such as the Bayesian genetic factor model of <xref rid="bib13" ref-type="bibr">de los Campos and Gianola (2007)</xref> in two key respects. First, in classic factor models, the total number of latent traits is assumed to be small (<italic>k</italic> &#x0226a; <italic>p</italic>). Therefore, Equation 5 would model <bold>G</bold> with only <italic>pk</italic> + <italic>k</italic> + <italic>p</italic> parameters instead of <italic>p</italic>(<italic>p</italic> + 1)/2. However, choosing <italic>k</italic> is a very difficult, unsolved problem, and inappropriate choices can result in biased and unstable estimates of <bold>G</bold> and <bold>R</bold> (<italic>e.g.</italic>, <xref rid="bib45" ref-type="bibr">Meyer and Kirkpatrick 2008</xref>). In our model we allow many latent traits but assume that the majority of them are relatively unimportant. This subtle difference is important because it removes the need to accurately choose <italic>k</italic>, instead emphasizing the estimation of the <italic>magnitude</italic> of each latent trait. This model is based on the work by <xref rid="bib3" ref-type="bibr">Bhattacharya and Dunson (2011)</xref>, which they term an &#x0201c;infinite&#x0201d; factor model. In our prior distribution on the factor loadings matrix <bold>&#x0039b;</bold> (see section <italic>Priors</italic>), we order the latent traits (columns of <bold>&#x0039b;</bold>) in terms of decreasing influence on the total phenotypic variation and assume that the variation explained by these latent traits decreases rapidly. Therefore, rather than attempt to identify the correct <italic>k</italic> we model the decline in the influence of successive latent traits. As in other factor models, to save computational effort we can truncate <bold>&#x0039b;</bold> to include only its first <italic>k</italic>* &#x0003c; <italic>k</italic> columns because we require the variance explained by each later column to approach zero. The truncation point <italic>k</italic>* can be estimated jointly while fitting the model and is flexible (we suggest truncating any columns of <bold>&#x0039b;</bold> defining modules that explain &#x0003c;1% of the phenotypic variation in any observed trait). Note that <italic>k</italic>* conveys little biological information and does not have the same interpretation as <italic>k</italic> in classic factor models. Since additional factors are expected to explain negligible phenotypic variation, including a few extra columns to <inline-formula><mml:math id="me14"><mml:mrow><mml:msub><mml:mi mathvariant="bold">&#x0039b;</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> to check for more factors is permissible (<italic>e.g.</italic>, <xref rid="bib45" ref-type="bibr">Meyer and Kirkpatrick 2008</xref>).</p><p>Second, we assume that the residual covariance <bold>R</bold> has a factor structure and that the same latent traits underly both <bold>G</bold> and <bold>R</bold>. Assuming a constrained space for <bold>R</bold> is uncommon in multivariate genetic estimation. For example, <xref rid="bib13" ref-type="bibr">de los Campos and Gianola (2007)</xref> fit an unconstrained <bold>R</bold>, although they used an informative inverse Wishart prior (<xref rid="bib17" ref-type="bibr">Gelman 2006</xref>) and only consider five traits. The risk of assuming a constrained <bold>R</bold> is that poorly modeled phenotypic covariance (<bold>P</bold> = <bold>G</bold> + <bold>R</bold>) can lead to biased estimates of genetic covariance in some circumstances (<xref rid="bib30" ref-type="bibr">Jaffrezic <italic>et al.</italic> 2002</xref>; <xref rid="bib45" ref-type="bibr">Meyer and Kirkpatrick 2008</xref>).</p><p>However, constraining <bold>R</bold> is necessary in high-dimensional settings to prevent the number of modeling parameters from increasing exponentially, and we argue that modeling <bold>R</bold> as we have done is biologically justified. Factor models fitting low numbers of latent factors are used in many fields because they accurately model phenotypic covariances. Reasonable constraints on <bold>R</bold> have been applied successfully in previous genetic models. One example is in the direct estimation of genetic principle components model of <xref rid="bib33" ref-type="bibr">Kirkpatrick and Meyer (2004)</xref>. These authors model only the first <italic>m</italic><sub>E</sub> eigenvectors of the residual covariance matrix. Our model for <bold>R</bold> is closely related to models used in random regression analysis of function-valued traits (<italic>e.g.</italic>, <xref rid="bib32" ref-type="bibr">Kirkpatrick and Heckman 1989</xref>; <xref rid="bib50" ref-type="bibr">Pletcher and Geyer 1999</xref>; <xref rid="bib30" ref-type="bibr">Jaffrezic <italic>et al.</italic> 2002</xref>; <xref rid="bib42" ref-type="bibr">Meyer 2005</xref>). In those models, <bold>R</bold> is modeled as a permanent environmental effect function plus independent error. The permanent environmental effect function is given a functional form similar to (or more complex than) the genetic function. In Equation 4, <bold>F</bold><sub>r</sub> is analogous to this permanent environmental effect (but across different traits rather than the same trait observed through time), with its functional form described by <bold>&#x0039b;</bold>, and <bold>E</bold><sub>r</sub> is independent error. Since both <bold>F</bold><sub>a</sub> and <bold>F</bold><sub>r</sub> relate to the observed phenotypes through <bold>&#x0039b;</bold>, the functional form of the model for the residuals (<bold>e</bold><italic><sub>i</sub></italic>) is at least as complex as the genetic functional form (and more complex whenever <inline-formula><mml:math id="me15"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for some factors).</p><p>The biological justification of our approach is that the factors represent latent traits, and just like any other trait their value can partially be determined by genetic variation. For example, the activity of developmental pathways is determined by the internal and external environment but can also have a genetic basis. The latent traits determine the phenotypic covariance of the observed traits, and their heritability determines the genetic covariance. In genetic experiments, some of these latent traits (<italic>e.g.</italic>, measurement biases) might be variable, but not have a genetic component. We expect that some factors will contribute to <bold>R</bold> but not <bold>G</bold>, so <bold>R</bold> will be modeled with more factors than <bold>G</bold> (<xref rid="bib45" ref-type="bibr">Meyer and Kirkpatrick 2008</xref>).</p><p>We examine the impact of our prior on <bold>R</bold> through simulations below, including cases when the true <bold>R</bold> is not low rank. When our assumptions regarding <bold>R</bold> do not hold, the prior may lead to biased estimates. For example, measurement biases might be low dimensional but not sparse, and some studies have estimated the phenotypic covariance <bold>P</bold> to be full rank (<italic>e.g.</italic>, <xref rid="bib41" ref-type="bibr">McGuigan and Blows 2007</xref>). However, we expect that for many general high-dimensional biological data sets this model will be useful and can provide novel insights. In particular, by directly modeling the heritability of the latent traits, we can predict their evolution.</p></sec><sec id="s3"><title>Priors</title><p>Modeling high-dimensional data requires some prior specification or penalty/regularization for accurate and stable parameter estimation (<xref rid="bib23" ref-type="bibr">Hastie <italic>et al.</italic> 2003</xref>; <xref rid="bib61" ref-type="bibr">West 2003</xref>; <xref rid="bib51" ref-type="bibr">Poggio and Smale 2003</xref>). For our model this means that constraints on <bold>G</bold> and <bold>R</bold> are required. We impose constraints through a highly informative prior on <bold>&#x0039b;</bold>. Our prior is motivated by the biological assumption that variation in underlying developmental processes such as gene networks or metabolic pathways gives rise to genetic and residual covariances. This implies:<list list-type="order" id="L1"><list-item><p>The biological system has limited complexity: a small number of latent traits are relevant for trait variation. This means that the number of important factors is low (<italic>k</italic>* &#x0226a; <italic>p</italic>).</p></list-item><list-item><p>Each underlying latent trait affects a limited number of the observed traits. This means the factor loadings (columns of <bold>&#x0039b;</bold>) are sparse (mostly near zero).</p></list-item></list>We formalize the above assumptions by a prior on <bold>&#x0039b;</bold> that imposes sparsity (formally, shrinkage toward zero) and low effective rank (<xref rid="bib3" ref-type="bibr">Bhattacharya and Dunson 2011</xref>). This prior is specified as a hierarchical distribution on each element <italic>&#x003bb;<sub>ij</sub></italic> of <bold>&#x0039b;</bold>:<disp-formula id="eq7"><mml:math id="me16"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>&#x003c4;</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>&#x02003;</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02026;</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mo>&#x02003;</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02026;</mml:mo><mml:mi>k</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:mtext>Ga</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>&#x003bd;</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#x003bd;</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>&#x003b4;</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>&#x02003;</mml:mo><mml:msub><mml:mi>&#x003b4;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:mtext>Ga</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>&#x02003;</mml:mo><mml:msub><mml:mi>&#x003b4;</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:mtext>Ga</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>for</mml:mtext><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x02026;</mml:mo><mml:mi>k</mml:mi><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><label>(7)</label></disp-formula>The hierarchical prior is composed of three levels:<list list-type="alpha-lower" id="L2"><list-item><p>We model each <italic>&#x003bb;<sub>ij</sub></italic> (specifying how observed trait <italic>i</italic> is related to latent trait <italic>j</italic>) with a normal distribution.</p></list-item><list-item><p>Based on assumption 2, we expect most <italic>&#x003bb;<sub>ij</sub></italic> &#x02248; 0. A normal distribution with a fixed variance parameter is not sufficient to impose this constraint. We model the the precision (inverse of the variance) of each loading element <italic>&#x003bb;<sub>ij</sub></italic> with the parameter <italic>&#x003c6;<sub>ij</sub></italic> drawn from a gamma distribution. This normal&#x02013;gamma mixture distribution (conditional on <italic>&#x003c4;<sub>j</sub></italic>) is commonly used to impose sparsity (<xref rid="bib48" ref-type="bibr">Neal 1996</xref>; <xref rid="bib57" ref-type="bibr">Tipping 2001</xref>) as the marginal distribution on <italic>&#x003bb;<sub>ij</sub></italic> takes the form of Student&#x02019;s <italic>t</italic>-distribution with <italic>v</italic> degrees of freedom and is heavy tailed. This forces the <italic>&#x003bb;<sub>ij</sub></italic>&#x02019;s to be concentrated near zero, but permits occasional large magnitude values. This prior specification is conceptually similar to the widely used Bayesian Lasso (<xref rid="bib64" ref-type="bibr">Park and Casella 2008</xref>).</p></list-item><list-item><p>The parameter <italic>&#x003c4;<sub>j</sub></italic> controls the overall variance explained by factor <italic>j</italic> by shrinking the variance toward zero as <italic>m</italic> &#x02192; &#x0221e;. The decay in the variance is enforced by increasing the precision of <italic>&#x003bb;<sub>ij</sub></italic> as <italic>j</italic> increases so that |<italic>&#x003bb;<sub>ij</sub></italic>| &#x02192; 0. The sequence {<italic>&#x003c4;<sub>j</sub></italic>, <italic>j</italic> = 1 &#x02026; <italic>k</italic>} is formed from the cumulative product of the sequence {<italic>&#x003b4;<sub>j</sub></italic>, <italic>j</italic> = 1 &#x02026; <italic>k</italic>}, where each element is modeled with a gamma distribution, and will be stochastically increasing as long as <italic>a</italic><sub>2</sub> &#x0003e; <italic>b</italic><sub>2</sub>. This means that the variance of <italic>&#x003bb;<sub>ij</sub></italic> will stochastically decrease and higher-indexed columns of <bold>&#x0039b;</bold> will be less likely to have any large magnitude elements. This decay ensures that it will be safe to truncate <bold>&#x0039b;</bold> at some sufficiently large <italic>k</italic>* because columns <italic>k</italic> &#x0003e; <italic>k</italic>* will (necessarily) explain less variance.</p></list-item></list></p><p>The prior distribution on <italic>&#x003c4;<sub>j</sub></italic> (and therefore the sequence {<italic>&#x003b4;</italic><sub>1</sub>, &#x02026;, <italic>&#x003b4;<sub>j</sub></italic>}) is a key modeling decision as <italic>&#x003c4;<sub>j</sub></italic> controls how much of the total phenotypic variance we expect each successive factor to explain. Based on assumption 1, we expect that few factors will be sufficient to explain total phenotypic variation, and thus {<italic>&#x003c4;<sub>j</sub></italic>} will increase rapidly. However, relatively flat priors on <italic>&#x003b4;<sub>m</sub></italic>, <italic>m</italic> = 2 &#x02026; <italic>k</italic> (<italic>e.g.</italic>, <italic>a</italic><sub>2</sub> = 3, <italic>b</italic><sub>2</sub> = 1), which allow some consecutive factors to be of nearly equal magnitude, appear to work well in simulations.</p><p>The prior on the heritability of each of latent factor trait is a discrete set of values in the unit interval. This specification was selected for computational efficiency and to give <inline-formula><mml:math id="me17"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> positive weight in the prior. We find the following discrete distribution works well,<disp-formula id="eq8"><mml:math id="me18"><mml:mrow><mml:msub><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02003;</mml:mo><mml:msub><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mtext>for</mml:mtext><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02026;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>, <label>(8)</label></disp-formula>where <italic>n<sub>h</sub></italic> is the number of points to evaluate <inline-formula><mml:math id="me19"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. In analyses reported here, we set <italic>n<sub>h</sub></italic> = 100. This prior gives equal weight to <inline-formula><mml:math id="me20"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="me21"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> because we expect several factors (in particular, those reflecting measurement error) to have no genetic variance. In principle, we could place a continuous prior on the interval [0, 1], but no such prior would be conjugate, and developing a MCMC sampler would be more difficult.</p><p>We place inverse gamma priors with parameters <italic>a</italic><sub>a</sub>, <italic>b</italic><sub>a</sub> and <italic>a</italic><sub>r</sub>, <italic>b</italic><sub>r</sub> on each diagonal element of <bold>&#x003a8;</bold><sub>a</sub> and <bold>&#x003a8;</bold><sub>r</sub>, respectively. Priors on each element of <bold>B</bold> are normal distributions with very large (&#x0003e;10<sup>6</sup>) variances.</p></sec><sec id="s4"><title>Implementation</title><p>Inference in the BSFG model uses an adaptive Gibbs sampler for which we provide detailed steps in the appendix. The code has been implemented in Matlab and can be found at the website (<ext-link ext-link-type="uri" xlink:href="http://www.stat.duke.edu/&#x0223c;sayan/bfgr/index.shtml">http://www.stat.duke.edu/&#x0223c;sayan/bfgr/index.shtml</ext-link>) together with code to replicate the simulations and gene expression analyses reported here.</p></sec><sec id="s5"><title>Simulations</title><p>We present a simulation study of high-dimensional traits observed in the offspring of a balanced paternal half-sib breeding design. We examined 10 scenarios (<xref ref-type="table" rid="t1">Table 1</xref>), each corresponding to different parameters for the matrices <bold>G</bold> and <bold>R</bold> to evaluate the impact of the modeling assumptions specified by our prior. For each scenario we simulated trait values of individuals from Equation (2) with <bold>Z</bold> = <bold>I</bold><italic><sub>n</sub></italic>, <bold>B</bold> = <bold>0</bold><italic><sub>p</sub></italic>, and <bold>X</bold> a single column of ones representing the trait means.</p><table-wrap id="t1" position="float"><label>Table 1</label><caption><title>Simulation parameters</title></caption><table frame="above" rules="groups"><col width="15.71%" span="1"/><col width="9.54%" span="1"/><col width="8.21%" span="1"/><col width="8.21%" span="1"/><col width="7.69%" span="1"/><col width="9.62%" span="1"/><col width="7.83%" span="1"/><col width="10.72%" span="1"/><col width="12.58%" span="1"/><col width="4.94%" span="1"/><col width="4.95%" span="1"/><thead><tr><th valign="top" align="left" scope="col" rowspan="1" colspan="1"/><td valign="top" align="center" scope="col" colspan="3" rowspan="1">No. factors<hr/></td><th valign="top" align="center" scope="col" colspan="2" rowspan="1"><bold>R</bold> type<hr/></th><th valign="top" align="center" scope="col" colspan="2" rowspan="1">No. traits<hr/></th><th valign="top" align="center" scope="col" colspan="3" rowspan="1">Sample size<hr/></th></tr><tr><th valign="top" align="left" scope="col" rowspan="1" colspan="1"/><th valign="top" align="center" scope="col" rowspan="1" colspan="1">a</th><th valign="top" align="center" scope="col" rowspan="1" colspan="1">b</th><th valign="top" align="center" scope="col" rowspan="1" colspan="1">c</th><th valign="top" align="center" scope="col" rowspan="1" colspan="1">d</th><th valign="top" align="center" scope="col" rowspan="1" colspan="1">e</th><th valign="top" align="center" scope="col" rowspan="1" colspan="1">f</th><th valign="top" align="center" scope="col" rowspan="1" colspan="1">g</th><th valign="top" align="center" scope="col" rowspan="1" colspan="1">h</th><th valign="top" align="center" scope="col" rowspan="1" colspan="1">i</th><th valign="top" align="center" scope="col" rowspan="1" colspan="1">j</th></tr></thead><tbody><tr><td valign="top" align="left" scope="col" rowspan="1" colspan="1"><bold>G</bold> and <bold>R</bold></td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">&#x02003;No. traits</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">20</td><td valign="top" align="char" char="." rowspan="1" colspan="1">1000</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">&#x02003;Residual type</td><td valign="top" align="center" rowspan="1" colspan="1">SF<xref ref-type="table-fn" rid="t1n1"><italic><sup>a</sup></italic></xref></td><td valign="top" align="center" rowspan="1" colspan="1">SF</td><td valign="top" align="center" rowspan="1" colspan="1">SF</td><td valign="top" align="center" rowspan="1" colspan="1">F<xref ref-type="table-fn" rid="t1n2"><italic><sup>b</sup></italic></xref></td><td valign="top" align="center" rowspan="1" colspan="1">Wishart<xref ref-type="table-fn" rid="t1n3"><italic><sup>c</sup></italic></xref></td><td valign="top" align="center" rowspan="1" colspan="1">SF</td><td valign="top" align="center" rowspan="1" colspan="1">SF</td><td valign="top" align="center" rowspan="1" colspan="1">SF</td><td valign="top" align="center" rowspan="1" colspan="1">SF</td><td valign="top" align="char" char="." rowspan="1" colspan="1">SF</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">&#x02003;No. factors</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">25</td><td valign="top" align="char" char="." rowspan="1" colspan="1">50</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">5</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"><italic>&#x02003;h</italic><sup>2</sup> of factors<xref ref-type="table-fn" rid="t1n4"><italic><sup>d</sup></italic></xref></td><td valign="top" align="center" rowspan="1" colspan="1">0.5 (5)</td><td valign="top" align="center" rowspan="1" colspan="1">0.5 (15)</td><td valign="top" align="center" rowspan="1" colspan="1">0.5 (30)</td><td valign="top" align="center" rowspan="1" colspan="1">0.5 (5)</td><td valign="top" align="center" rowspan="1" colspan="1">1.0 (5)</td><td colspan="2" valign="top" align="center" rowspan="1">0.5 (5)</td><td colspan="3" valign="top" align="center" rowspan="1">0.9&#x02013;0.1 (5)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">0.0 (5)</td><td valign="top" align="center" rowspan="1" colspan="1">0.0 (10)</td><td valign="top" align="center" rowspan="1" colspan="1">0.0 (20)</td><td valign="top" align="center" rowspan="1" colspan="1">0.0 (5)</td><td valign="top" align="left" rowspan="1" colspan="1"/><td colspan="2" valign="top" align="center" rowspan="1">0.0 (5)</td><td colspan="3" valign="top" align="center" rowspan="1">0.0 (5)</td></tr><tr><td valign="top" align="left" scope="col" rowspan="1" colspan="1">Sample size</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">&#x02003;No. sires</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">50</td><td valign="top" align="char" char="." rowspan="1" colspan="1">100</td><td valign="top" align="char" char="." rowspan="1" colspan="1">500</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">&#x02003;No. offspring/sire</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">5</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td></tr></tbody></table><table-wrap-foot><fn><p>Eight simulations were designed to demonstrate the capabilities of BSFG. Scenarios a&#x02013;c test genetic and residual covariance matrices composed of different numbers of factors. Scenarios d&#x02013;e test residual covariance matrices that are not sparse. Scenarios f&#x02013;g test different numbers of traits. Scenarios h&#x02013;j test different sample sizes. All simulations followed a paternal half-sib breeding design. Each simulation was run 10 times.</p></fn><fn id="t1n1"><label>a</label><p>Sparse factor model for <bold>R</bold>. Each simulated factor loading (<italic>&#x003bb;<sub>ij</sub></italic>) had a 75&#x02013;97% chance of equaling zero.</p></fn><fn id="t1n2"><label>b</label><p>Factor model for <bold>R</bold>. Residual factors (those with <inline-formula><mml:math id="me22"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) were not sparse (<italic>&#x003bb;<sub>ij</sub></italic> &#x02260; 0).</p></fn><fn id="t1n3"><label>c</label><p><bold>R</bold> was simulated from a Wishart distribution with <italic>p</italic> + 1 degrees of freedom and inverse scale matrix <inline-formula><mml:math id="me23"><mml:mrow><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>p</mml:mi></mml:mfrac></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Five additional factors were each assigned a heritability of 1.0.</p></fn><fn id="t1n4"><label>d</label><p>In each column, factors are divided between those <italic>h</italic><sup>2</sup> &#x0003e; 0 and those with <italic>h</italic><sup>2</sup> = 0. The number in parentheses provides the number of factors with the given heritability.</p></fn></table-wrap-foot></table-wrap><p>Scenarios a&#x02013;c tested the accuracy of the model given increasing numbers of latent traits. <bold>G</bold> and <bold>P</bold> were simulated based on 10, 25, or 50 important factors, respectively, for 100 traits. Heritabilities <inline-formula><mml:math id="me24"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of latent factors <italic>j</italic> = 1 &#x02026; 5, 1 &#x02026; 15, or 1 &#x02026; 30, respectively, were set to 0.5 and contributed to both <bold>G</bold> and <bold>R</bold>. Heritabilities of the remaining factors (<italic>j</italic> = 6 &#x02026; 10, 16 &#x02026; 25, or 31 &#x02026; 50, respectively) were set to 0.0 and contributed only to <bold>R</bold>. For each latent factor, loadings <italic>&#x003bb;<sub>ij</sub></italic> were drawn from independent standard normal distributions. To make the covariance matrices biologically reasonable, we forced each factor to be sparse: 75&#x02013;97% of the <italic>&#x003bb;<sub>ij</sub></italic> were set to zero. The idiosyncratic variances <bold>&#x003a8;</bold><sub>a</sub> and <bold>&#x003a8;</bold><sub>e</sub> were set to 0.2 &#x000d7; <bold>I</bold><italic><sub>p</sub></italic>. Therefore, trait-specific heritabilties ranged from 0.0 to 0.5, with the majority toward the upper limit. Each simulation included 10 offspring from 100 unrelated sires.</p><p>Scenarios d&#x02013;e tested the accuracy of the model when the true <bold>R</bold> was neither sparse nor low rank, since inappropriately modeled residual variances can lead to biased estimates of <bold>G</bold> (<italic>e.g.</italic>, <xref rid="bib30" ref-type="bibr">Jaffrezic <italic>et al.</italic> 2002</xref>; <xref rid="bib44" ref-type="bibr">Meyer and Kirkpatrick 2007</xref>). Scenarios were identical to a except the <bold>R</bold> matrix did not have a sparse factor form. In scenario d, <bold>R</bold> was constructed with a factor structure with 10 factors, but 5 of these factors (<italic>j</italic> = 6 &#x02026; 10, <italic>i.e.</italic>, those with <inline-formula><mml:math id="me25"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.0</mml:mn></mml:mrow></mml:math></inline-formula>) were not sparse (<italic>i.e.</italic>, all factor loadings were nonzero). This might occur, for example, if the nongenetic factors were caused by measurement error. In scenario e, <bold>R</bold> was drawn from a central Wishart distribution with <italic>p</italic> + 1 degrees of freedom and therefore was full rank and did not follow a factor structure at all.</p><p>Scenarios f&#x02013;g tested the accuracy of the model given increasing numbers of observed traits. Both scenarios were identical to scenario a except scenario f had 20 observed traits and scenario g had 1000.</p><p>Scenarios h&#x02013;j tested the accuracy of the model given experiments of different size and given different latent trait heritabilities. Simulations were identical to scenario a except that the five genetic factors in each simulation were assigned <inline-formula><mml:math id="me26"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn><mml:mo>,</mml:mo><mml:mn>0.7</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula>, and 0.1 for <italic>j</italic> = 2, 4, 6, 8, 10, the number of sires was set to 50, 100, or 500, and the number of offspring per sire was set to 5 (for simulation <italic>h</italic> only).</p><p>To fit the simulated data, we set the hyperparameters in the prior to: <italic>&#x003bd;</italic> = 3, <italic>a</italic><sub>1</sub> = 2, <italic>b</italic><sub>1</sub> = 1/20, <italic>a</italic><sub>2</sub> = 3, <italic>b</italic><sub>2</sub> = 1. We ran our Gibbs sampler for 12,000 iterations, discarded the first 10,000 samples as burn-in, and collected 1000 posterior samples with a thinning rate of two.</p><p>We calculated a number of statistics from each simulation to quantify the estimation error of the BSFG model. For each statistic, we compared the posterior mean of a model parameter to the true value specified in the simulation.</p><p>First, as a sanity check, we compared the accuracy of our method to a methods of moments estimate of <bold>G</bold> calculated as <bold>G</bold><sub>m</sub> = 4(<bold>B</bold> &#x02212; <bold>W</bold>)/<italic>n</italic>, where <bold>B</bold> and <bold>W</bold> are the between- and within-sire matrices of mean squares and cross products and <italic>n</italic> is the number of offspring per sire. We compared the accuracy of the moments estimator <bold>G</bold><sub>m</sub> to the posterior mean <inline-formula><mml:math id="me27"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi mathvariant="bold">G</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle></mml:math></inline-formula> from our model by calculating the Frobenius norm of the errors: |<bold>G</bold><sub>m</sub> &#x02212; <bold>G</bold>|<sub>F</sub> and <inline-formula><mml:math id="me28"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi mathvariant="bold">G</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mtext>F</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>The Frobenius norm measure above quantifies the total sum of square error in each pairwise covariance estimate. However, the geometry of <bold>G</bold> is more important for predicting evolution (<xref rid="bib60" ref-type="bibr">Walsh and Blows 2009</xref>). We evaluated the accuracy of each estimated <bold>G</bold> matrix by comparing the <italic>k</italic>-dimensional subspace of &#x0211d;<italic><sup>p</sup></italic> with the majority of the variation in <bold>G</bold> to the corresponding subspace for the posterior mean estimate <inline-formula><mml:math id="me29"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi mathvariant="bold">G</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle></mml:math></inline-formula>. We used the Krzanowski subspace comparison statistic (<xref rid="bib36" ref-type="bibr">Krzanowski 1979</xref>; <xref rid="bib6" ref-type="bibr">Blows <italic>et al.</italic> 2004</xref>), which is the sum of the eigenvalues of the matrix <inline-formula><mml:math id="me30"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mtext>T</mml:mtext></mml:msup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle></mml:msub><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover accent="true"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="me31"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is the subspace spanned by the eigenvectors with the <italic>k</italic> largest eigenvalues of the posterior mean of <bold>G</bold>, and <bold>G<sub>k</sub></bold> is the corresponding subspace of the true (simulated) matrix. This statistic will be zero for orthogonal (nonoverlapping) subspaces and will equal <italic>k</italic> for identical subspaces. The accuracy of the estimated <bold>P</bold> was calculated similarly. For each comparison, <italic>k</italic> was chosen as the number of factors used in the construction of the simulated matrix (<xref ref-type="table" rid="t1">Table 1</xref>), except in scenario e with the Wishart-distributed <bold>R</bold> matrix. Here, we set the <italic>k</italic> for <bold>P</bold> at 19, which was sufficient to capture &#x0003e;99% of the variation in most simulated <bold>P</bold> matrices.</p><p>We evaluated the accuracy of latent factor estimates in two ways. First, we calculated the magnitude of each factor as |<bold><italic>&#x003bb;</italic></bold><italic><sub>j</sub></italic>|<sup>2</sup> where |&#x022c5;| is the <italic>L</italic><sub>2</sub>-norm. This quantifies the phenotypic variance across all traits explained by each factor. We then counted the number of factors that explained &#x0003e;0.1% of total phenotypic variance. Such factors were termed &#x0201c;large factors.&#x0201d; Second, for each simulated factor <italic>j</italic>, we calculated the error in estimated factor identity by finding the estimated factor <italic>j</italic>* with trait loadings vector <inline-formula><mml:math id="me32"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">&#x003bb;</mml:mi><mml:mrow><mml:msup><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> that had the smallest vector angle with the true factor trait loadings vector <bold><italic>&#x003bb;</italic></bold><italic><sub>j</sub></italic>. Smaller angles correspond to more accurately identified factors. For scenarios d and e, error angles could be calculated only for the genetically variable factors (factors 1&#x02013;5) because the residual factors for these scenarios were not well defined. In scenario d, factors 6&#x02013;10 were not sparse and thus were identifiable only up to an arbitrary rotation by any matrix <bold>H</bold> such that <bold>HH</bold><sup>T</sup> = <bold>I</bold> (<xref rid="bib43" ref-type="bibr">Meyer 2009</xref>). In scenario e, the residual matrix did not have a factor form.</p></sec><sec id="s6"><title>Gene expression analysis</title><p>We downloaded gene expression profiles and measures of competitive fitness of 40 wild-derived lines of <italic>Drosophila melanogaster</italic> from ArrayExpress (accession E-MEXP-1594) and the Drosophila Genetic Reference Panel (DGRP) website (<ext-link ext-link-type="uri" xlink:href="http://dgrp.gnets.ncsu.edu/">http://dgrp.gnets.ncsu.edu/</ext-link>) (<xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> 2009</xref>). A line&#x02019;s competitive fitness (<xref rid="bib34" ref-type="bibr">Knight and Robertson 1957</xref>; <xref rid="bib22" ref-type="bibr">Hartl and Jungen 1979</xref>) measures the percentage of offspring bearing the assay line&#x02019;s genotype recovered from vials seeded with a known proportion of adults from a reference line. We used the BSFG model to infer a set of latent factor traits underlying the among-line gene expression covariance matrix for a subset of the genes and the among-line covariance between each gene and competitive fitness. These latent factors are useful because they provide insight into what genes and developmental or molecular pathways underlie variation in competitive fitness.</p><p>We first normalized the processed gene expression data to correspond to the analyses of <xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> (2009)</xref> and then selected the 414 genes identified in that article as having a plausible among-line covariance with competitive fitness. In this data set, two biological replicates of male and female fly collections from each line were analyzed for whole-animal RNA expression. The competitive fitness measurements were the means of 20 competitive trials performed with sets of flies from these same lines, but not the same flies used in the gene expression analysis. Gene expression values for the samples measured for competitive fitness and competitive fitness values for the samples measured for gene expression were treated as missing data (see <italic>Appendix</italic>). We used our model to estimate the covariance of line effects. Following the analyses of <xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> (2009)</xref>, we included a fixed effect of sex and independent random effects of the sex:line interaction for each gene. No sex or sex:line effects were fit for competitive fitness itself as this value was measured at the level of the line, not on individual flies.</p><p>We set the prior hyperparameters as above and ran our Gibbs sampler for 40,000 iterations, discarded the first 20,000 samples as a burn-in period, and collected 1000 posterior samples of all parameters with a thinning rate of 20.</p></sec></sec><sec sec-type="results" id="s7"><title>Results</title><sec id="s8"><title>Simulation example</title><p>The BSFG model&#x02019;s estimates of genetic covariances were considerably more accurate than estimates based on unbiased methods of moments estimators. In scenario a, for example, the mean Frobenius norm was 13.9 for the moments estimator and 6.3 for the Bayesian genetic sparse factor model&#x02019;s posterior mean, a 54% improvement.</p><p>The BSFG model accurately estimated subspaces containing the majority of variation in both <bold>G</bold> and <bold>P</bold>. <xref ref-type="fig" rid="fig1">Figure 1</xref> shows the distribution of Krzanowski&#x02019;s subspace similarity statistics <inline-formula><mml:math id="me33"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:msub><mml:mtext>s</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for <bold>G</bold> in each scenario (subspace statistics for <bold>P</bold> are shown in supporting information, <ext-link ext-link-type="uri" xlink:href="http://www.genetics.org/lookup/suppl/doi:10.1534/genetics.113.151217/-/DC1/genetics.113.151217-3.pdf">Figure S1</ext-link>). Krzanowski&#x02019;s statistic corresponds approximately to the number of eigenvectors of the true subspace recovered in the estimated subspace and in our simulations rarely differed even one unit from the true value of <italic>k</italic> for either <bold>G</bold> and <bold>P</bold>. The exceptions for <bold>G</bold> were mostly in scenarios h&#x02013;j, where the fifth genetic factor (factor 10) was assigned a heritability of 0.1 and the subspace spanned by the first five eigenvectors of estimated <bold>G</bold> matrices often did not include this vector. This effect was exacerbated at low sample sizes. The Krzanowski error for <bold>G</bold> (relative to <italic>k</italic>) also increased slightly for larger numbers of factors (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), if <bold>R</bold> was full rank (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), if few traits were observed (<xref ref-type="fig" rid="fig1">Figure 1C</xref>), or if the sample size was small (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Some simulations with nonsparse latent factors of <bold>R</bold> also caused slight subspace errors (scenario d, <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Krzanowski&#x02019;s statistics for <bold>P</bold> followed a similar pattern to those for <bold>G</bold> (<ext-link ext-link-type="uri" xlink:href="http://www.genetics.org/lookup/suppl/doi:10.1534/genetics.113.151217/-/DC1/genetics.113.151217-3.pdf">Figure S1</ext-link>), except that the errors for full-rank <bold>R</bold> or for different numbers of traits were more pronounced (<ext-link ext-link-type="uri" xlink:href="http://www.genetics.org/lookup/suppl/doi:10.1534/genetics.113.151217/-/DC1/genetics.113.151217-3.pdf">Figure S1</ext-link>B).</p><fig id="fig1" fig-type="figure" position="float"><label>Figure 1</label><caption><p>BSFG recovers the dominant subspace of high-dimensional G-matrices. Each subplot shows the distribution of Krzanowski&#x02019;s statistics (<inline-formula><mml:math id="me34"><mml:mrow><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:msub><mml:mtext>s</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>, <xref rid="bib36" ref-type="bibr">Krzanowski 1979</xref>; <xref rid="bib6" ref-type="bibr">Blows <italic>et al.</italic> 2004</xref>) calculated for posterior mean estimates of <bold>G</bold> across a related set of scenarios. Plotted values are <inline-formula><mml:math id="me35"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:msub><mml:mtext>s</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula> so that statistics are comparable across scenarios with different subspace dimensions. On this scale, identical subspaces have a value of zero and values increase as the subspaces diverge. The value of <italic>k</italic> used in each scenario is listed inside each box plot. The difference from zero roughly corresponds to the number of eigenvectors of the true subspace missing from the estimated subspace. Different parameters were varied in each set of simulations as listed below each box. (A) Increasing numbers of simulated factors. (B) Different types of <bold>R</bold> matrices. SF, a sparse-factor form for <bold>R</bold>. F, a (nonsparse) factor form for <bold>R</bold>. Wishart, <bold>R</bold> was sampled from a Wishart distribution. (C) Different numbers of traits. (D) Different numbers of sampled individuals. Note that in scenarios h&#x02013;j, factor <italic>h</italic><sup>2</sup>&#x02019;s ranged from 0.0 to 0.9. Complete parameter sets describing each simulation are described in <xref ref-type="table" rid="t1">Table 1</xref>.</p></caption><graphic xlink:href="753fig1"/></fig><p>Even though the number of latent factors is not an explicit parameter in the BSFG model, the number of &#x0201c;large factors&#x0201d; fit in each scenario was always close to the true number of simulated factors (<xref ref-type="table" rid="t2">Table 2</xref>, except in scenario e where <bold>R</bold> was full rank). Factor identity estimates were also accurate. <xref ref-type="fig" rid="fig2">Figure 2</xref> shows the distribution of error angles between the true factors and their estimates for each scenario. Median error angles were generally around 3&#x000b0;, but occasionally as large 5&#x000b0;&#x02013;10&#x000b0; when there were more true latent factors (<xref ref-type="fig" rid="fig2">Figure 2A</xref>), if <bold>R</bold> was full rank (scenario e, <xref ref-type="fig" rid="fig2">Figure 2B</xref>), or if the sample size was small (small numbers of individuals or small numbers of traits, scenarios f and h; <xref ref-type="fig" rid="fig2">Figure 2, C and D</xref>).</p><table-wrap id="t2" position="float"><label>Table 2</label><caption><title>Number of large factors recovered in each scenario</title></caption><table frame="above" rules="groups"><col width="27.89%" span="1"/><col width="9.08%" span="1"/><col width="23.16%" span="1"/><col width="20.23%" span="1"/><col width="19.64%" span="1"/><thead><tr><th colspan="1" valign="top" align="left" scope="colgroup" rowspan="1">Scenario</th><th colspan="2" valign="top" align="center" scope="col" rowspan="1">Expected<hr/></th><th valign="top" align="center" scope="col" rowspan="1" colspan="1">Median</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Range</th></tr></thead><tbody><tr><td rowspan="3" valign="top" align="left" scope="row" colspan="1">No. factors</td><td valign="top" align="center" rowspan="1" colspan="1">a</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="(" rowspan="1" colspan="1">(10,10)</td></tr><tr><td valign="top" colspan="1" align="center" scope="row" rowspan="1">b</td><td valign="top" align="char" char="." rowspan="1" colspan="1">25</td><td valign="top" align="char" char="." rowspan="1" colspan="1">25</td><td valign="top" align="char" char="(" rowspan="1" colspan="1">(23,25)</td></tr><tr><td valign="top" colspan="1" align="center" scope="row" rowspan="1">c</td><td valign="top" align="char" char="." rowspan="1" colspan="1">50</td><td valign="top" align="char" char="." rowspan="1" colspan="1">49</td><td valign="top" align="char" char="(" rowspan="1" colspan="1">(48,50)</td></tr><tr><td rowspan="2" valign="top" align="left" scope="row" colspan="1"><bold>R</bold> type</td><td valign="top" align="center" rowspan="1" colspan="1">d</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="(" rowspan="1" colspan="1">(10,10)</td></tr><tr><td valign="top" colspan="1" align="center" scope="row" rowspan="1">e</td><td valign="top" align="center" rowspan="1" colspan="1">NA<xref ref-type="table-fn" rid="t2n1"><italic><sup>a</sup></italic></xref></td><td valign="top" align="char" char="." rowspan="1" colspan="1">56</td><td valign="top" align="char" char="(" rowspan="1" colspan="1">(44,66)</td></tr><tr><td rowspan="2" valign="top" align="left" scope="row" colspan="1">No. traits</td><td valign="top" align="center" rowspan="1" colspan="1">f</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">9</td><td valign="top" align="char" char="(" rowspan="1" colspan="1">(8,11)</td></tr><tr><td valign="top" colspan="1" align="center" scope="row" rowspan="1">g</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="(" rowspan="1" colspan="1">(10,10)</td></tr><tr><td rowspan="3" valign="top" align="left" scope="row" colspan="1">Sample size</td><td valign="top" align="center" rowspan="1" colspan="1">h</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="(" rowspan="1" colspan="1">(10,10)</td></tr><tr><td valign="top" colspan="1" align="center" scope="row" rowspan="1">i</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="(" rowspan="1" colspan="1">(10,10)</td></tr><tr><td valign="top" colspan="1" align="center" scope="row" rowspan="1">j</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="." rowspan="1" colspan="1">10</td><td valign="top" align="char" char="(" rowspan="1" colspan="1">(10,10)</td></tr></tbody></table><table-wrap-foot><fn><p>Each scenario was simulated 10 times. Factor magnitude was calculated as the <italic>L</italic><sub>2</sub>-norm of the factor loadings, divided by the total phenotypic variance across all traits. Factors explaining &#x0003e;0.1% of total phenotypic variance were considered large.</p></fn><fn id="t2n1"><label>a</label><p>In scenario e, the residual matrix did not have a factor form.</p></fn></table-wrap-foot></table-wrap><fig id="fig2" fig-type="figure" position="float"><label>Figure 2</label><caption><p>BSFG successfully fits trait loadings on latent factors. The estimated factors were matched to the true latent traits in each simulation by calculating the vector angle between the trait loadings of each true factor and the most similar estimated factor (column of <bold>&#x0039b;</bold>). The median error angle across factors was calculated for each simulation. Box plots show the distribution of median error angles by scenario. Two identical vectors have an angle of zero. Completely orthogonal vectors have an angle of 90&#x000b0;. (A) Increasing numbers of simulated factors. (B) Different types of <bold>R</bold> matrices. Angles are shown only for the genetically variable factors in scenarios d and e (factors 1&#x02013;5, see <italic>Methods</italic>). (C) Different numbers of traits. (D) Different numbers of sampled individuals.</p></caption><graphic xlink:href="753fig2"/></fig><p>Finally, the genetic architectures of the unobserved latent traits (factors) and the observed traits were accurately estimated. As expected, latent factor heritability estimates were more accurate for scenarios with larger sample sizes (<xref ref-type="fig" rid="fig3">Figure 3</xref>), but there was little difference in <italic>h</italic><sup>2</sup> estimates for factors with nonzero heritability across scenarios with different numbers of factors, different residual properties, or different numbers of traits (<ext-link ext-link-type="uri" xlink:href="http://www.genetics.org/lookup/suppl/doi:10.1534/genetics.113.151217/-/DC1/genetics.113.151217-2.pdf">Figure S2</ext-link>). With small sample sizes (scenario h), larger numbers of factors (scenarios b&#x02013;c), or fewer traits (scenario f), there was increasing error in <italic>h</italic><sup>2</sup> for factors with true <italic>h</italic><sup>2</sup> = 0 (<xref ref-type="fig" rid="fig3">Figures 3</xref> and <ext-link ext-link-type="uri" xlink:href="http://www.genetics.org/lookup/suppl/doi:10.1534/genetics.113.151217/-/DC1/genetics.113.151217-2.pdf">Figure S2</ext-link>). Similarly, sample size had the greatest effect on the quality of <italic>h</italic><sup>2</sup> estimates for the 20&#x02013;1000 traits in each scenario (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Surprisingly, the most accurate trait heritability estimates were recovered when <bold>R</bold> had a factor structure but was not sparse (scenario d, <xref ref-type="fig" rid="fig4">Figure 4B</xref>), probably because the true range of <italic>h</italic><sup>2</sup> values was greater. Heritability estimates were also more accurate with increasing complexity of <bold>G</bold> and <bold>R</bold> (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), but were not strongly affected by the number of traits studied (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), or by full-rank <bold>R</bold> (<xref ref-type="fig" rid="fig4">Figure 4B</xref>).</p><fig id="fig3" fig-type="figure" position="float"><label>Figure 3</label><caption><p>BSFG accurately estimates the heritability of latent traits. Distributions of factor <italic>h</italic><sup>2</sup> estimates for scenarios h&#x02013;j. These scenarios differed in the number of individuals sampled. Ten latent traits with <italic>h</italic><sup>2</sup>&#x02019;s between 0.0 and 0.9 were generated in each simulation. After fitting our factor model to each simulated data set, the estimated factors were matched to the true latent traits based on the trait-loading vector angles. Each box plot shows the distribution of <italic>h</italic><sup>2</sup> estimates for each simulated factor across 10 simulations. Note that the trait loadings for each factor differed in each simulation; only the <italic>h</italic><sup>2</sup> values remained the same. Thin horizontal lines in each column show the simulated <italic>h</italic><sup>2</sup> values. Colors correspond to the scenario, and solid boxes/circles are used for factors with <italic>h</italic><sup>2</sup> &#x0003e; 0.0.</p></caption><graphic xlink:href="753fig3"/></fig><fig id="fig4" fig-type="figure" position="float"><label>Figure 4</label><caption><p>BSFG estimates of individual trait heritability are accurate. The heritability of each individual trait was calculated as <inline-formula><mml:math id="me36"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>P</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. <inline-formula><mml:math id="me37"><mml:mrow><mml:mtext>RSME</mml:mtext><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> was calculated for each simulation. Box plots show the distribution of RMSE values for each scenario. (A) Increasing numbers of simulated factors. (B) Different types of <bold>R</bold> matrices. (C) Different numbers of traits. (D) Different numbers of sampled individuals.</p></caption><graphic xlink:href="753fig4"/></fig></sec><sec id="s9"><title>Gene expression example</title><p>Our estimate of the G-matrix from the <italic>Drosophila</italic> gene expression data was qualitatively similar to the original estimate (<xref ref-type="fig" rid="fig5">Figure 5B</xref>, and compare to Figure 7a in <xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> 2009)</xref>. Estimates of the broad-sense heritability of each gene were also similar (<italic>r</italic> = 0.74). While a direct comparison of the dominant G-matrix subspace recovered by our model and the estimate by <xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> (2009)</xref> was not possible because individual covariances were not reported, we could compare the two estimates of the underlying structure. Using the modulated modularity clustering (MMC) algorithm (<xref rid="bib56" ref-type="bibr">Stone and Ayroles 2009</xref>), <xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> (2009)</xref> identified 20 modules of genetically correlated transcripts <italic>post hoc</italic>. Our model identified 27 latent factors (<xref ref-type="fig" rid="fig5">Figure 5, D&#x02013;F</xref>), of which 13 were large factors (explaining &#x0003e;1% variation in 2<sup>+</sup> genes). The large factors were consistent (<italic>r</italic> &#x0003e; 0.95) across three parallel chains of the Gibbs sampler. Many factors were similar to the modules identified by MMC (<xref ref-type="fig" rid="fig5">Figure 5E</xref>). Some of the factors were nearly one-to-one matches to modules (<italic>e.g.</italic>, factor 10 with module 8, and factor 14 with module 12). However, others merged together two or more modules (<italic>e.g.</italic>, factor 1 with modules 7 and 9, and factor 2 with modules 4, 13, 16&#x02013;20). And some entire modules were part of two or more factors (<italic>e.g.</italic>, module 17 was included in factors 2 and 4, and module 18 was included in factors 2 and 16).</p><fig id="fig5" fig-type="figure" position="float"><label>Figure 5</label><caption><p>Among-line covariance of gene expression and competitive fitness in <italic>Drosophila</italic> is modular. (A&#x02013;C) Genetic (among-line) architecture of 414 gene expression traits measured in adult flies of 40 wild-caught lines (<xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> 2009</xref>). (A) Posterior mean broad-sense heritabilities (<italic>H</italic><sup>2</sup>) of the 414 genes. (B) Heat map of posterior mean genetic correlations among these genes. (C) Posterior mean estimates and 95% highest posterior density (HPD) intervals for genetic correlations between each gene and competitive fitness. For comparison, see <xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> (2009</xref>, Figure 7a). (D&#x02013;F) Latent trait structure underlying gene expression covariances. (D) Posterior mean <italic>H</italic><sup>2</sup> for each estimated latent trait. (E) Heat map of posterior mean <bold>&#x0039b;</bold> matrix showing gene loadings on each latent trait. (F) Posterior mean estimates and 95% HPD intervals for genetic correlations between each latent trait and competitive fitness. The right axis of E groups genes into modules inferred using modulated modularity clustering (<xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> 2009</xref>; <xref rid="bib56" ref-type="bibr">Stone and Ayroles 2009</xref>).</p></caption><graphic xlink:href="753fig5"/></fig><p>Each factor represents a sparse set (or &#x0201c;module&#x0201d;) of genes that may be coregulated by a common developmental process. Using the Database for Annotation, Visualization and Integrated Discovery (DAVID) v. 6.7 (<xref rid="bib28" ref-type="bibr">Huang <italic>et al.</italic> 2009a</xref>,<xref rid="bib29" ref-type="bibr">b</xref>), we identified several factors that were individually enriched (within this set of 414 genes) for defense and immunity, nervous system function, odorant binding, and transcription and cuticle formation. Similar molecular functions were identified among the modules identified by <xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> (2009)</xref>. By inferring factors at the level of phenotypic variation, rather than the among-line covariances, we could directly estimate the broad-sense heritability (<italic>H</italic><sup>2</sup>) of these latent traits themselves. <xref ref-type="fig" rid="fig5">Figure 5D</xref> shows these <italic>H</italic><sup>2</sup> estimates for each latent trait. Several of the factors have very low (&#x0003c;0.2) or very high (&#x0003e;0.75) <italic>H</italic><sup>2</sup> values. Selection on the later latent traits would likely be considerably more efficient than the former.</p><p>Finally, we estimated the among-line correlation between the expression of each gene and competitive fitness (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). Roughly 15% (60/414) of the 95% highest posterior density (HPD) interval estimates of the among-line correlations did not included zero. We also estimated the genetic correlation between competitive fitness and each of the latent traits defined by the 27 factors (<xref ref-type="fig" rid="fig5">Figure 5F</xref>). Most factors were not genetically correlated with competitive fitness. However, the genetic correlations between competitive fitness and factors 2 and 16 were large and highly significant, suggesting intriguing genetic relationships between these two latent traits and fitness.</p></sec></sec><sec sec-type="discussion" id="s10"><title>Discussion</title><p>The BSFG model performs well on both simulated and real data and opens the possibility of incorporating high-dimensional traits into evolutionary genetic studies and breeding programs. Technologies for high-dimensional phenotyping are becoming widely available in evolutionary biology and ecology so methods for modeling such traits are needed. Gene expression traits in particular provide a way to measure underappreciated molecular and developmental traits that may be important for evolution, and technologies exist to measure these traits on very large scales. Our model can be applied to other molecular traits (<italic>e.g.</italic>, metabolites or protein concentrations), high-dimensional morphological traits (<italic>e.g.</italic>, outlines of surfaces from geometric morphometrics), or gene&#x02013;environment interactions (<italic>e.g.</italic>, the same trait observed in multiple environments).</p><sec id="s11"><title>Scalability of the method</title><p>The key advantage of the BSFG model over existing methods is its ability to provide robust estimates of covariance parameters for data sets with large numbers of traits. In this study, we demonstrated high performance of the model for 100&#x02013;1000 simulated traits and robust results on real data with 415. Similar factor models (without the genetic component) have been applied to gene expression data sets with thousands of traits (<xref rid="bib3" ref-type="bibr">Bhattacharya and Dunson 2011</xref>), and we expect the genetic model to perform similarly. The main limitation will be computational time, which scales roughly linearly with the number of traits analyzed (assuming the number of important factors grows more slowly). As an example, analyses of simulations from scenario g with 1000 traits and 1000 individuals took about 4 hr to generate 12,000 posterior samples on a laptop computer with a 4-core 2.4-GHz Intel Core i7, while analyses of scenario a with 100 traits took &#x0223c;45 min. Parallel computing techniques may speed up analyses in cases of very large (<italic>e.g.</italic>, 10,000+) numbers of traits.</p><p>The main reason that our model scales well in this way is that under our prior, each factor is sparse. Experience with factor models in fields such as gene expression analysis, economics, finance, and social sciences (<xref rid="bib16" ref-type="bibr">Fan <italic>et al.</italic> 2011</xref>), as well as with genetic association studies (<italic>e.g.</italic>, <xref rid="bib15" ref-type="bibr">Engelhardt and Stephens 2010</xref>; <xref rid="bib55" ref-type="bibr">Stegle <italic>et al.</italic> 2010</xref>; <xref rid="bib49" ref-type="bibr">Parts <italic>et al.</italic> 2011</xref>) demonstrates that sparsity (or shrinkage) is necessary to perform robust inference on high-dimensional data (<xref rid="bib4" ref-type="bibr">Bickel and Levina 2008a</xref>,<xref rid="bib5" ref-type="bibr">b</xref>; <xref rid="bib14" ref-type="bibr">El Karoui 2008</xref>; <xref rid="bib46" ref-type="bibr">Meyer and Kirkpatrick 2010</xref>). Otherwise, sampling variability can overwhelm any true signals, leading to unstable estimates. Here, we used the <italic>t</italic>-distribution as a shrinkage prior, following <xref rid="bib3" ref-type="bibr">Bhattacharya and Dunson (2011)</xref>, but many other choices are possible (<xref rid="bib1" ref-type="bibr">Armagan <italic>et al.</italic> 2011</xref>).</p></sec><sec id="s12"><title>Applications to evolutionary quantitive genetics</title><p>The G-matrix features prominently in the theory of evolutionary quantitative genetics, and its estimation has been a central goal of many experimental and observational studies (<xref rid="bib60" ref-type="bibr">Walsh and Blows 2009</xref>). Since the BSFG model is built on the standard &#x0201c;animal model&#x0201d; framework, it is flexible and can be applied to many experimental designs. And since the BSFG model is Bayesian and naturally produces estimates within the parameter space, posterior samples provide convenient credible intervals for the G-matrix itself and for many evolutionarily important parameters, such as trait-specific eritabilities or individual breeding values (<xref rid="bib54" ref-type="bibr">Sorensen and Gianola 2010</xref>).</p><p>An important use of the G-matrix is to predict the response of a set of traits to selection (<xref rid="bib37" ref-type="bibr">Lande 1979</xref>). Applying Robertson&#x02019;s second theorem of natural selection, the response in <inline-formula><mml:math id="me38"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi mathvariant="bold">y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mstyle></mml:math></inline-formula> will equal the additive genetic covariance between the vector of traits and fitness <inline-formula><mml:math id="me39"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi mathvariant="bold">y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mtext>A</mml:mtext></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref rid="bib52" ref-type="bibr">Rausher 1992</xref>; <xref rid="bib60" ref-type="bibr">Walsh and Blows 2009</xref>). This quantity can be estimated directly from our model if fitness is included as the <italic>p</italic>* = (<italic>p</italic> + 1)th trait,<disp-formula id="eq"><mml:math id="me40"><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mstyle mathvariant="bold"><mml:mover accent="true"><mml:mi mathvariant="bold">y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mrow><mml:mo>/</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="me41"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mrow><mml:mo>/</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> contains all rows of <bold>&#x0039b;</bold> except the row for fitness, and <inline-formula><mml:math id="me42"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> contains only the row of <bold>&#x0039b;</bold> corresponding to fitness. Similarly, the quantity <inline-formula><mml:math id="me43"><mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> equals the percentage of genetic variation in fitness accounted for by variation in the observed traits (<xref rid="bib60" ref-type="bibr">Walsh and Blows 2009</xref>), which is useful for identifying other traits that might be relevant for fitness.</p><p>On the other hand, our model is not well suited to estimating the dimensionality of the G-matrix. A low-rank G-matrix means that there are absolute genetic constraints on evolution (<xref rid="bib37" ref-type="bibr">Lande 1979</xref>). Several methods provide statistical tests for the rank of the G-matrix (<italic>e.g.</italic>, <xref rid="bib33" ref-type="bibr">Kirkpatrick and Meyer 2004</xref>; <xref rid="bib47" ref-type="bibr">Mezey and Houle 2005</xref>; <xref rid="bib26" ref-type="bibr">Hine and Blows 2006</xref>). We use a prior that shrinks the magnitudes of higher index factors to provide robust estimates of the largest factors. This will likely have a side effect of underestimating the total number of factors, although this effect was not observed in our simulations. However, absolute constraints appear rare (<xref rid="bib27" ref-type="bibr">Houle 2010</xref>), and the dimensions of the G-matrix with the most variation are likely those with the greatest effect on evolution in natural populations (<xref rid="bib53" ref-type="bibr">Schluter 1996</xref>; <xref rid="bib31" ref-type="bibr">Kirkpatrick 2009</xref>). Our model should estimate these dimensions well. From a practical standpoint, preselecting the number of factors has plagued other reduced-rank estimators of the G-matrix (<italic>e.g.</italic>, <xref rid="bib33" ref-type="bibr">Kirkpatrick and Meyer 2004</xref>; <xref rid="bib26" ref-type="bibr">Hine and Blows 2006</xref>; <xref rid="bib43" ref-type="bibr">Meyer 2009</xref>). Our prior is based on an infinite factor model (<xref rid="bib3" ref-type="bibr">Bhattacharya and Dunson 2011</xref>), and so no <italic>a priori</italic> decision on <italic>k</italic> is needed. Instead, the parameters of the prior distribution on {<italic>&#x003c4;<sub>j</sub></italic>} become important modeling decisions. In our experience, a relatively diffuse prior on <italic>&#x003b4;<sub>l</sub></italic> with <italic>a</italic><sub>2</sub> = 3, <italic>b</italic><sub>2</sub> = 1 tends to work well.</p></sec><sec id="s13"><title>Biological interpretation of factors</title><p>Genetic modules are sets of traits likely to evolve together. We assume that the developmental process is modular and model a set of latent traits that each affect a limited number of observed traits. A unique feature of the BSFG model is that the genetic and environmental factors are estimated jointly, instead of separately as in classic multilevel factor models (<italic>e.g.</italic>, <xref rid="bib19" ref-type="bibr">Goldstein 2010</xref>). If each factor represents a true latent trait (<italic>e.g.</italic>, variation in a developmental process), it is reasonable to decompose variation in this trait into genetic and environmental components. We directly estimate the heritability of the latent traits and, therefore, can use our model to predict their evolution.</p><p>Other techniques for identifying genetic modules have several limitations. The MMC algorithm (<xref rid="bib56" ref-type="bibr">Stone and Ayroles 2009</xref>; <xref rid="bib2" ref-type="bibr">Ayroles <italic>et al.</italic> 2009</xref>) does not infer modules in an explicit quantitative genetic framework and constrains each observed trait to belong to only one module. A common strategy (<italic>e.g.</italic>, <xref rid="bib40" ref-type="bibr">McGraw <italic>et al.</italic> 2011</xref>) is to treat each major eigenvector of <bold>G</bold> or <bold>P</bold> itself as a module. These eigenvectors can be modeled directly (<italic>e.g.</italic>, <xref rid="bib33" ref-type="bibr">Kirkpatrick and Meyer 2004</xref>), but their biological interpretation is unclear because of the mathematical constraint that the eigenvectors be orthogonal (<xref rid="bib21" ref-type="bibr">Hansen and Houle 2008</xref>). Classic factor models (such as proposed by <xref rid="bib43" ref-type="bibr">Meyer 2009</xref> or <xref rid="bib13" ref-type="bibr">de los Campos and Gianola 2007</xref>) assume a form of modularity, but since the latent factors are not identifiable (<xref rid="bib43" ref-type="bibr">Meyer 2009</xref>), the identity of the underlying modules is unclear. In contrast, under our sparsity prior, the modules we identify <italic>are</italic> identifiable (up to a sign-flip: the loadings on each factor can be multiplied by &#x02212;1 without affecting its probability under the model, but this does not change which traits are associated with each factor). In simulations and with the <italic>Drosophila</italic> gene expression data, independent MCMC chains consistently identify the same dominant factors. Therefore the observed traits associated with each factor can be used to characterize a developmental module.</p></sec><sec id="s14"><title>Extensions</title><p>Our model is built on the classic mixed effect model in quantitative genetics (<xref rid="bib25" ref-type="bibr">Henderson 1984</xref>). It is straightforward to extend to models with additional fixed or random effects (<italic>e.g.</italic>, dominance or epistatic effects) for each trait. The update equation for <inline-formula><mml:math id="me44"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> in the Gibbs sampler described in the <italic>Appendix</italic> does not allow additional random effects in the model for the latent factors themselves, although other formulations are possible. A second extension relates to the case in which the relationship matrix among individuals (<bold>A</bold>) is unknown. Here, relationship estimates from genotype data can be easily incorporated. As such, our model is related to a recently proposed sparse factor model for genetic associations with intermediate phenotypes (<xref rid="bib49" ref-type="bibr">Parts <italic>et al.</italic> 2011</xref>). These authors introduced prior information on genetic modules from gene function and pathway databases, which could be incorporated in our model in a similar way.</p></sec></sec><sec sec-type="conclusions" id="s15"><title>Conclusions</title><p>The BSFG model we propose provides a novel approach to genetic estimation with high-dimensional traits. We anticipate that incorporating many diverse phenotypes into genetic studies will provide powerful insights into evolutionary processes. The use of highly informative but biologically grounded priors is necessary for making inferences on high-dimensional data and can help identify developmental mechanisms underlying phenotypic variation in populations.</p></sec>
<sec sec-type="supplementary-material">
<title>Supplementary Material</title>
<supplementary-material id="PMC_1" content-type="local-data">
<caption>
<title>Supporting Information</title>
</caption>
<media mimetype="text" mime-subtype="html" xlink:href="supp_194_3_753__index.html"/>
<media xlink:role="associated-file" mimetype="application" mime-subtype="pdf"
xlink:href="89db1ab4633f5fdf3aa3ca7ff231b205_genetics.113.151217-1.pdf"/>
<media xlink:role="associated-file" mimetype="application" mime-subtype="pdf"
xlink:href="b5ca384230c85ce7e65b241d21cf93bd_genetics.113.151217-3.pdf"/>
<media xlink:role="associated-file" mimetype="application" mime-subtype="pdf"
xlink:href="8c29f96183680be3991f7d35b76baee6_genetics.113.151217-2.pdf"/>
</supplementary-material>
</sec>
</body><back><ack><title>Acknowledgments</title><p>We thank Barbara Engelhardt, Iulian Pruteanu-Malinici, Jenny Tung, and two anonymous reviewers for comments and advice on this method. S.M. and D.E.R. are pleased to acknowledge the support of National Institutes of Health (Systems Biology) 5P50-GM081883, and S.M. is pleased to acknowledge the support of Air Force Office of Scientific Research, FA9550-10-1-0436, National Science Foundation (NSF) CCF-1049290, and NSF DMS-1209155.</p></ack><fn-group><fn id="fn1"><p>Communicating editor: I. Hoeschele</p></fn></fn-group><app-group><app><title>Appendix: Posterior sampling</title><p>We estimate the posterior distribution of the BSFG model with an adaptive partially collapsed Gibbs sampler (<xref rid="bib58" ref-type="bibr">van Dyk and Park 2011</xref>) based on the procedure proposed by <xref rid="bib3" ref-type="bibr">Bhattacharya and Dunson (2011)</xref>. The value <italic>k</italic>* at which columns in <bold>&#x0039b;</bold> are truncated is set using an adaptive procedure (<xref rid="bib3" ref-type="bibr">Bhattacharya and Dunson 2011</xref>). Given a truncation point, the following conditional posterior distributions are sampled in order:<list list-type="order" id="L3"><list-item><p>The full conditional posterior distribution of the truncated factor loading matrix <inline-formula><mml:math id="me45"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is dependent on the parameters <bold>B</bold>, <bold>E</bold><sub>a</sub>, <bold>F</bold> = <bold>F</bold><sub>a</sub> + <bold>F</bold><sub>r</sub>, and <inline-formula><mml:math id="me46"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a8;</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mtext>Diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The full density factors into independent multivariate normal densities (MVNs) for each row of <inline-formula><mml:math id="me47"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>:<disp-formula><mml:math id="me48"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">&#x003bb;</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <disp-formula><mml:math id="me49"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msubsup><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mtext>Diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>.</disp-formula></p><p>To speed up the MCMC mixing, we partially collapse this Gibbs update step by marginalizing over <bold>E</bold><sub>a</sub> &#x0223c; N(<bold>0</bold>, <bold>A</bold>, <bold>&#x003a8;</bold><sub>a</sub>). Let <inline-formula><mml:math id="me50"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a8;</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mtext>Diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>,<disp-formula><mml:math id="me51"><mml:mrow><mml:msub><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">&#x003bb;</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02009;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mo>&#x02009;</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02009;</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mrow><mml:mo>*</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi><mml:mi>A</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mrow><mml:mo>*</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="me52"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi><mml:mi>A</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mtext>Diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The matrix sum <inline-formula><mml:math id="me53"><mml:mrow><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi><mml:mi>A</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula> can be efficiently inverted each MCMC iteration by precalculating a unitary matrix <bold>U</bold> and a diagonal matrix <bold>S</bold> such that <bold>ZAZ</bold><sup>T</sup> = <bold>USU</bold><sup>T</sup>. Thus, <inline-formula><mml:math id="me54"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi><mml:mi>A</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>&#x02002;</mml:mo><mml:mtext>Diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula>, which does not require a full matrix inversion.</p></list-item><list-item><p>The full conditional posterior distribution of the joint matrix <inline-formula><mml:math id="me55"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>B</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mo>&#x02009;</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext><mml:mtext>T</mml:mtext></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula> is dependent on the parameters <bold>F</bold>, <bold>&#x0039b;</bold>, &#x003a8;<sub>a</sub>, and &#x003a8;<sub>r</sub>. The full density factors into independent MVNs for each column of the matrix,<disp-formula><mml:math id="me56"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">&#x003bb;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:msubsup><mml:mi mathvariant="bold-italic">&#x003bb;</mml:mi><mml:mi>j</mml:mi><mml:mtext>T</mml:mtext></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where<bold>W</bold> and <bold>C</bold> are defined as<disp-formula><mml:math id="me57"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi mathvariant="bold">W</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>&#x02002;</mml:mo><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="bold">0</mml:mi></mml:mtd><mml:mtd><mml:mi mathvariant="bold">0</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="bold">0</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>The precision matrix <bold>C</bold> can be efficiently inverted each MCMC iteration by precalculating the unitary matrix <bold>U</bold> and diagonal matrices <bold>S</bold><sub>1</sub> and <bold>S</bold><sub>2</sub> as the generalized singular value decomposition of the Cholesky decomposition of the two components of <bold>C</bold> such that <inline-formula><mml:math id="me58"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>&#x02002;</mml:mo><mml:mtext>Diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>r</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:msub><mml:mn>2</mml:mn><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula>, which does not require a full matrix inversion.</p></list-item><list-item><p>The full conditional posterior distribution of the latent factor heritabilities, <inline-formula><mml:math id="me59"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>Diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, is dependent on <bold>F</bold> and <bold>F</bold><sub>a</sub>. The density factors into independent distributions for each <inline-formula><mml:math id="me60"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, each of which has the form of a multinomial distribution since the prior on this parameter is discrete. This update step can be partially collapsed by marginalizing over <inline-formula><mml:math id="me61"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The partially collapsed density is normalized by summing over all possibilities of <inline-formula><mml:math id="me62"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>,<disp-formula><mml:math id="me63"><mml:mrow><mml:msub><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>f</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>f</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>f</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi><mml:mi>A</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>f</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi><mml:mi>A</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mtext>E</mml:mtext></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>where N(<bold>x</bold>|<italic>&#x003bc;</italic>, &#x003a3;) is the MVN with mean <italic>&#x003bc;</italic> and variance &#x003a3;, evaluated at <bold>x</bold>, <inline-formula><mml:math id="me64"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="me65"><mml:mrow><mml:msub><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the prior probability that <inline-formula><mml:math id="me66"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. Given this conditional posterior, <inline-formula><mml:math id="me67"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is sampled from a multinomial distribution. The MVN densities can be calculated efficiently with the diagonalization matrices given in step 1.</p></list-item><list-item><p>The full conditional posterior distribution of the genetic effects on the factors, <bold>F</bold><sub>a</sub>, depends on <bold>F</bold> and <bold>&#x003a3;</bold><sub>a</sub>. This distribution factors into independent MVNs for each column <inline-formula><mml:math id="me68"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>f</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02026;</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>&#x000a0;</mml:mo><mml:mtext>st</mml:mtext><mml:mo>&#x000a0;</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02260;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>,<disp-formula><mml:math id="me69"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>f</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>f</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>,</disp-formula></p><p>where <inline-formula><mml:math id="me70"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>.</p><p>The precision matrix <bold>C</bold> can be efficiently inverted each MCMC iteration in the same manner as in step 2.</p></list-item><list-item><p>The residuals of the genetic effects on the factor scores, <bold>F</bold><sub>r</sub>, can be calculated as <bold>F</bold> &#x02212; <bold>F</bold><sub>a</sub>. The full conditional posterior distribution of <bold>F</bold> is a matrix variate normal distribution that depends on <inline-formula><mml:math id="me71"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>B</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mo>&#x02009;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and &#x003a8;<sub>r</sub>:<disp-formula><mml:math id="me72"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mo>|</mml:mo></mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Y</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>B</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a8;</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mrow><mml:mtext>MN</mml:mtext></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Y</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi><mml:mi>B</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a8;</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>F</mml:mi></mml:mstyle><mml:mtext>a</mml:mtext></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where<disp-formula><mml:math id="me73"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a8;</mml:mi></mml:mstyle><mml:mtext>r</mml:mtext><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x0039b;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x003a3;</mml:mi></mml:mstyle><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math>.</disp-formula></p></list-item><list-item><p>The conditional posterior of the factor loading precision parameter <italic>&#x003c6;<sub>ij</sub></italic> for trait <italic>i</italic> on factor <italic>j</italic> is<disp-formula id="eq___10"><mml:math id="me84"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mtext>Ga</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>&#x003bd;</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003bd;</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msubsup><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>The conditional posterior of <italic>&#x003b4;<sub>m</sub></italic>, <italic>m</italic> = 1 &#x02026; <italic>k</italic>* is as follows. For <italic>&#x003b4;</italic><sub>1</sub>,<disp-formula><mml:math id="me75"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b4;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>&#x003c6;</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>&#x003c4;</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi mathvariant="bold">&#x0039b;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mtext>Ga</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mi>&#x003c4;</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>and for <disp-formula><mml:math id="me77"><mml:mrow><mml:msub><mml:mi>&#x003b4;</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02003;</mml:mo><mml:mi>h</mml:mi><mml:mo>&#x02265;</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula><mml:math id="me76"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b4;</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>&#x003c6;</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>&#x003c4;</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi mathvariant="bold">&#x0039b;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mtext>Ga</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mi>h</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mi>&#x003c4;</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <disp-formula><mml:math id="me85"><mml:mrow><mml:msubsup><mml:mi>&#x003c4;</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>&#x003b4;</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math>.</disp-formula></p><p>The sequence {<italic>&#x003c4;<sub>j</sub></italic>} is calculated as the cumulative product: <inline-formula><mml:math id="me78"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>&#x003b4;</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></list-item><list-item><p>The conditional posterior of the precision of the residual genetic effects of trait <italic>j</italic> is<disp-formula id="eq___15"><mml:math id="me79"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mtext>Ga</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>The conditional posterior of the residual precision of model residuals for trait <italic>j</italic> is<disp-formula id="eq___16"><mml:math id="me80"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mi>&#x003c8;</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mtext>Ga</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mtext>r</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mtext>r</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mover><mml:mrow><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder></mml:mrow><mml:mi>n</mml:mi></mml:mover><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>f</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msubsup><mml:mi mathvariant="bold-italic">&#x003bb;</mml:mi><mml:mi>j</mml:mi><mml:mtext>T</mml:mtext></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>z</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>If missing observations are present, values are drawn independently from univariate normal distributions parameterized by the current values of all other parameters,<disp-formula id="eq___17"><mml:math id="me81"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>f</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msubsup><mml:mi mathvariant="bold-italic">&#x003bb;</mml:mi><mml:mi>j</mml:mi><mml:mtext>T</mml:mtext></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>z</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>&#x003c8;</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <italic>y<sub>ij</sub></italic> is the imputed phenotype value for the <italic>j</italic>th trait in individual <italic>i</italic>. The three components of the mean are: <bold>x</bold><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>, the row vector of fixed effect covariates for individual <italic>i</italic> times <bold>b</bold><italic><sub>j</sub></italic>, the <italic>j</italic>th column of the fixed effect coefficient matrix; <bold>f</bold><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>, the row vector of factor scores on the <italic>k</italic>* factors for individual <italic>i</italic> times <inline-formula><mml:math id="me82"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">&#x003bb;</mml:mi><mml:mi>j</mml:mi><mml:mtext>T</mml:mtext></mml:msubsup></mml:mrow></mml:math></inline-formula>, the row of the factor loading matrix for trait <italic>j</italic>; and <bold>z</bold><sup>(</sup><italic><sup>i</sup></italic><sup>)</sup>, the row vector of the random (genetic) effect incidence matrix for individual <italic>i</italic> times <inline-formula><mml:math id="me83"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, the vector of residual genetic effects for trait <italic>j</italic> not accounted for by the <italic>k</italic>* factors. Finally, <italic>&#x003c8;<sub>j</sub></italic> is the residual variance of trait <italic>j</italic>. All missing data are drawn in a single block update.</p><p>Other random effects, such as the line &#x000d7; sex effects modeled in the gene expression example of this article can be incorporated into this sampling scheme in much the same way that the residual genetic effects, <bold>E</bold><sub>a</sub>, are included here.</p></list-item></list></p></app></app-group><ref-list><title>Literature Cited</title><ref id="bib1"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Armagan</surname><given-names>A.</given-names></name><name><surname>Dunson</surname><given-names>D.</given-names></name><name><surname>Clyde</surname><given-names>M.</given-names></name></person-group>, <year>2011</year>&#x02003;<article-title>Generalized beta mixtures of Gaussians</article-title>, pp. <fpage>523</fpage>&#x02013;<lpage>531</lpage> in <source>Advances in Neural Information Processing Systems 24</source>, edited by <person-group person-group-type="editor"><name><surname>Shawe-Taylor</surname><given-names>J.</given-names></name><name><surname>Zemel</surname><given-names> R.</given-names></name><name><surname>Bartlett</surname><given-names>P.</given-names></name><name><surname>Pereira</surname><given-names>F.</given-names></name><name><surname>Weinberger</surname><given-names>K.</given-names></name></person-group> Available at: <ext-link ext-link-type="uri" xlink:href="http://books.nips.cc/nips24.html">http://books.nips.cc/nips24.html</ext-link></mixed-citation></ref><ref id="bib2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ayroles</surname><given-names>J. F.</given-names></name><name><surname>Carbone</surname><given-names>M. A.</given-names></name><name><surname>Stone</surname><given-names>E. A.</given-names></name><name><surname>Jordan</surname><given-names>K. W.</given-names></name><name><surname>Lyman</surname><given-names>R. F.</given-names></name><etal/></person-group>, <year>2009</year>&#x02003;<article-title>Systems genetics of complex traits in <italic>Drosophila melanogaster</italic>.</article-title>
<source>Nat. Genet.</source>
<volume>41</volume>(<issue>3</issue>): <fpage>299</fpage>&#x02013;<lpage>307</lpage><pub-id pub-id-type="pmid">19234471</pub-id></mixed-citation></ref><ref id="bib3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhattacharya</surname><given-names>A.</given-names></name><name><surname>Dunson</surname><given-names>D. B.</given-names></name></person-group>, <year>2011</year>&#x02003;<article-title>Sparse Bayesian infinite factor models.</article-title>
<source>Biometrika</source>
<volume>98</volume>(<issue>2</issue>): <fpage>291</fpage>&#x02013;<lpage>306</lpage><pub-id pub-id-type="pmid">23049129</pub-id></mixed-citation></ref><ref id="bib4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bickel</surname><given-names>P. J.</given-names></name><name><surname>Levina</surname><given-names>E.</given-names></name></person-group>, <year>2008</year><comment>a</comment>&#x02003;<article-title>Covariance regularization by thresholding.</article-title>
<source>Ann. Stat.</source>
<volume>36</volume>: <fpage>2577</fpage>&#x02013;<lpage>2604</lpage></mixed-citation></ref><ref id="bib5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bickel</surname><given-names>P. J.</given-names></name><name><surname>Levina</surname><given-names>E.</given-names></name></person-group>, <year>2008</year><comment>b</comment>&#x02003;<article-title>Regularized estimation of large covariance matrices.</article-title>
<source>Ann. Stat.</source>
<volume>36</volume>: <fpage>199</fpage>&#x02013;<lpage>227</lpage></mixed-citation></ref><ref id="bib6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blows</surname><given-names>M. W.</given-names></name><name><surname>Chenoweth</surname><given-names>S. F.</given-names></name><name><surname>Hine</surname><given-names>E.</given-names></name></person-group>, <year>2004</year>&#x02003;<article-title>Orientation of the genetic variance&#x02013;covariance matrix and the fitness surface for multiple male sexually selected traits.</article-title>
<source>Am. Nat.</source>
<volume>163</volume>(<issue>3</issue>): <fpage>329</fpage>&#x02013;<lpage>340</lpage><pub-id pub-id-type="pmid">15026971</pub-id></mixed-citation></ref><ref id="bib7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cantor</surname><given-names>R. M.</given-names></name><name><surname>Lange</surname><given-names>K.</given-names></name><name><surname>Sinsheimer</surname><given-names>J. S.</given-names></name></person-group>, <year>2010</year>&#x02003;<article-title>Prioritizing GWAS results: a review of statistical methods and recommendations for their application.</article-title>
<source>Am. J. Hum. Genet.</source>
<volume>86</volume>(<issue>1</issue>): <fpage>6</fpage>&#x02013;<lpage>22</lpage><pub-id pub-id-type="pmid">20074509</pub-id></mixed-citation></ref><ref id="bib8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carvalho</surname><given-names>C. M.</given-names></name><name><surname>Chang</surname><given-names>J.</given-names></name><name><surname>Lucas</surname><given-names>J. E.</given-names></name><name><surname>Nevins</surname><given-names>J. R.</given-names></name><name><surname>Wang</surname><given-names>Q.</given-names></name><etal/></person-group>, <year>2008</year>&#x02003;<article-title>High-dimensional sparse factor modeling: applications in gene expression genomics.</article-title>
<source>J. Am. Stat. Assoc.</source>
<volume>103</volume>(<issue>484</issue>): <fpage>1438</fpage>&#x02013;<lpage>1456</lpage><pub-id pub-id-type="pmid">21218139</pub-id></mixed-citation></ref><ref id="bib9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheverud</surname><given-names>J. M.</given-names></name></person-group>, <year>1996</year>&#x02003;<article-title>Developmental integration and the evolution of pleiotropy.</article-title>
<source>Integr. Comp. Biol.</source>
<volume>36</volume>(<issue>1</issue>): <fpage>44</fpage>&#x02013;<lpage>50</lpage></mixed-citation></ref><ref id="bib10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>E.</given-names></name><name><surname>Levine</surname><given-names>M.</given-names></name></person-group>, <year>2008</year>&#x02003;<article-title>Properties of developmental gene regulatory networks.</article-title>
<source>Proc. Natl. Acad. Sci. USA</source>
<volume>105</volume>(<issue>51</issue>): <fpage>20063</fpage>&#x02013;<lpage>20066</lpage><pub-id pub-id-type="pmid">19104053</pub-id></mixed-citation></ref><ref id="bib11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dawid</surname><given-names>A. P.</given-names></name></person-group>, <year>1981</year>&#x02003;<article-title>Some matrix-variate distribution theory: notational considerations and a Bayesian application.</article-title>
<source>Biometrika</source>
<volume>68</volume>(<issue>1</issue>): <fpage>265</fpage>&#x02013;<lpage>274</lpage></mixed-citation></ref><ref id="bib12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de la Cruz</surname><given-names>O.</given-names></name><name><surname>Wen</surname><given-names>X.</given-names></name><name><surname>Ke</surname><given-names>B.</given-names></name><name><surname>Song</surname><given-names>M.</given-names></name><name><surname>Nicolae</surname><given-names>D. L.</given-names></name></person-group>, <year>2010</year>&#x02003;<article-title>Gene, region and pathway level analyses in whole-genome studies.</article-title>
<source>Genet. Epidemiol.</source>
<volume>34</volume>: <fpage>222</fpage>&#x02013;<lpage>231</lpage><pub-id pub-id-type="pmid">20013942</pub-id></mixed-citation></ref><ref id="bib13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Los Campos</surname><given-names>G.</given-names></name><name><surname>Gianola</surname><given-names>D.</given-names></name></person-group>, <year>2007</year>&#x02003;<article-title>Factor analysis models for structuring covariance matrices of additive genetic effects: a Bayesian implementation.</article-title>
<source>Genet. Sel. Evol.</source>
<volume>39</volume>(<issue>5</issue>): <fpage>481</fpage>&#x02013;<lpage>494</lpage><pub-id pub-id-type="pmid">17897592</pub-id></mixed-citation></ref><ref id="bib14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>el Karoui</surname><given-names>N.</given-names></name></person-group>, <year>2008</year>&#x02003;<article-title>Operator norm consistent estimation of large dimensional sparse covariance matrices.</article-title>
<source>Ann. Stat.</source>
<volume>36</volume>: <fpage>2717</fpage>&#x02013;<lpage>2756</lpage></mixed-citation></ref><ref id="bib15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engelhardt</surname><given-names>B. E.</given-names></name><name><surname>Stephens</surname><given-names>M.</given-names></name></person-group>, <year>2010</year>&#x02003;<article-title>Analysis of population structure: a unifying framework and novel methods based on sparse factor analysis.</article-title>
<source>PLoS Genet.</source>
<volume>6</volume>(<issue>9</issue>): <fpage>e1001117</fpage><pub-id pub-id-type="pmid">20862358</pub-id></mixed-citation></ref><ref id="bib16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>J.</given-names></name><name><surname>Lv</surname><given-names>J.</given-names></name><name><surname>Qi</surname><given-names>L.</given-names></name></person-group>, <year>2011</year>&#x02003;<article-title>Sparse high dimensional models in economics.</article-title>
<source>Annu. Rev. Econom.</source>
<volume>3</volume>: <fpage>291</fpage>&#x02013;<lpage>317</lpage><pub-id pub-id-type="pmid">22022635</pub-id></mixed-citation></ref><ref id="bib17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gelman</surname><given-names>A.</given-names></name></person-group>, <year>2006</year>&#x02003;<article-title>Prior distributions for variance parameters in hierarchical models.</article-title>
<source>Bayesian Anal.</source>
<volume>1</volume>(<issue>3</issue>): <fpage>515</fpage>&#x02013;<lpage>533</lpage></mixed-citation></ref><ref id="bib18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibson</surname><given-names>G.</given-names></name><name><surname>Weir</surname><given-names>B.</given-names></name></person-group>, <year>2005</year>&#x02003;<article-title>The quantitative genetics of transcription.</article-title>
<source>Trends Genet.</source>
<volume>21</volume>(<issue>11</issue>): <fpage>616</fpage>&#x02013;<lpage>623</lpage><pub-id pub-id-type="pmid">16154229</pub-id></mixed-citation></ref><ref id="bib19"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Goldstein</surname><given-names>H.</given-names></name></person-group>, <year>2010</year>&#x02003;<source><italic>Multilevel Factor Analysis</italic>, <italic>Structural Equation and Mixture Models</italic></source>, pp. <fpage>189</fpage>&#x02013;<lpage>200.</lpage>
<publisher-name>Wiley, New York.</publisher-name></mixed-citation></ref><ref id="bib20"><mixed-citation publication-type="other">Hahn, P. R., C. M. Carvalho, and S. Mukherjee, 2013&#x02003;Partial factor modeling: predictor-dependent shrinkage for linear regression. J. Am. Stat. Assoc. (in press).</mixed-citation></ref><ref id="bib21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname><given-names>T. F.</given-names></name><name><surname>Houle</surname><given-names>D.</given-names></name></person-group>, <year>2008</year>&#x02003;<article-title>Measuring and comparing evolvability and constraint in multivariate characters.</article-title>
<source>J. Evol. Biol.</source>
<volume>21</volume>(<issue>5</issue>): <fpage>1201</fpage>&#x02013;<lpage>1219</lpage><pub-id pub-id-type="pmid">18662244</pub-id></mixed-citation></ref><ref id="bib22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartl</surname><given-names>D. L.</given-names></name><name><surname>Jungen</surname><given-names>H.</given-names></name></person-group>, <year>1979</year>&#x02003;<article-title>Estimation of average fitness of populations of <italic>Drosophila melanogaster</italic> and the evolution of fitness in experimental populations.</article-title>
<source>Evolution</source>
<volume>33</volume>(<issue>1</issue>): <fpage>371</fpage>&#x02013;<lpage>380</lpage></mixed-citation></ref><ref id="bib23"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hastie</surname><given-names>T.</given-names></name><name><surname>Tibshirani</surname><given-names>R.</given-names></name><name><surname>Friedman</surname><given-names>J. H.</given-names></name></person-group>, <year>2003</year>&#x02003;<source>The Elements of Statistical Learning</source>. <publisher-name>Springer, New York</publisher-name></mixed-citation></ref><ref id="bib24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayes</surname><given-names>J. F.</given-names></name><name><surname>Hill</surname><given-names>W. G.</given-names></name></person-group>, <year>1981</year>&#x02003;<article-title>Modification of estimates of parameters in the construction of genetic selection indices (&#x02019;bending&#x02019;).</article-title>
<source>Biometrics</source>
<volume>37</volume>(<issue>3</issue>): <fpage>483</fpage>&#x02013;<lpage>493</lpage></mixed-citation></ref><ref id="bib25"><mixed-citation publication-type="book">Henderson, C. R., 1984&#x02003;<italic>Applications of Linear Models in Animal Breeding</italic> University of Guelph, Guelph, Ontario, Canada.</mixed-citation></ref><ref id="bib26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hine</surname><given-names>E.</given-names></name><name><surname>Blows</surname><given-names>M. W.</given-names></name></person-group>, <year>2006</year>&#x02003;<article-title>Determining the effective dimensionality of the genetic variance-covariance matrix.</article-title>
<source>Genetics</source>
<volume>173</volume>: <fpage>1135</fpage>&#x02013;<lpage>1144</lpage><pub-id pub-id-type="pmid">16547106</pub-id></mixed-citation></ref><ref id="bib27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houle</surname><given-names>D.</given-names></name></person-group>, <year>2010</year>&#x02003;<article-title>Colloquium papers: numbering the hairs on our heads: the shared challenge and promise of phenomics.</article-title>
<source>Proc. Natl. Acad. Sci. USA</source>
<volume>107</volume>(<issue>Suppl. 1</issue>): <fpage>1793</fpage>&#x02013;<lpage>1799</lpage><pub-id pub-id-type="pmid">19858477</pub-id></mixed-citation></ref><ref id="bib28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>D. W.</given-names></name><name><surname>Sherman</surname><given-names>B. T.</given-names></name><name><surname>Lempicki</surname><given-names>R. A.</given-names></name></person-group>, <year>2009</year><comment>a</comment>&#x02003;<article-title>Bioinformatics enrichment tools: paths toward the comprehensive functional analysis of large gene lists.</article-title>
<source>Nucleic Acids Res.</source>
<volume>37</volume>(<issue>1</issue>): <fpage>1</fpage>&#x02013;<lpage>13</lpage><pub-id pub-id-type="pmid">19033363</pub-id></mixed-citation></ref><ref id="bib29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>D. W.</given-names></name><name><surname>Sherman</surname><given-names>B. T.</given-names></name><name><surname>Lempicki</surname><given-names>R. A.</given-names></name></person-group>, <year>2009</year><comment>b</comment>&#x02003;<article-title>Systematic and integrative analysis of large gene lists using DAVID bioinformatics resources.</article-title>
<source>Nat. Protoc.</source>
<volume>4</volume>(<issue>1</issue>): <fpage>44</fpage>&#x02013;<lpage>57</lpage><pub-id pub-id-type="pmid">19131956</pub-id></mixed-citation></ref><ref id="bib30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaffrezic</surname><given-names>F.</given-names></name><name><surname>White</surname><given-names>M. S.</given-names></name><name><surname>Thompson</surname><given-names>R.</given-names></name><name><surname>Visscher</surname><given-names>P. M.</given-names></name></person-group>, <year>2002</year>&#x02003;<article-title>Contrasting models for lactation curve analysis.</article-title>
<source>J. Dairy Sci.</source>
<volume>85</volume>: <fpage>968</fpage>&#x02013;<lpage>975</lpage><pub-id pub-id-type="pmid">12018443</pub-id></mixed-citation></ref><ref id="bib31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirkpatrick</surname><given-names>M.</given-names></name></person-group>, <year>2009</year>&#x02003;<article-title>Patterns of quantitative genetic variation in multiple dimensions.</article-title>
<source>Genetica</source>
<volume>136</volume>(<issue>2</issue>): <fpage>271</fpage>&#x02013;<lpage>284</lpage><pub-id pub-id-type="pmid">18695991</pub-id></mixed-citation></ref><ref id="bib32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirkpatrick</surname><given-names>M.</given-names></name><name><surname>Heckman</surname><given-names>N.</given-names></name></person-group>, <year>1989</year>&#x02003;<article-title>A quantitative genetic model for growth, shape, reaction norms, and other infinite-dimensional characters.</article-title>
<source>J. Math. Biol.</source>
<volume>27</volume>(<issue>4</issue>): <fpage>429</fpage>&#x02013;<lpage>450</lpage><pub-id pub-id-type="pmid">2769086</pub-id></mixed-citation></ref><ref id="bib33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirkpatrick</surname><given-names>M.</given-names></name><name><surname>Meyer</surname><given-names>K.</given-names></name></person-group>, <year>2004</year>&#x02003;<article-title>Direct estimation of genetic principal components: simplified analysis of complex phenotypes.</article-title>
<source>Genetics</source>
<volume>168</volume>: <fpage>2295</fpage>&#x02013;<lpage>2306</lpage><pub-id pub-id-type="pmid">15611193</pub-id></mixed-citation></ref><ref id="bib34"><mixed-citation publication-type="journal">Knight, G. R., and A. Robertson 1957&#x02003;Fitness as a measurable character in Drosophila. Genetics 42: 524.</mixed-citation></ref><ref id="bib35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruuk</surname><given-names>L. E. B.</given-names></name></person-group>, <year>2004</year>&#x02003;<article-title>Estimating genetic parameters in natural populations using the &#x02019;animal model&#x02019;.</article-title>
<source>Philos. Trans. R. Soc. B</source>
<volume>359</volume>(<issue>1446</issue>): <fpage>873</fpage>&#x02013;<lpage>890</lpage></mixed-citation></ref><ref id="bib36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krzanowski</surname><given-names>W. J.</given-names></name></person-group>, <year>1979</year>&#x02003;<article-title>Between-groups comparison of principal components.</article-title>
<source>J. Am. Stat. Assoc.</source>
<volume>74</volume>(<issue>367</issue>): <fpage>703</fpage>&#x02013;<lpage>707</lpage></mixed-citation></ref><ref id="bib37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lande</surname><given-names>R.</given-names></name></person-group>, <year>1979</year>&#x02003;<article-title>Quantitative genetic-analysis of multivariate evolution, applied to brain&#x02013;body size allometry.</article-title>
<source>Evolution</source>
<volume>33</volume>(<issue>1</issue>): <fpage>402</fpage>&#x02013;<lpage>416</lpage></mixed-citation></ref><ref id="bib38"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lucas</surname><given-names>J.</given-names></name><name><surname>Carvalho</surname><given-names>C.</given-names></name><name><surname>Wang</surname><given-names>Q.</given-names></name><name><surname>Bild</surname><given-names>A.</given-names></name><name><surname>Nevins</surname><given-names>J.</given-names></name><etal/></person-group>, <year>2006</year>&#x02003;<article-title>Sparse statistical modelling in gene expression genomics</article-title>, pp. <fpage>155</fpage>&#x02013;<lpage>173</lpage> in <source>Bayesian Inference for Gene Expression and Proteomics</source>, edited by<person-group person-group-type="editor"><name><surname>Do</surname><given-names> K.-A.</given-names></name><name><surname>Muller</surname><given-names> P.</given-names></name><name><surname>Vannucci</surname><given-names>M.</given-names></name></person-group>
<publisher-name>Cambridge University Press</publisher-name>, <publisher-loc>Cambridge, UK</publisher-loc></mixed-citation></ref><ref id="bib39"><mixed-citation publication-type="book">Lynch, M., and B. Walsh, 1998&#x02003;<italic>Genetics and Analysis of Quantitative Traits</italic>, Ed. 1. Sinauer Associates, Sunderland, MA.</mixed-citation></ref><ref id="bib40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGraw</surname><given-names>E. A.</given-names></name><name><surname>Ye</surname><given-names>Y. H.</given-names></name><name><surname>Foley</surname><given-names>B.</given-names></name><name><surname>Chenoweth</surname><given-names>S. F.</given-names></name><name><surname>Higgie</surname><given-names>M.</given-names></name><etal/></person-group>, <year>2011</year>&#x02003;<article-title>High-dimensional variance partitioning reveals the modular genetic basis of adaptive divergence in gene expression during reproductive character displacement.</article-title>
<source>Evolution</source>
<volume>65</volume>(<issue>11</issue>): <fpage>3126</fpage>&#x02013;<lpage>3137</lpage><pub-id pub-id-type="pmid">22023580</pub-id></mixed-citation></ref><ref id="bib41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGuigan</surname><given-names>K.</given-names></name><name><surname>Blows</surname><given-names>M. W.</given-names></name></person-group>, <year>2007</year>&#x02003;<article-title>The phenotypic and genetic covariance structure of drosphilid wings.</article-title>
<source>Evolution</source>
<volume>61</volume>(<issue>4</issue>): <fpage>902</fpage>&#x02013;<lpage>911</lpage><pub-id pub-id-type="pmid">17439620</pub-id></mixed-citation></ref><ref id="bib42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>K.</given-names></name></person-group>, <year>2005</year>&#x02003;<article-title>Advances in methodology for random regression analyses.</article-title>
<source>Aust. J. Exp. Agric.</source>
<volume>45</volume>: <fpage>847</fpage>&#x02013;<lpage>858</lpage></mixed-citation></ref><ref id="bib43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>K.</given-names></name></person-group>, <year>2009</year>&#x02003;<article-title>Factor-analytic models for genotype &#x000d7; environment type problems and structured covariance matrices.</article-title>
<source>Genet. Sel. Evol.</source>
<volume>41</volume>: <fpage>21</fpage><pub-id pub-id-type="pmid">19284520</pub-id></mixed-citation></ref><ref id="bib44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>K.</given-names></name><name><surname>Kirkpatrick</surname><given-names>M.</given-names></name></person-group>, <year>2007</year>&#x02003;<article-title>A note on bias in reduced rank estimates of covariance matrices.</article-title>
<source>Proc. Assoc. Adv. Anim. Breed. Genet</source>
<volume>17</volume>: <fpage>154</fpage>&#x02013;<lpage>157</lpage></mixed-citation></ref><ref id="bib45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>K.</given-names></name><name><surname>Kirkpatrick</surname><given-names>M.</given-names></name></person-group>, <year>2008</year>&#x02003;<article-title>Perils of parsimony: properties of reduced-rank estimates of genetic covariance matrices.</article-title>
<source>Genetics</source>
<volume>180</volume>: <fpage>1153</fpage>&#x02013;<lpage>1166</lpage><pub-id pub-id-type="pmid">18757923</pub-id></mixed-citation></ref><ref id="bib46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>K.</given-names></name><name><surname>Kirkpatrick</surname><given-names>M.</given-names></name></person-group>, <year>2010</year>&#x02003;<article-title>Better estimates of genetic covariance matrices by &#x0201c;bending&#x0201d; using penalized maximum likelihood.</article-title>
<source>Genetics</source>
<volume>185</volume>(<issue>3</issue>): <fpage>1097</fpage>&#x02013;<lpage>1110</lpage><pub-id pub-id-type="pmid">20442220</pub-id></mixed-citation></ref><ref id="bib47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mezey</surname><given-names>J.</given-names></name><name><surname>Houle</surname><given-names>D.</given-names></name></person-group>, <year>2005</year>&#x02003;<article-title>The dimensionality of genetic variation for wing shape in <italic>Drosophila melanogaster</italic>.</article-title>
<source>Evolution</source>
<volume>59</volume>(<issue>5</issue>): <fpage>1027</fpage>&#x02013;<lpage>1038</lpage><pub-id pub-id-type="pmid">16136802</pub-id></mixed-citation></ref><ref id="bib48"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Neal</surname><given-names>R. M.</given-names></name></person-group>, <year>1996</year>&#x02003;<source>Bayesian Learning for Neural Networks</source>. <publisher-name>Springer-Verlag, New York</publisher-name>, <publisher-loc>Secaucus, NJ</publisher-loc></mixed-citation></ref><ref id="bib49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parts</surname><given-names>L.</given-names></name><name><surname>Stegle</surname><given-names>O.</given-names></name><name><surname>Winn</surname><given-names>J.</given-names></name><name><surname>Durbin</surname><given-names>R.</given-names></name></person-group>, <year>2011</year>&#x02003;<article-title>Joint genetic analysis of gene expression data with inferred cellular phenotypes.</article-title>
<source>PLoS Genet.</source>
<volume>7</volume>(<issue>1</issue>): <fpage>e1001276</fpage><pub-id pub-id-type="pmid">21283789</pub-id></mixed-citation></ref><ref id="bib64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>T.</given-names></name><name><surname>Casella</surname><given-names>G.</given-names></name></person-group>, <year>2008</year>&#x02003;<italic>The Bayesian Lasso.</italic>
<source>J. Am. Stat. Assoc.</source>
<volume>103</volume>: <fpage>681</fpage>&#x02013;<lpage>686</lpage></mixed-citation></ref><ref id="bib50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pletcher</surname><given-names>S. D.</given-names></name><name><surname>Geyer</surname><given-names>C. J.</given-names></name></person-group>, <year>1999</year>&#x02003;<article-title>The genetic analysis of age-dependent traits: modeling the character process.</article-title>
<source>Genetics</source>
<volume>153</volume>: <fpage>825</fpage>&#x02013;<lpage>835</lpage><pub-id pub-id-type="pmid">10610347</pub-id></mixed-citation></ref><ref id="bib51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poggio</surname><given-names>T.</given-names></name><name><surname>Smale</surname><given-names>S.</given-names></name></person-group>, <year>2003</year>&#x02003;<article-title>The mathematics of learning: dealing with data.</article-title>
<source>Not. Am. Math. Soc.</source>
<volume>50</volume>: <fpage>2003</fpage></mixed-citation></ref><ref id="bib52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rausher</surname><given-names>M. D.</given-names></name></person-group>, <year>1992</year>&#x02003;<article-title>The measurement of selection on quantitative traits - biases due to environmental covariances between traits and fitness.</article-title>
<source>Evolution</source>
<volume>46</volume>(<issue>3</issue>): <fpage>616</fpage>&#x02013;<lpage>626</lpage></mixed-citation></ref><ref id="bib53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schluter</surname><given-names>D.</given-names></name></person-group>, <year>1996</year>&#x02003;<article-title>Adaptive radiation along genetic lines of least resistance.</article-title>
<source>Evolution</source>
<volume>50</volume>(<issue>5</issue>): <fpage>1766</fpage>&#x02013;<lpage>1774</lpage></mixed-citation></ref><ref id="bib54"><mixed-citation publication-type="book">Sorensen, D., and D. Gianola, 2010&#x02003;<italic>Likelihood</italic>, <italic>Bayesian and MCMC Methods in Quantitative Genetics: Statistics for Biology and Health</italic> Springer-Verlag, Berlin.</mixed-citation></ref><ref id="bib55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stegle</surname><given-names>O.</given-names></name><name><surname>Parts</surname><given-names>L.</given-names></name><name><surname>Durbin</surname><given-names>R.</given-names></name><name><surname>Winn</surname><given-names>J.</given-names></name></person-group>, <year>2010</year>&#x02003;<article-title>A Bayesian framework to account for complex non-genetic factors in gene expression levels greatly increases power in eQTL studies.</article-title>
<source>PLOS Comput. Biol.</source>
<volume>6</volume>(<issue>5</issue>): <fpage>e1000770</fpage><pub-id pub-id-type="pmid">20463871</pub-id></mixed-citation></ref><ref id="bib56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stone</surname><given-names>E. A.</given-names></name><name><surname>Ayroles</surname><given-names>J. F.</given-names></name></person-group>, <year>2009</year>&#x02003;<article-title>Modulated modularity clustering as an exploratory tool for functional genomic inference.</article-title>
<source>PLoS Genet.</source>
<volume>5</volume>(<issue>5</issue>): <fpage>e1000479</fpage><pub-id pub-id-type="pmid">19424432</pub-id></mixed-citation></ref><ref id="bib57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tipping</surname><given-names>M. E.</given-names></name></person-group>, <year>2001</year>&#x02003;<article-title>Sparse bayesian learning and the relevance vector machine.</article-title>
<source>J. Mach. Learn. Res.</source>
<volume>1</volume>: <fpage>211</fpage>&#x02013;<lpage>244</lpage></mixed-citation></ref><ref id="bib58"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>van Dyk</surname><given-names>D. A.</given-names></name><name><surname>Park</surname><given-names>T.</given-names></name></person-group>, <year>2011</year>&#x02003;<article-title>Partially collapsed Gibbs sampling and path-adaptive Metropolis-Hastings in high-energy astrophysics</article-title>, pp. <fpage>383</fpage>&#x02013;<lpage>397</lpage> in <source>Handbook of Markov Chain Monte Carlo</source>, edited by<person-group person-group-type="editor"><name><surname>Brooks</surname><given-names> S.</given-names></name><name><surname>Gelman</surname><given-names> A.</given-names></name><name><surname>Jones</surname><given-names>G.</given-names></name><name><surname>Meng</surname><given-names>X.-L.</given-names></name></person-group>
<publisher-name>Chapman &#x00026; Hall/CRC Handbooks of Modern Statistical Methods</publisher-name>, <publisher-loc>New York, NY</publisher-loc></mixed-citation></ref><ref id="bib59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagner</surname><given-names>G.</given-names></name><name><surname>Altenberg</surname><given-names>L.</given-names></name></person-group>, <year>1996</year>&#x02003;<article-title>Perspective: complex adaptations and the evolution of evolvability.</article-title>
<source>Evolution</source>
<volume>50</volume>: <fpage>967</fpage>&#x02013;<lpage>976</lpage></mixed-citation></ref><ref id="bib60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walsh</surname><given-names>B.</given-names></name><name><surname>Blows</surname><given-names>M. W.</given-names></name></person-group>, <year>2009</year>&#x02003;<article-title>Abundant genetic variation plus strong selection = multivariate genetic constraints: a geometric view of adaptation.</article-title>
<source>Annu. Rev. Ecol. Evol. Syst.</source>
<volume>40</volume>: <fpage>41</fpage>&#x02013;<lpage>59</lpage></mixed-citation></ref><ref id="bib61"><mixed-citation publication-type="book">West, M., 2003&#x02003;Bayesian factor regression models in the &#x0201c;large p, small n&#x0201d; paradigm, pp. 723&#x02013;732 in <italic>Bayesian Statistics</italic> Oxford University Press, Oxford.</mixed-citation></ref><ref id="bib62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiong</surname><given-names>Q.</given-names></name><name><surname>Ancona</surname><given-names>N.</given-names></name><name><surname>Hauser</surname><given-names>E. R.</given-names></name><name><surname>Mukherjee</surname><given-names>S.</given-names></name><name><surname>Furey</surname><given-names>T. S.</given-names></name></person-group>, <year>2012</year>&#x02003;<article-title>Integrating genetic and gene expression evidence into genome-wide association analysis of gene sets.</article-title>
<source>Genome Res.</source>
<volume>22</volume>: <fpage>386</fpage>&#x02013;<lpage>397</lpage><pub-id pub-id-type="pmid">21940837</pub-id></mixed-citation></ref><ref id="bib63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>X.</given-names></name><name><surname>Stephens</surname><given-names>M.</given-names></name></person-group>, <year>2012</year>&#x02003;<article-title>Genome-wide efficient mixed-model analysis for association studies.</article-title>
<source>Nat. Genet.</source>
<volume>44</volume>: <fpage>821</fpage>&#x02013;<lpage>824</lpage><pub-id pub-id-type="pmid">22706312</pub-id></mixed-citation></ref></ref-list></back></article>